\documentclass[]{krantz}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{
            pdftitle={R Programming for Data Sciences},
            pdfauthor={Andrew O. Finley, Jeffrey W. Doser, Vince Melfi},
            colorlinks=true,
            linkcolor=Maroon,
            citecolor=Blue,
            urlcolor=Blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.43,0.43,0.43}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.61,0.61,0.61}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.33,0.33,0.33}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.14,0.14,0.14}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{long table}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\frontmatter

\title{R Programming for Data Sciences}
\author{Andrew O. Finley, Jeffrey W. Doser, Vince Melfi}
\date{2019-07-16}

\begin{document}
\maketitle

% you may need to leave a few empty pages before the dedication page

%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}

\begin{center}
To my son,

without whom I should have finished this book two years earlier
%\includegraphics{images/dedication.pdf}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

{
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoftables
\listoffigures
\chapter*{Course Description}\label{course-description}


This book serves as an introduction to programming in R and the use of
associated open source tools. We address practical issues in documenting
workflow, data management, and scientific computing.

\mainmatter

\chapter{Data}\label{data}

Data science is a field that intersects with statistics, mathematics,
computer science, and a wide range of applied fields, such as marketing,
biology, and physics. As such, it is hard to formally define data
science, but obviously data is central to data science, and it is useful
at the start to consider some types of data that are of interest.

\section{Baby Crawling Data}\label{baby-crawling-data}

When thinking about data, we might initially have in mind a modest-sized
and uncomplicated data set consisting primarily of numbers. As an
example of such a data set, a study was done to assess the possible
relationship between the age at which babies first begin to crawl and
the temperature at the time of first crawling. Participants in the study
were volunteers.\footnote{More correctly, were volunteered by their
  parents.} The data set from this study separates the babies by birth
month, and reports the birth month, the average age (in weeks) when
first crawling for that month, the standard deviation of the crawling
ages for that month, the number of infants for that month, and the
average temperature during the month when crawling commenced. The data
are shown in Table \ref{tab:crawling} below.\footnote{These data were
  retrieved from
  \url{http://lib.stat.cmu.edu/DASL/Datafiles/Crawling.html}.}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/BabyCrawling.tsv"}
\OperatorTok{>}\StringTok{ }\NormalTok{BabyCrawling <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(u, }\DataTypeTok{header=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:crawling}Data on age at crawling}
\centering
\begin{tabular}{lrrrr}
\toprule
BirthMonth & AvgCrawlingAge & SD & n & temperature\\
\midrule
January & 29.84 & 7.08 & 32 & 66\\
February & 30.52 & 6.96 & 36 & 73\\
March & 29.70 & 8.33 & 23 & 72\\
April & 31.84 & 6.21 & 26 & 63\\
May & 28.58 & 8.07 & 27 & 52\\
\addlinespace
June & 31.44 & 8.10 & 29 & 39\\
July & 33.64 & 6.91 & 21 & 33\\
August & 32.82 & 7.61 & 45 & 30\\
September & 33.83 & 6.93 & 38 & 33\\
October & 33.35 & 7.29 & 44 & 37\\
\addlinespace
November & 33.38 & 7.42 & 49 & 48\\
December & 32.32 & 5.71 & 44 & 57\\
\bottomrule
\end{tabular}
\end{table}

This data set has many simple properties: it is relatively small, there
are no missing observations, the variables are easily understood, etc.

\section{World Bank Data}\label{world-bank-data}

The World Bank provides data related to the development of countries. A
data set was constructed from the World Bank repository. The data set
contains data on countries throughout the world for the years 1960
through 2014 and contains, among others, variables representing average
life expectancy, fertility rate, and population. Table
\ref{tab:worldBank} contains the first five records and then 10 more
randomly selected records for these variables in the data set.

\begin{table}[t]

\caption{\label{tab:worldBank}A small portion of the World Bank data set}
\centering
\begin{tabular}{lrrrr}
\toprule
country & year & fertility.rate & life.expectancy & population\\
\midrule
Andorra & 1978 &  &  & 33746\\
Andorra & 1979 &  &  & 34819\\
Andorra & 1977 &  &  & 32769\\
Andorra & 2007 & 1.180 &  & 81292\\
Andorra & 1976 &  &  & 31781\\
\addlinespace
Cayman Islands & 1977 &  &  & 13840\\
Jamaica & 1992 & 2.855 & 70.45 & 2423044\\
Maldives & 1975 & 6.981 & 47.97 & 134077\\
St. Vincent and the Grenadines & 1972 & 5.629 & 65.47 & 92465\\
Mauritania & 1981 & 6.368 & 54.84 & 1578670\\
\addlinespace
Oman & 1993 & 6.098 & 68.95 & 2043912\\
Bahamas, The & 1966 & 3.893 & 64.68 & 146364\\
Angola & 1983 & 7.205 & 40.53 & 8489864\\
French Polynesia & 1980 & 3.989 & 64.71 & 151702\\
Lesotho & 1974 & 5.780 & 50.29 & 1122484\\
\bottomrule
\end{tabular}
\end{table}

Notice that many observations contain missing data for fertility rate
and life expectancy. If all the variables were shown, we would see much
more missing data. This data set is also substantially larger than the
baby crawling age data, with 11880 rows and 15 columns of data in the
full data set. (Each column represents one of the variables. Each row
represents one country during one year).

\section{Email Data}\label{email-data}

It is estimated that in 2015, 90\% of the total 205 billion emails sent
were spam.\footnote{Radicati Group \url{http://www.radicati.com}} Spam
filters use large amounts of data from emails to learn what
distinguishes spam messages from non-spam (sometimes called ``ham'')
messages. Below we include one spam message followed by a ham
message.\footnote{These messages both come from the large collection of
  spam and ham messages at \url{http://spamassassin.apache.org}.}

\begin{verbatim}
From safety33o@l11.newnamedns.com  Fri Aug 23 11:03:37 2002
Return-Path: <safety33o@l11.newnamedns.com>
Delivered-To: zzzz@localhost.example.com
Received: from localhost (localhost [127.0.0.1])
    by phobos.labs.example.com (Postfix) with ESMTP id 5AC994415F
    for <zzzz@localhost>; Fri, 23 Aug 2002 06:02:59 -0400 (EDT)
Received: from mail.webnote.net [193.120.211.219]
    by localhost with POP3 (fetchmail-5.9.0)
    for zzzz@localhost (single-drop); Fri, 23 Aug 2002 11:02:59 +0100 (IST)
Received: from l11.newnamedns.com ([64.25.38.81])
    by webnote.net (8.9.3/8.9.3) with ESMTP id KAA09379
    for <zzzz@example.com>; Fri, 23 Aug 2002 10:18:03 +0100
From: safety33o@l11.newnamedns.com
Date: Fri, 23 Aug 2002 02:16:25 -0400
Message-Id: <200208230616.g7N6GOR28438@l11.newnamedns.com>
To: kxzzzzgxlrah@l11.newnamedns.com
Reply-To: safety33o@l11.newnamedns.com
Subject: ADV: Lowest life insurance rates available!                                                   
moode

Lowest rates available for term life insurance! Take a moment 
and fill out our online form 
to see the low rate you qualify for. 
Save up to 70% from regular rates! Smokers accepted! 
http://www.newnamedns.com/termlife/ 
          
Representing quality nationwide carriers. Act now!
\end{verbatim}

\begin{verbatim}
From rssfeeds@jmason.org  Tue Oct  1 10:37:22 2002
Return-Path: <rssfeeds@example.com>
Delivered-To: yyyy@localhost.example.com
Received: from localhost (jalapeno [127.0.0.1])
    by jmason.org (Postfix) with ESMTP id B277816F16
    for <jm@localhost>; Tue,  1 Oct 2002 10:37:21 +0100 (IST)
Received: from jalapeno [127.0.0.1]
    by localhost with IMAP (fetchmail-5.9.0)
    for jm@localhost (single-drop); Tue, 01 Oct 2002 10:37:21 +0100 (IST)
Received: from dogma.slashnull.org (localhost [127.0.0.1]) by
    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g9180YK15357 for
    <jm@jmason.org>; Tue, 1 Oct 2002 09:00:34 +0100
Message-Id: <200210010800.g9180YK15357@dogma.slashnull.org>
To: yyyy@example.com
From: boingboing <rssfeeds@example.com>
Subject: Disney's no-good Park-Czar replaced
Date: Tue, 01 Oct 2002 08:00:34 -0000
Content-Type: text/plain; encoding=utf-8
X-Spam-Status: No, hits=-641.2 required=5.0
    tests=AWL
    version=2.50-cvs
X-Spam-Level: 

URL: http://boingboing.net/#85506723
Date: Not supplied

Disney has named a new president of Walt Disney Parks, replacing Paul Pressler, 
the exec who did his damnedest to ruin Disneyland, slashing spending (at the 
expense of safety and employee satisfaction), building the craptastical 
California Adventure, reducing the number of SKUs available for sale in the 
Park stores, and so on. The new president, James Rasulo, used to be head of 
Euro Disney. Link[1] Discuss[2]

[1] http://reuters.com/news_article.jhtml?type=search&StoryID=1510778
[2] http://www.quicktopic.com/boing/H/rw7cDXT3W44C
\end{verbatim}

To implement a spam filter we would have to get the data from these
email messages (and thousands of others) into a software package,
extract and separate potentially important features such as the
\texttt{To:} line, the \texttt{Subject:} line, the message body, etc.,
and then compare spam and non-spam messages to find a method to classify
new emails correctly. These steps are not simple in this example. In
particular, we would need to become skilled at working with \emph{text
data}.

\section{Handwritten Digit
Recognition}\label{handwritten-digit-recognition}

Correct recognition of handwritten digits by a machine is commonly
required in today's world. For example, the postal service must scan and
recognize zip codes on handwritten mail. Roughly speaking, a handwritten
digit is scanned and converted to a digital image. To keep things simple
we will assume the scanning creates a grayscale rather than a color
image. When converting an image to a grayscale digital image, a grid of
``pixels'' is used to represent the handwritten image, where each pixel
has a black intensity value. For concreteness we'll assume that
intensities are recorded on a scale from \(-1\) (no black intensity at
all) to \(1\) (maximum black intensity). If the pixel grid is 16 by 16
then the resulting digitized image will contain 256 intensity values,
one for each of the \(16\times 16 = 256\) pixels.

For example, here are the data corresponding to one handwritten digit,
which happens to be the numeral ``6''. Figure \ref{fig:digit} shows how
that digit looks when digitized.

\begin{verbatim}
-1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.631  0.862 -0.167 
-1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 
-1.000 -1.000 -0.992  0.297  1.000  0.307 -1.000 -1.000 -1.000 -1.000 
-1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.410  1.000 
 0.986 -0.565 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 
-1.000 -1.000 -1.000 -0.683  0.825  1.000  0.562 -1.000 -1.000 -1.000 
-1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.938  0.540 
 1.000  0.778 -0.715 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 
-1.000 -1.000 -1.000 -1.000  0.100  1.000  0.922 -0.439 -1.000 -1.000 
-1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.257 
 0.950  1.000 -0.162 -1.000 -1.000 -1.000 -0.987 -0.714 -0.832 -1.000 
-1.000 -1.000 -1.000 -1.000 -0.797  0.909  1.000  0.300 -0.961 -1.000 
-1.000 -0.550  0.485  0.996  0.867  0.092 -1.000 -1.000 -1.000 -1.000 
 0.278  1.000  0.877 -0.824 -1.000 -0.905  0.145  0.977  1.000  1.000 
 1.000  0.990 -0.745 -1.000 -1.000 -0.950  0.847  1.000  0.327 -1.000 
-1.000  0.355  1.000  0.655 -0.109 -0.185  1.000  0.988 -0.723 -1.000 
-1.000 -0.630  1.000  1.000  0.068 -0.925  0.113  0.960  0.308 -0.884 
-1.000 -0.075  1.000  0.641 -0.995 -1.000 -1.000 -0.677  1.000  1.000 
 0.753  0.341  1.000  0.707 -0.942 -1.000 -1.000  0.545  1.000  0.027 
-1.000 -1.000 -1.000 -0.903  0.792  1.000  1.000  1.000  1.000  0.536 
 0.184  0.812  0.837  0.978  0.864 -0.630 -1.000 -1.000 -1.000 -1.000 
-0.452  0.828  1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000 
 0.135 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.483  0.813  1.000 
 1.000  1.000  1.000  1.000  1.000  0.219 -0.943 -1.000 -1.000 -1.000 
-1.000 -1.000 -1.000 -1.000 -0.974 -0.429  0.304  0.823  1.000  0.482 
-0.474 -0.991 -1.000 -1.000 -1.000 -1.000 
\end{verbatim}

\begin{figure}
\centering
\includegraphics{bookdown_files/figure-latex/digit-1.pdf}
\caption{\label{fig:digit}A digitized version of a handwritten 6}
\end{figure}

Looking at the digitized images, it may seem simple to correctly
identify a handwritten numeral. But remember, the machine only has
access to the 256 pixel intensities, and must make a decision based on
them.

Figure \ref{fig:25digits} shows the digitized images of the first 25
numerals in the data set, and Figure \ref{fig:25Sevens} shows the
digitized images of the first 25 numeral sevens in the data set. These
give some idea of the variability in how digits are written.\footnote{Actually,
  these data were already pre-processed to get the orientation correct.
  Actual handwritten digits would be even more variable.}

\begin{figure}
\centering
\includegraphics{bookdown_files/figure-latex/25digits-1.pdf}
\caption{\label{fig:25digits}The first 25 handwritten numerals, digitized}
\end{figure}

\begin{figure}
\centering
\includegraphics{bookdown_files/figure-latex/25Sevens-1.pdf}
\caption{\label{fig:25Sevens}The first 25 numeral sevens, digitized}
\end{figure}

\section{Looking Forward}\label{looking-forward}

The four examples above illustrate a small sample of the wide variety of
data sets that may be encountered in data science. Each of these
provides its own challenges. The baby crawling data present challenges
that are more statistical in nature. For example, how might the study
design (which isn't described here) affect methods of analysis and
conclusions drawn from the study? Similar challenges are also present
within the other data sets, but these data sets also present more
substantial challenges prior to (and during) the analysis stage, such as
how to work with the missing data in the World Bank data set, or how to
effectively and efficiently process the email data to extract features
of interest.

This book and associated material introduce tools to tackle some of the
challenges in working with real data sets, within the context of the R
statistical system. We will focus on important topics such as

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Obtaining and manipulating data
\item
  Graphical tools for exploring and summarizing data
\item
  Communicating findings about data that support reproducible research
\item
  Tools for classification problems such as email spam filtering or
  handwritten digit recognition
\item
  Programming and writing functions in R
\end{enumerate}

\section{How to learn (The most important section in this
book!)}\label{how-to-learn-the-most-important-section-in-this-book}

There are several ways to engage with the content of this book and
associated materials.

One way is not to engage at all. Leave the book closed on a shelf and do
something else with your time. That may or may not be a good life
strategy, depending on what else you do with your time, but you won't
learn much from the book!

Another way to engage is to read through the book ``passively'', reading
all that's written but not reading the book while at your computer,
where you could enter the R commands from the book. With this strategy
you'll probably learn more than if you leave the book closed on a shelf,
but there are better options.

A third way to engage is to read the book while you're at a computer,
enter the R commands from the book as you read about them, and work on
the practice problems within many of the chapters. You'll likely learn
more this way.

A fourth strategy is even better. In addition to reading, entering the
commands given in the book, and working through the practice exercises,
you think about what you're doing, and ask yourself questions (which you
then go on to answer). For example after working through some R code
computing the logarithm of positive numbers you might ask yourself,
``What would R do if I asked it to calculate the logarithm of a negative
number? What would R do if I asked it to calculate the logarithm of a
really large number such as one trillion?'' You could explore these
questions easily by just trying things out in the R Console window.

If your goal is to maximize the time you have to binge-watch
\emph{Stranger Things} Season 2 on Netflix, the first strategy may be
optimal. But if your goal is to learn a lot about computational tools
for data science, the fourth strategy is probably going to be best.

\chapter{Introduction to R and
RStudio}\label{introduction-to-r-and-rstudio}

Various statistical and programming software environments are used in
data science, including R, Python, SAS, C++, SPSS, and many others. Each
has strengths and weaknesses, and often two or more are used in a single
project. This book focuses on R for several reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  R is free
\item
  It is one of, if not the, most widely used software environments in
  data science
\item
  R is under constant and open development by a diverse and expert core
  group
\item
  It has an incredible variety of contributed packages
\item
  A new user can (relatively) quickly gain enough skills to obtain,
  manage, and analyze data in R
\end{enumerate}

Several enhanced interfaces for R have been developed. Generally such
interfaces are referred to as \emph{integrated development environments
(IDE)}. These interfaces are used to facilitate software development. At
minimum, an IDE typically consists of a source code editor and build
automation tools. We will use the RStudio IDE, which according to its
developers ``is a powerful productive user interface for R.''\footnote{\url{http://www.rstudio.com/}}
RStudio is widely used, it is used increasingly in the R community, and
it makes learning to use R a bit simpler. Although we will use RStudio,
most of what is presented in this book can be accomplished in R (without
an added interface) with few or no changes.

\section{Obtaining and Installing R}\label{obtaining-and-installing-r}

It is simple to install R on computers running Microsoft Windows, macOS,
or Linux. For other operating systems users can compile the source code
directly.\footnote{Windows, macOS, and Linux users also can compile the
  source code directly, but for most it is a better idea to install R
  from already compiled binary distributions.} Here is a step-by-step
guide to installing R for Microsoft Windows.\footnote{New versions of R
  are released regularly, so the version number in Step 6 might be
  different from what is listed below.} macOS and Linux users would
follow similar steps.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Go to \url{http://www.r-project.org/}
\item
  Click on the \texttt{CRAN} link on the left side of the page
\item
  Choose one of the mirrors.\footnote{The \url{http://cran.rstudio.com/}
    mirror is usually fast. Otherwise choose a mirror in Michigan.}
\item
  Click on \texttt{Download\ R\ for\ Windows}
\item
  Click on \texttt{base}
\item
  Click on \texttt{Download\ R\ 3.6.0\ for\ Windows}
\item
  Install R as you would install any other Windows program
\end{enumerate}

\section{Obtaining and Installing
RStudio}\label{obtaining-and-installing-rstudio}

You must install R prior to installing RStudio. RStudio is also simple
to install:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Go to \url{http://www.rstudio.com}
\item
  Click on the link \texttt{RStudio} under the \texttt{Products} tab,
  then select the \texttt{Desktop} option
\item
  Click on the \texttt{Desktop} link
\item
  Choose the \texttt{DOWNLOAD\ RSTUDIO\ DESKTOP} link in the
  \texttt{Open\ Source\ Edition} column
\item
  On the ensuing page, click on the \texttt{Installer} version for your
  operating system, and once downloaded, install as you would any other
  program
\end{enumerate}

\section{Using R and RStudio}\label{using-r-and-rstudio}

Start RStudio as you would any other program in your operating system.
For example, under Microsoft Windows use the Start Menu or double click
on the shortcut on the desktop (if a shortcut was created in the
installation process). A (rather small) view of RStudio is displayed in
Figure \ref{fig:rstudioPic}.

\begin{figure}
\includegraphics[width=1\linewidth]{../figures/RStudio} \caption{The RStudio IDE}\label{fig:rstudioPic}
\end{figure}

Initially the RStudio window contains three smaller windows. For now our
main focus will be the large window on the left, the \texttt{Console}
window, in which R statements are typed. The next few sections give
simple examples of the use of R. In these sections we will focus on
small and non-complex data sets, but of course later in the book we will
work with much larger and more complex sets of data. Read these sections
at your computer with R running, and enter the R commands there to get
comfortable using the R console window and RStudio.

\subsection{R as a Calculator}\label{r-as-a-calculator}

R can be used as a calculator. Note that \texttt{\#} is the comment
character in R, so R ignores everything following this character. Also,
you will see that R prints \texttt{{[}1{]}} before the results of each
command. Soon we will explain its relevance, but ignore this for now.
The command prompt in R is the greater than sign
\texttt{\textgreater{}}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{34}\OperatorTok{+}\DecValTok{20}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{100}\NormalTok{)  ## +,-,*,/ have the expected meanings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 234
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\DecValTok{2}\NormalTok{)  ##The exponential function}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 7.389
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{log10}\NormalTok{(}\DecValTok{100}\NormalTok{)  ##Base 10 logarithm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{log}\NormalTok{(}\DecValTok{100}\NormalTok{)  ##Base e logarithm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.605
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{10}\OperatorTok{^}\KeywordTok{log10}\NormalTok{(}\DecValTok{55}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 55
\end{verbatim}

Most functions in R can be applied to vector arguments rather than
operating on a single argument at a time. A \texttt{vector} is a data
structure that contains elements of the same data type (i.e.~integers).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{25}\NormalTok{ ##The integers from 1 to 25}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17
[18] 18 19 20 21 22 23 24 25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{log}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{25}\NormalTok{) ##The base e logarithm of these integers}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.0000 0.6931 1.0986 1.3863 1.6094 1.7918 1.9459
 [8] 2.0794 2.1972 2.3026 2.3979 2.4849 2.5649 2.6391
[15] 2.7081 2.7726 2.8332 2.8904 2.9444 2.9957 3.0445
[22] 3.0910 3.1355 3.1781 3.2189
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{25}\OperatorTok{*}\DecValTok{1}\OperatorTok{:}\DecValTok{25}\NormalTok{ ##What will this produce?}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]   1   4   9  16  25  36  49  64  81 100 121 144
[13] 169 196 225 256 289 324 361 400 441 484 529 576
[25] 625
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{25}\OperatorTok{*}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{ ##What about this?}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]   1   4   9  16  25   6  14  24  36  50  11  24
[13]  39  56  75  16  34  54  76 100  21  44  69  96
[25] 125
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\DecValTok{0}\NormalTok{, }\DataTypeTok{to=}\DecValTok{1}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{) ##A sequence of numbers from 0 to 1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\DecValTok{0}\NormalTok{, }\DataTypeTok{to=}\DecValTok{1}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{)) ##What will this produce?}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 1.000 1.105 1.221 1.350 1.492 1.649 1.822 2.014
 [9] 2.226 2.460 2.718
\end{verbatim}

Now the mysterious square bracketed numbers appearing next to the output
make sense. R puts the position of the beginning value on a line in
square brackets before the line of output. For example if the output has
40 values, and 15 values appear on each line, then the first line will
have \texttt{{[}1{]}} at the left, the second line will have
\texttt{{[}16{]}} to the left, and the third line will have
\texttt{{[}31{]}} to the left.

\subsection{Basic descriptive statistics and graphics in R}\label{dec}

It is easy to compute basic descriptive statistics and to produce
standard graphical representations of data in R. First we create three
variables with horsepower, miles per gallon, and names for 15
cars.\footnote{These are from a relatively old data set, with 1974 model
  cars.} In this case with a small data set we enter the data ``by
hand'' using the \texttt{c()} function, which concatenates its arguments
into a vector. For larger data sets we will clearly want an alternative.
Note that character values are surrounded by quotation marks.

A style note: R has two widely used methods of assignment: the left
arrow, which consists of a less than sign followed immediately by a
dash: \texttt{\textless{}-} and the equals sign: \texttt{=}. Much ink
has been used debating the relative merits of the two methods, and their
subtle differences. Many leading R style guides (e.g., the Google style
guide at \url{https://google.github.io/styleguide/Rguide.xml} and the
Bioconductor style guide at
\url{http://www.bioconductor.org/developers/how-to/coding-style/})
recommend the left arrow \texttt{\textless{}-} as an assignment
operator, and we will use this throughout the book.

Also you will see that if a command has not been completed but the ENTER
key is pressed, the command prompt changes to a \texttt{+} sign. To get
back to the regular prompt sign, you can either type something to finish
the command (i.e., \texttt{)} or \texttt{{]}}), or you can press your
\texttt{ESC} button and retype the whole command.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{car.hp <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{110}\NormalTok{, }\DecValTok{110}\NormalTok{, }\DecValTok{93}\NormalTok{, }\DecValTok{110}\NormalTok{, }\DecValTok{175}\NormalTok{, }\DecValTok{105}\NormalTok{, }\DecValTok{245}\NormalTok{, }\DecValTok{62}\NormalTok{, }\DecValTok{95}\NormalTok{, }\DecValTok{123}\NormalTok{, }
\OperatorTok{+}\StringTok{ }\DecValTok{123}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{205}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{car.mpg <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{21.0}\NormalTok{, }\FloatTok{21.0}\NormalTok{, }\FloatTok{22.8}\NormalTok{, }\FloatTok{21.4}\NormalTok{, }\FloatTok{18.7}\NormalTok{, }\FloatTok{18.1}\NormalTok{, }\FloatTok{14.3}\NormalTok{, }\FloatTok{24.4}\NormalTok{, }\FloatTok{22.8}\NormalTok{, }
\OperatorTok{+}\StringTok{              }\FloatTok{19.2}\NormalTok{, }\FloatTok{17.8}\NormalTok{, }\FloatTok{16.4}\NormalTok{, }\FloatTok{17.3}\NormalTok{, }\FloatTok{15.2}\NormalTok{, }\FloatTok{10.4}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{car.name <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Mazda RX4"}\NormalTok{, }\StringTok{"Mazda RX4 Wag"}\NormalTok{, }\StringTok{"Datsun 710"}\NormalTok{, }
\OperatorTok{+}\StringTok{               "Hornet 4 Drive"}\NormalTok{, }\StringTok{"Hornet Sportabout"}\NormalTok{, }\StringTok{"Valiant"}\NormalTok{, }
\OperatorTok{+}\StringTok{               "Duster 360"}\NormalTok{, }\StringTok{"Merc 240D"}\NormalTok{, }\StringTok{"Merc 230"}\NormalTok{, }\StringTok{"Merc 280"}\NormalTok{, }
\OperatorTok{+}\StringTok{               "Merc 280C"}\NormalTok{, }\StringTok{"Merc 450SE"}\NormalTok{, }\StringTok{"Merc 450SL"}\NormalTok{, }
\OperatorTok{+}\StringTok{               "Merc 450SLC"}\NormalTok{, }\StringTok{"Cadillac Fleetwood"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{car.hp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 110 110  93 110 175 105 245  62  95 123 123 180
[13] 180 180 205
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{car.mpg}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2
[11] 17.8 16.4 17.3 15.2 10.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{car.name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "Mazda RX4"          "Mazda RX4 Wag"     
 [3] "Datsun 710"         "Hornet 4 Drive"    
 [5] "Hornet Sportabout"  "Valiant"           
 [7] "Duster 360"         "Merc 240D"         
 [9] "Merc 230"           "Merc 280"          
[11] "Merc 280C"          "Merc 450SE"        
[13] "Merc 450SL"         "Merc 450SLC"       
[15] "Cadillac Fleetwood"
\end{verbatim}

Next we compute some descriptive statistics for the two numeric
variables (\texttt{car.hp} and \texttt{car.mpg})

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(car.hp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 139.7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sd}\NormalTok{(car.hp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 50.78
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{summary}\NormalTok{(car.hp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
     62     108     123     140     180     245 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(car.mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 18.72
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sd}\NormalTok{(car.mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.714
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{summary}\NormalTok{(car.mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   10.4    16.9    18.7    18.7    21.2    24.4 
\end{verbatim}

Next, a scatter plot of \texttt{cars.mpg} versus \texttt{cars.hp}:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(car.hp, car.mpg)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-8-1.pdf}

Unsurprisingly as horsepower increases, mpg tends to decrease. This
relationship can be investigated further using linear regression, a
statistical procedure that involves fitting a linear model to a data set
in order to further understand the relationship between two variables.

\subsection{An Initial Tour of
RStudio}\label{an-initial-tour-of-rstudio}

When you created the \texttt{car.hp} and other vectors in the previous
section, you might have noticed the vector name and a short description
of its attributes appear in the top right \texttt{Global\ Environment}
window. Similarly, when you called \texttt{plot(car.hp,car.mpg)} the
corresponding plot appeared in the lower right \texttt{Plots} window.

A comprehensive, but slightly overwhelming, cheatsheet for RStudio is
available here
\url{https://www.rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf}.
As we progress in learning R and RStudio, this cheatsheet will become
more useful. For now you might use the cheatsheet to locate the various
windows and functions identified in the coming chapters.

\subsection{Practice Problem}\label{practice-problem}

When running a large program consisting of numerous lines of complicated
code, it is often basic algebraic typos that lead to the most
frustrating bugs. Having a good grip on the order of operations is a
basic, yet very important skill for writing good code. To practice,
compute the following operation in R.

\[
\frac{(e^{14} + \text{log}_{10}(8)) \times \sqrt{5}}{\text{log}_{e}(4) - 5 * 10^2}
\]

\section{Getting Help}\label{getting-help}

There are several free (and several not free) ways to get R help when
needed.

Several help-related functions are built into R. If there's a particular
R function of interest, such as \texttt{log}, \texttt{help(log)} or
\texttt{?log} will bring up a help page for that function. In RStudio
the help page is displayed, by default, in the \texttt{Help} tab in the
lower right window.\footnote{There are ways to change this default
  behavior.} The function \texttt{help.start} opens a window which
allows browsing of the online documentation included with R. To use
this, type \texttt{help.start()} in the console window.\footnote{You may
  wonder about the parentheses after \texttt{help.start}. A user can
  specify arguments to any R function inside parentheses. For example
  \texttt{log(10)} asks R to return the logarithm of the argument 10.
  Even if no arguments are needed, R requires empty parentheses at the
  end of any function name. In fact if you just type the function name
  without parentheses, R returns the definition of the function. For
  simple functions this can be illuminating.} The \texttt{help.start}
function also provides several manuals online and can be a useful
interface in addition to the built in help.

Search engines provide another, sometimes more user-friendly, way to
receive answers for R questions. A Google search often quickly finds
something written by another user who had the same (or a similar)
question, or an online tutorial that touches on the question. More
specialized is \href{http://rseek.org}{rseek.org}, which is a search
engine focused specifically on R. Both Google and
\href{http://rseek.org}{rseek.org} are valuable tools, often providing
more user-friendly information than R's own help system.

In addition, R users have written many types of contributed
documentation. Some of this documentation is available at
\url{http://cran.r-project.org/other-docs.html}. Of course there are
also numerous books covering general and specialized R topics available
for purchase.

\section{Workspace, Working Directory, and Keeping
Organized}\label{workspace-working-directory-and-keeping-organized}

The \emph{workspace} is your R session working environment and includes
any objects you create. Recall these objects are listed in the
\texttt{Global\ Environment} window. The command \texttt{ls()}, which
stands for list, will also list all the objects in your workspace (note,
this is the same list that is given in the \texttt{Global\ Environment}
window). When you close RStudio, a dialog box will ask you if you want
to save an image of the current workspace. If you choose to save your
workspace, RStudio saves your session objects and information in a
\texttt{.RData} file (the period makes it a hidden file) in your
\emph{working directory}. Next time you start R or RStudio it checks if
there is a \texttt{.RData} in the working directory, loads it if it
exists, and your session continues where you left off. Otherwise R
starts with an empty workspace. This leads to the next question---what
is a working directory?

Each R session is associated with a working directory. This is just a
directory from which R reads and writes files, e.g., the \texttt{.RData}
file, data files you want to analyze, or files you want to save. On Mac
when you start RStudio it sets the working directory to your home
directory (for me that's \texttt{/Users/andy}). If you're on a different
operating system, you can check where the default working directory is
by typing \texttt{getwd()} in the console. You can change the default
working directory under RStudio's \verb+Global Option+ dialog found
under the \texttt{Tools} dropdown menu. There are multiple ways to
change the working directory once an R session is started in RStudio.
One method is to click on the \texttt{Files} tab in the lower right
window and then click the \texttt{More} button. Alternatively, you can
set the session's working directory using the \texttt{setwd()} in the
console. For example, on Windows
\texttt{setwd("C:/Users/andy/for875/exercise1")} will set the working
directory to \texttt{C:/Users/andy/for875/exercise1}, assuming that file
path and directory exist (Note: Windows file path uses a backslash,
\texttt{\textbackslash{}}, but in R the backslash is an escape
character, hence specifying file paths in R on Windows uses the forward
slash, i.e., \texttt{/}). Similarly on Mac you can use
\texttt{setwd("/Users/andy/for875/exercise1")}. Perhaps the most simple
method is to click on the \texttt{Session} tab at the top of your screen
and click on the \texttt{Set\ Working\ Directory} option. Later on when
we start reading and writing data from our R session, it will be very
important that you are able to identify your current working directory
and change it if needed. We will revisit this in subsequent chapters.

As with all work, keeping organized is the key to efficiency. It is good
practice to have a dedicated directory for each R project or exercise.

\section{Quality of R code}\label{quality-of-r-code}

\begin{figure}
\includegraphics[width=1\linewidth]{../figures/code_quality} \caption{xkcd: Code Quality}\label{fig:comic}
\end{figure}

Writing well-organized and well-labeled code allows your code to be more
easily read and understood by another person. (See xkcd's take on code
quality in Figure \ref{fig:comic}.) More importantly, though, your
well-written code is more accessible to you hours, days, or even months
later. We are hoping that you can use the code you write in this class
in future projects and research.

Google provides style guides for many programming languages. You can
find the R style guide
\href{https://google.github.io/styleguide/Rguide.xml}{here}. Below are a
few of the key points from the guide that we will use right away.

\subsection{Naming Files}\label{naming-files}

File names should be meaningful and end in \texttt{.R}. If we write a
script that analyzes a certain species distribution:

\begin{itemize}
\tightlist
\item
  GOOD: \(\color{green}{\verb+african_rhino_distribution.R+}\)
\item
  GOOD: \(\color{green}{\verb+africanRhinoDistribution.R+}\)
\item
  BAD: \(\color{red}{\verb+speciesDist.R+}\) (too ambiguous)
\item
  BAD: \(\color{red}{\verb+species.dist.R+}\) (too ambiguous and two
  periods can confuse operating systems' file type auto-detect)
\item
  BAD: \(\color{red}{\verb+speciesdist.R+}\) (too ambiguous and
  confusing)
\end{itemize}

\subsection{Naming Variables}\label{naming-variables}

\begin{itemize}
\tightlist
\item
  GOOD: \(\color{green}{\verb+rhino.count+}\)
\item
  GOOD: \(\color{green}{\verb+rhinoCount+}\)
\item
  GOOD: \(\color{green}{\verb+rhino_count+}\) (We don't mind the
  underscore and use it quite often, although Google's style guide says
  it's a no-no for some reason)
\item
  BAD: \(\color{red}{\verb+rhinocount+}\) (confusing)
\end{itemize}

\subsection{Syntax}\label{syntax}

\begin{itemize}
\tightlist
\item
  Keep code lines under 80 characters long.
\item
  Indent your code with two spaces. (RStudio does this by default when
  you press the TAB key.)
\end{itemize}

\chapter{Scripts and R Markdown}\label{scripts-and-r-markdown}

Doing work in data science, whether for homework, a project for a
business, or a research project, typically involves several iterations.
For example creating an effective graphical representation of data can
involve trying out several different graphical representations, and then
tens if not hundreds of iterations when fine-tuning the chosen
representation. Furthermore, each of these representations may require
several R commands to create. Although this all could be accomplished by
typing and re-typing commands at the R Console, it is easier and more
effective to write the commands in a \emph{script file}, which then can
be submitted to the R console either a line at a time or all
together.\footnote{Unsurprisingly it is also possible to submit several
  selected lines of code at once.}

In addition to making the workflow more efficient, R scripts provide
another large benefit. Often we work on one part of a homework
assignment or project for a few hours, then move on to something else,
and then return to the original part a few days, months, or sometimes
even years later. In such cases we may have forgotten how we created the
graphical display that we were so proud of, and will need to again spend
a few hours to recreate it. If we save a script file, we have the
ingredients immediately available when we return to a portion of a
project.\footnote{In principle the R history mechanism provides a
  similar record. But with history we have to search through a lot of
  other code to find what we're looking for, and scripts are a much
  cleaner mechanism to record our work.}

Next consider the larger scientific endeavor. Ideally a scientific study
will be reproducible, meaning that an independent group of researchers
(or the original researchers) will be able to duplicate the study.
Thinking about data science, this means that all the steps taken when
working with the data from a study should be reproducible, from the
selection of variables to formal data analysis. In principle, this can
be facilitated by explaining, in words, each step of the work with data.
In practice, it is typically difficult or impossible to reproduce a full
data analysis based on a written explanation. Much more effective is to
include the actual computer code which accomplished the data work in the
report, whether the report is a homework assignment or a research paper.
Tools in R such as \emph{R Markdown} facilitate this process.

\section{Scripts in R}\label{scripts-in-r}

As noted above, scripts help to make work with data more efficient and
provide a record of how data were managed and analyzed. Below we
describe an example. This example uses features of R that we have not
yet discussed, so don't worry about the details, but rather about how it
motivates the use of a script file.

First we read in a data set containing data on (among other things)
fertility rate and life expectancy for countries throughout the world,
for the years 1960 through 2014.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/WorldBank.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{WorldBank <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{stringsAsFactors=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next we print the names of the variables in the data set. Don't be
concerned about the specific details. Later we will learn much more
about reading in data and working with data sets in R.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(WorldBank)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "iso2c"                       
 [2] "country"                     
 [3] "year"                        
 [4] "fertility.rate"              
 [5] "life.expectancy"             
 [6] "population"                  
 [7] "GDP.per.capita.Current.USD"  
 [8] "X15.to.25.yr.female.literacy"
 [9] "iso3c"                       
[10] "region"                      
[11] "capital"                     
[12] "longitude"                   
[13] "latitude"                    
[14] "income"                      
[15] "lending"                     
\end{verbatim}

We will try to create a scatter plot of fertility rate versus life
expectancy of countries for the year 1960. To do this we'll first create
variables containing the values of fertility rate and life expectancy
for 1960\footnote{This isn't necessary, but it is convenient}, and print
out the first ten values of each variable.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{fertility <-}\StringTok{ }\NormalTok{WorldBank}\OperatorTok{$}\NormalTok{fertility.rate[WorldBank}\OperatorTok{$}\NormalTok{year }\OperatorTok{==}\StringTok{ }\DecValTok{1960}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{lifeexp <-}\StringTok{ }\NormalTok{WorldBank}\OperatorTok{$}\NormalTok{life.expectancy[WorldBank}\OperatorTok{$}\NormalTok{year}\OperatorTok{==}\DecValTok{1960}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{fertility[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]    NA 6.928 7.671 4.425 6.186 4.550 7.316 3.109
 [9]    NA 2.690
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{lifeexp[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]    NA 52.24 31.58 61.78 62.25 65.86 32.98 65.22
 [9]    NA 68.59
\end{verbatim}

We see that some countries do not have data for 1960. R represents
missing data via \texttt{NA}. Of course at some point it would be good
to investigate which countries' data are missing and why. The
\texttt{plot()} function in R will just omit missing values, and for now
we will just plot the non-missing data. A scatter plot of the data is
drawn next.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(lifeexp, fertility)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-13-1.pdf}

The scatter plot shows that as life expectancy increases, fertility rate
tends to decrease in what appears to be a nonlinear relationship. Now
that we have a basic scatter plot, it is tempting to make it more
informative. We will do this by adding two features. One is to make the
points' size proportional to the country's population, and the second is
to make the points' color represent the region of the world the country
resides in. We'll first extract the population and region variables for
1960.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{pop <-}\StringTok{ }\NormalTok{WorldBank}\OperatorTok{$}\NormalTok{population[WorldBank}\OperatorTok{$}\NormalTok{year}\OperatorTok{==}\DecValTok{1960}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{region <-}\StringTok{ }\NormalTok{WorldBank}\OperatorTok{$}\NormalTok{region[WorldBank}\OperatorTok{$}\NormalTok{year}\OperatorTok{==}\DecValTok{1960}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{pop[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]    13414    89608  8774440    54681  1608800
 [6]  1867396  4965988 20623998    20012  7047539
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{region[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "Europe & Central Asia (all income levels)"     
 [2] "Middle East & North Africa (all income levels)"
 [3] "South Asia"                                    
 [4] "Latin America & Caribbean (all income levels)" 
 [5] "Europe & Central Asia (all income levels)"     
 [6] "Europe & Central Asia (all income levels)"     
 [7] "Sub-Saharan Africa (all income levels)"        
 [8] "Latin America & Caribbean (all income levels)" 
 [9] "East Asia & Pacific (all income levels)"       
[10] "Europe & Central Asia (all income levels)"     
\end{verbatim}

To create the scatter plot we will do two things. First we will create
the axes, labels, etc. for the plot, but not plot the points. The
argument \texttt{type="n"} tells R to do this. Then we will use the
\texttt{symbols()} function to add symbols, the \texttt{circles}
argument to set the sizes of the points, and the \texttt{bg} argument to
set the colors. Don't worry about the details! In fact, later in the
book we will learn about an R package called \texttt{ggplot2} that
provides a different way to create such plots. You'll see two plots
below, first the ``empty'' plot which is just a building block, then the
plot including the appropriate symbols.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(lifeexp, fertility, }\DataTypeTok{type=}\StringTok{"n"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-15-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{symbols}\NormalTok{(lifeexp, fertility, }\DataTypeTok{circles=}\KeywordTok{sqrt}\NormalTok{(pop}\OperatorTok{/}\NormalTok{pi), }\DataTypeTok{inches=}\FloatTok{0.35}\NormalTok{, }
\OperatorTok{+}\StringTok{         }\DataTypeTok{bg=}\KeywordTok{match}\NormalTok{(region, }\KeywordTok{unique}\NormalTok{(region)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-15-2.pdf}

Of course we should have a key which tells the viewer which region each
color represents, and a way to determine which country each point
represents, and a lot of other refinements. For now we will resist such
temptations.

Some of the process leading to the completed plot is shown above, such
as reading in the data, creating variables representing the 1960
fertility rate and life expectancy, an intermediate plot that was
rejected, and so on. A lot of the process isn't shown, simply to save
space. There would likely be mistakes (either minor typing mistakes or
more complex errors). Focusing only on the \texttt{symbols()} function
that was used to add the colorful symbols to the scatter plot, there
would likely have been a substantial number of attempts with different
values of the \texttt{circles}, \texttt{inches}, and \texttt{bg}
arguments before settling on the actual form used to create the plot.
This is the typical process you will soon discover when producing useful
data visualizations.

Now imagine trying to recreate the plot a few days later. Possibly
someone saw the plot and commented that it would be interesting to see
some similar plots, but for years in the 1970s when there were major
famines in different countries of the world. If all the work, including
all the false starts and refinements, were done at the console, it would
be hard to sort things out and would take longer than necessary to
create the new plots. This would be especially true if a few months had
passed rather than just a few days.

But with a script file, especially a script file with a few well-chosen
comments, creating the new scatter plots would be much easier.
Fortunately it is quite easy to create and work with script files in
RStudio.\footnote{It is also easy in R without RStudio. Just use
  \texttt{File\ \textgreater{}\ New\ script} to create a script file,
  and save it before exiting R.} Just choose
\texttt{File\ \textgreater{}\ New\ File\ \textgreater{}\ R\ script} and
a script window will open up in the upper left of the full RStudio
window.

An example of a script window (with some R code already typed in) is
shown in Figure \ref{fig:script}. From the script window the user can,
among other things, save the script (either using the \texttt{File} menu
or the icon near the top left of the window) and run one or more lines
of code from the window (using the \texttt{run} icon in the window, or
by copying and pasting into the console window). In addition, there is a
\texttt{Source\ on\ Save} checkbox. If this is checked, the R code in
the script window is automatically read into R and executed when the
script file is saved.

\begin{figure}
\includegraphics[width=1\linewidth]{../figures/ScriptWindow} \caption{A script window in RStudio}\label{fig:script}
\end{figure}

\section{R Markdown}\label{r-markdown}

People typically work on data with a larger purpose in mind. Possibly
the purpose is to understand a biological system more clearly. Possibly
the purpose is to refine a system that recommends movies to users in an
online streaming movie service. Possibly the purpose is to complete a
homework assignment and demonstrate to the instructor an understanding
of an aspect of data analysis. Whatever the purpose, a key aspect is
communicating with the desired audience.

One possibility, which is somewhat effective, is to write a document
using software such as Microsoft Word \footnote{Or possibly LaTeX if the
  document is more technical} and to include R output such as
computations and graphics by cutting and pasting into the main document.
One drawback to this approach is similar to what makes script files so
useful: If the document must be revised it may be hard to unearth the R
code that created graphics or analyses, to revise these.\footnote{Organizing
  the R code using script files and keeping all the work organized in a
  well-thought-out directory structure can help here, but this requires
  a level of forethought and organization that most people do not
  possess \(\ldots\) including myself.} A more subtle but possibly more
important drawback is that the reader of the document will not know
precisely how analyses were done, or how graphics were created. Over
time even the author(s) of the paper will forget the details. A verbal
description in a ``methods'' section of a paper can help here, but
typically these do not provide all the details of the analysis, but
rather might state something like, ``All analyses were carried out using
R version 3.3.1.''

RStudio's website provides an excellent overview of R Markdown
capabilities for reproducible research. At minimum, follow the
\texttt{Get\ Started} link at \url{http://rmarkdown.rstudio.com/} and
watch the introduction video.

Among other things, R Markdown provides a way to include R code that
read in data, create graphics, or perform analyses, all in a single
document that is processed to create a research paper, homework
assignment, or other written product. The R Markdown file is a plain
text file containing text the author wants to show in the final
document, simple commands to indicate how the text should be formatted
(for example boldface, italic, or a bulleted list), and R code that
creates output (including graphics) on the fly. Perhaps the simplest way
to get started is to see an R Markdown file and the resulting document
that is produced after the R Markdown document is processed. In Figure
\ref{fig:rmark} we show the input and output of an example R Markdown
document. In this case the output created is an HTML file, but there are
other possible output formats, such as Microsoft Word or PDF.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/rmarkdownInputOutput} 

}

\caption{Example R Markdown Input and Output}\label{fig:rmark}
\end{figure}

At the top of the input R Markdown file are some lines with
\texttt{-\/-\/-} at the top and the bottom. These lines are not needed,
but give a convenient way to specify the title, author, and date of the
article that are then typeset prominently at the top of the output
document. For now, don't be concerned with the lines following
\texttt{output:}. These can be omitted (or included as shown).

Next are a few lines showing some of the ways that font effects such as
italics, boldface, and strikethrough can be achieved. For example, an
asterisk before and after text sets the text in \emph{italics}, and two
asterisks before and after text sets the text in \textbf{boldface}.

More important for our purposes is the ability to include R code in the
R Markdown file, which will be executed with the output appearing in the
output document. Bits of R code included this way are called \emph{code
chunks}. The beginning of a code chunk is indicated with three backticks
and an ``r'' in curly braces:
\texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}. The
end of a code chunk is indicated with three backticks
\texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}}. For
example, the R Markdown file in Figure \ref{fig:rmark} has one code
chunk:

\begin{Shaded}
\begin{Highlighting}[]
\StringTok{```}\DataTypeTok{\{r\}}
\DataTypeTok{x = 1:10}
\DataTypeTok{y = 10:1}
\DataTypeTok{mean(x)}
\DataTypeTok{sd(y)}
\StringTok{```}
\end{Highlighting}
\end{Shaded}

In this code chunk two vectors \texttt{x} and \texttt{y} are created,
and the mean of \texttt{x} and the standard deviation of \texttt{y} are
computed. In the output in Figure \ref{fig:rmark} the R code is
reproduced, and the output of the two lines of code asking for the mean
and standard deviation is shown.

\subsection{Creating and processing R Markdown
documents}\label{creating-and-processing-r-markdown-documents}

RStudio has features which facilitate creating and processing R Markdown
documents. Choose
\texttt{File\ \textgreater{}\ New\ File\ \textgreater{}\ R\ \ Markdown...}.
In the ensuing dialog box, make sure that \texttt{Document} is
highlighted on the left, enter the title and author (if desired), and
choose the Default Output Format (HTML is good to begin). Then click OK.
A document will appear in the upper left of the RStudio window. It is an
R Markdown document, and the title and author you chose will show up,
delimited by \texttt{-\/-\/-} at the top of the document. A generic body
of the document will also be included.

For now just keep this generic document as is. To process it to create
the HTML output, click the \texttt{Knit\ HTML} button at the top of the
R Markdown window\footnote{If you hover your mouse over this Knit button
  after a couple seconds it should display a keyboard shortcut for you
  to do this if you don't like pushing buttons}. You'll be prompted to
choose a filename for the R Markdown file. Make sure that you use
\texttt{.Rmd} as the extension for this file. Once you've successfully
saved the file, RStudio will process the file, create the HTML output,
and open this output in a new window. The HTML output file will also be
saved to your working directory. This file can be shared with others,
who can open it using a web browser such as Chrome or Firefox.

There are many options which allow customization of R Markdown
documents. Some of these affect formatting of text in the document,
while others affect how R code is evaluated and displayed. The RStudio
web site contains a useful summary of many R Markdown options at
\url{https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf}.
A different, but mind-numbingly busy, cheatsheet is at
\url{https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf}.
Some of the more commonly used R Markdown options are described next.

\subsection{Text: Lists and Headers}\label{text-lists-and-headers}

Unordered (sometimes called bulleted) lists and ordered lists are easy
in R Markdown. Figure \ref{fig:lists} illustrates the creation of
unordered and ordered lists.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/listsPic} 

}

\caption{Producing Lists in R Markdown}\label{fig:lists}
\end{figure}

\begin{itemize}
\item
  For an unordered list, either an asterisk, a plus sign, or a minus
  sign may precede list items. Use a space after these symbols before
  including the list text. To have second-level items (sub-lists) indent
  four spaces before indicating the list item. This can also be done for
  third-level items.
\item
  For an ordered list use a numeral followed by a period and a space (1.
  or 2. or 3. or \ldots{}) to indicate a numbered list, and use a letter
  followed by a period and a space (a. or b. or c. or \ldots{}) to
  indicate a lettered list. The same four space convention used in
  unordered lists is used to designate ordered sub lists.
\item
  For an ordered list, the first list item will be labeled with the
  number or letter that you specify, but subsequent list items will be
  numbered sequentially. The example in Figure \ref{fig:lists} will make
  this more clear. In those examples notice that for the ordered list,
  although the first-level numbers given in the R Markdown file are 1,
  2, and 17, the numbers printed in the output are 1, 2, and 3.
  Similarly the letters given in the R Markdown file are c and q, but
  the output file prints c and d.
\end{itemize}

R Markdown does not give substantial control over font size. Different
``header'' levels are available that provide different font sizes. Put
one or more hash marks in front of text to specify different header
levels. Other font choices such as subscripts and superscripts are
possible, by surrounding the text either by tildes or carets. More
sophisticated mathematical displays are also possible, and are
surrounded by dollar signs. The actual mathematical expressions are
specified using a language called LaTeX See Figures \ref{fig:headers}
and \ref{fig:latex} for examples.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/headersAndLatex} 

}

\caption{Headers and Some LaTeX in R Markdown}\label{fig:headers}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/latex} 

}

\caption{Other useful LaTeX symbols and expressions in R Markdown}\label{fig:latex}
\end{figure}

\subsection{Code Chunks}\label{code-chunks}

R Markdown provides a large number of options to vary the behavior of
code chunks. In some contexts it is useful to display the output but not
the R code leading to the output. In some contexts it is useful to
display the R prompt, while in others it is not. Maybe we want to change
the size of figures created by graphics commands. And so on. A large
number of code chunk options are described in
\url{http://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf}.

Code chunk options are specified in the curly braces near the beginning
of a code chunk. Below are a few of the more commonly used options are
described. The use of these options is illustrated in Figure
\ref{fig:chunk}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \texttt{echo=FALSE} specifies that the R code itself should not be
  printed, but any output of the R code should be printed in the
  resulting document.
\item
  \texttt{include=FALSE} specifies that neither the R code nor the
  output should be printed. However, the objects created by the code
  chunk will be available for use in later code chunks.
\item
  \texttt{eval=FALSE} specifies that the R code should not be evaluated.
  The code will be printed unless, for example, \texttt{echo=FALSE} is
  also given as an option.
\item
  \texttt{error=FALSE} and \texttt{warning=FALSE} specify that,
  respectively, error messages and warning messages generated by the R
  code should not be printed.
\item
  The \texttt{comment} option allows a specified character string to be
  prepended to each line of results. By default this is set to
  \texttt{comment\ =\ \textquotesingle{}\#\#\textquotesingle{}} which
  explains the two hash marks preceding the results in Figure
  \ref{fig:rmark}. Setting \texttt{comment\ =\ NA} presents output
  without any character string prepended. That is done in most code
  chunks in this book.
\item
  \texttt{prompt=TRUE} specifies that the R prompt
  \texttt{\textgreater{}} will be prepended to each line of R code shown
  in the document. \texttt{prompt\ =\ FALSE} specifies that command
  prompts should not be included.
\item
  \texttt{fig.height} and \texttt{fig.width} specify the height and
  width of figures generated by R code. These are specified in inches.
  For example, \texttt{fig.height=4} specifies a four inch high figure.
\end{enumerate}

Figures \ref{fig:chunk} gives examples of the use of code chunk options.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{../figures/chunks1} \includegraphics[width=0.5\linewidth]{../figures/chunks2} 

}

\caption{Output of Example R Markdown}\label{fig:chunk}
\end{figure}

\subsection{Output formats other than
HTML}\label{output-formats-other-than-html}

It is possible to use R Markdown to produce documents in formats other
than HTML, including Word and PDF documents. Next to the
\texttt{Knit\ HTML} button is a down arrow. Click on this and choose
\texttt{Knit\ Word} to produce a Microsoft word output document.
Although there is also a \texttt{Knit\ PDF} button, PDF output requires
additional software called TeX in addition to RStudio.\footnote{It isn't
  particularly hard to install TeX software. For a Microsoft Windows
  system, MiKTeX is convenient and is available from
  \url{https://miktex.org}. For a Mac system, MacTeX is available from
  \url{https://www.tug.org/mactex/}}

\subsection{\texorpdfstring{LaTeX, \texttt{knitr}, and
\texttt{bookdown}}{LaTeX, knitr, and bookdown}}\label{latex-knitr-and-bookdown}

While basic R Markdown provides substantial flexibility and power, it
lacks features such as cross-referencing, fine control over fonts, etc.
If this is desired, a variant of R Markdown called \texttt{knitr}, which
has very similar syntax to R Markdown for code chunks, can be used in
conjunction with the typesetting system LaTeX to produce documents.
Another option is to use the R package \texttt{bookdown} which uses R
Markdown syntax and some additional features to allow for writing more
technical documents. In fact this book was initially created using
\texttt{knitr} and LaTeX, but the simplicity of markdown syntax and the
additional intricacies provided by the \texttt{bookdown} package
convinced us to write the book in R Markdown using \texttt{bookdown}.
For simpler tasks, basic R Markdown is plenty sufficient, and very easy
to use.

\section{Exercises}\label{exercises}

\textbf{Exercise 1} Learning objectives: practice setting up a working
directory and read in data; explore the workspace within RStudio and
associated commands; produce basic descriptive statistics and graphics.

\textbf{Exercise 2} Learning objectives: practice working within
RStudio; create a R Markdown document and resulting html document in
RStudio; calculate descriptive statistics and produce graphics.

\chapter{Data Structures}\label{structures}

A data structure is a format for organizing and storing data. The
structure is designed so that data can be accessed and worked with in
specific ways. Statistical software and programming languages have
methods (or functions) designed to operate on different kinds of data
structures.

This chapter's focus is on data structures. To help initial
understanding, the data in this chapter will be relatively modest in
size and complexity. The ideas and methods, however, generalize to
larger and more complex data sets.

The base data structures in R are vectors, matrices, arrays, data
frames, and lists. The first three, vectors, matrices, and arrays,
require all elements to be of the same type or homogeneous, e.g., all
numeric or all character. Data frames and lists allow elements to be of
different types or heterogeneous, e.g., some elements of a data frame
may be numeric while other elements may be character. These base
structures can also be organized by their dimensionality, i.e.,
1-dimensional, 2-dimensional, or N-dimensional, as shown in Table
\ref{tab:dataStructures}.

\begin{table}[t]

\caption{\label{tab:dataStructures}Dimension and type content of base data structures
  in R}
\centering
\begin{tabular}{lll}
\toprule
Dimension & Homogeneous & Heterogeneous\\
\midrule
1 & Atomic vector & List\\
2 & Matrix & Data frame\\
N & Array & \\
\bottomrule
\end{tabular}
\end{table}

R has no scalar types, i.e., 0-dimensional. Individual numbers or
strings are actually vectors of length one.

An efficient way to understand what comprises a given object is to use
the \texttt{str()} function. \texttt{str()} is short for structure and
prints a compact, human-readable description of any R data structure.
For example, in the code below, we prove to ourselves that what we might
think of as a scalar value is actually a vector of length one.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{a <-}\StringTok{ }\DecValTok{1}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 num 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.vector}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

Here we assigned \texttt{a} the scalar value one. The \texttt{str(a)}
prints \texttt{num\ 1}, which says \texttt{a} is numeric of length one.
Then just to be sure we used the function \texttt{is.vector()} to test
if \texttt{a} is in fact a vector. Then, just for fun, we asked the
length of \texttt{a}, which again returns one. There are a set of
similar logical tests for the other base data structures, e.g.,
\texttt{is.matrix()}, \texttt{is.array()}, \texttt{is.data.frame()}, and
\texttt{is.list()}. These will all come in handy as we encounter
different R objects.

\section{Vectors}\label{vector}

Think of a vector\footnote{Technically the objects described in this
  section are ``atomic'' vectors (all elements of the same type), since
  lists, to be described below, also are actually vectors. This will not
  be an important issue, and the shorter term vector will be used for
  atomic vectors below.} as a structure to represent one variable in a
data set. For example a vector might hold the weights, in pounds, of 7
people in a data set. Or another vector might hold the genders of those
7 people. The \texttt{c()} function in R is useful for creating (small)
vectors and for modifying existing vectors. Think of \texttt{c} as
standing for ``combine''.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{123}\NormalTok{, }\DecValTok{157}\NormalTok{, }\DecValTok{205}\NormalTok{, }\DecValTok{199}\NormalTok{, }\DecValTok{223}\NormalTok{, }\DecValTok{140}\NormalTok{, }\DecValTok{105}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 205 199 223 140 105
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"female"}\NormalTok{, }\StringTok{"female"}\NormalTok{, }\StringTok{"male"}\NormalTok{, }\StringTok{"female"}\NormalTok{, }\StringTok{"male"}\NormalTok{,}
\OperatorTok{+}\StringTok{             "male"}\NormalTok{, }\StringTok{"female"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{gender}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "female" "female" "male"   "female" "male"  
[6] "male"   "female"
\end{verbatim}

Notice that elements of a vector are separated by commas when using the
\texttt{c()} function to create a vector. Also notice that character
values are placed inside quotation marks.

The \texttt{c()} function also can be used to add to an existing vector.
For example, if an eighth male person was included in the data set, and
his weight was 194 pounds, the existing vectors could be modified as
follows.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight <-}\StringTok{ }\KeywordTok{c}\NormalTok{(weight, }\DecValTok{194}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{gender <-}\StringTok{ }\KeywordTok{c}\NormalTok{(gender, }\StringTok{"male"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 205 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "female" "female" "male"   "female" "male"  
[6] "male"   "female" "male"  
\end{verbatim}

\subsection{Types, Conversion,
Coercion}\label{types-conversion-coercion}

Clearly it is important to distinguish between different types of
vectors. For example, it makes sense to ask R to calculate the mean of
the weights stored in \texttt{weight}, but does not make sense to ask R
to compute the mean of the genders stored in \texttt{gender}. Vectors in
R may have one of six different ``types'': character, double, integer,
logical, complex, and raw. Only the first four of these will be of
interest below, and the distinction between double and integer will not
be of great import. To illustrate logical vectors, imagine that each of
the eight people in the data set was asked whether he or she was taking
blood pressure medication, and the responses were coded as \texttt{TRUE}
if the person answered yes, and \texttt{FALSE} if the person answered
no.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{typeof}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "double"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{typeof}\NormalTok{(gender)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "character"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{bp <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{bp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE  TRUE FALSE FALSE  TRUE FALSE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{typeof}\NormalTok{(bp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "logical"
\end{verbatim}

It may be surprising to see that the variable \texttt{weight} is of
\texttt{double} type, even though its values all are integers. By
default R creates a double type vector when numeric values are given via
the \texttt{c()} function.

When it makes sense, it is possible to convert vectors to a different
type. Consider the following examples.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight.int <-}\StringTok{ }\KeywordTok{as.integer}\NormalTok{(weight)}
\OperatorTok{>}\StringTok{ }\NormalTok{weight.int}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 205 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{typeof}\NormalTok{(weight.int)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "integer"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight.char <-}\StringTok{ }\KeywordTok{as.character}\NormalTok{(weight)}
\OperatorTok{>}\StringTok{ }\NormalTok{weight.char}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "123" "157" "205" "199" "223" "140" "105" "194"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{bp.double <-}\StringTok{ }\KeywordTok{as.double}\NormalTok{(bp)}
\OperatorTok{>}\StringTok{ }\NormalTok{bp.double}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0 1 0 0 1 0 1 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender.oops <-}\StringTok{ }\KeywordTok{as.double}\NormalTok{(gender)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: NAs introduced by coercion
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender.oops}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NA NA NA NA NA NA NA NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sum}\NormalTok{(bp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3
\end{verbatim}

The integer version of \texttt{weight} doesn't look any different, but
it is stored differently, which can be important both for computational
efficiency and for interfacing with other languages such as
\texttt{C++}. As noted above, however, we will not worry about the
distinction between integer and double types. Converting \texttt{weight}
to character goes as expected: The character representations of the
numbers replace the numbers themselves. Converting the logical vector
\texttt{bp} to double is pretty straightforward too: \texttt{FALSE} is
converted to zero, and \texttt{TRUE} is converted to one. Now think
about converting the character vector \texttt{gender} to a numeric
double vector. It's not at all clear how to represent ``female'' and
``male'' as numbers. In fact in this case what R does is to create a
character vector, but with each element set to \texttt{NA}, which is the
representation of missing data.\footnote{Missing data will be discussed
  in more detail later in the chapter.} Finally consider the code
\texttt{sum(bp)}. Now \texttt{bp} is a logical vector, but when R sees
that we are asking to sum this logical vector, it automatically converts
it to a numerical vector and then adds the zeros and ones representing
\texttt{FALSE} and \texttt{TRUE}.

R also has functions to test whether a vector is of a particular type.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.double}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.character}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.integer}\NormalTok{(weight.int)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.logical}\NormalTok{(bp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\subsubsection{Coercion}\label{coercion}

Consider the following examples.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{xx <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{xx}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 3 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{yy <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"dog"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{yy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "1"   "2"   "3"   "dog"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{zz <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\StringTok{"cat"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{zz}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "TRUE"  "FALSE" "cat"  
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight}\OperatorTok{+}\NormalTok{bp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 158 205 199 224 140 106 194
\end{verbatim}

Vectors in R can only contain elements of one type. If more than one
type is included in a \texttt{c()} function, R silently \emph{coerces}
the vector to be of one type. The examples illustrate the hierarchy---if
any element is a character, then the whole vector is character. If some
elements are numeric (either integer or double) and other elements are
logical, the whole vector is numeric. Note what happened when R was
asked to add the numeric vector \texttt{weight} to the logical vector
\texttt{bp}. The logical vector was silently coerced to be numeric, so
that FALSE became zero and TRUE became one, and then the two numeric
vectors were added.

\subsection{Accessing Specific Elements of
Vectors}\label{accessing-specific-elements-of-vectors}

To access and possibly change specific elements of vectors, refer to the
position of the element in square brackets. For example,
\texttt{weight{[}4{]}} refers to the fourth element of the vector
\texttt{weight}. Note that R starts the numbering of elements at 1,
i.e., the first element of a vector \texttt{x} is \texttt{x{[}1{]}}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 205 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 223
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 205
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(weight)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\KeywordTok{length}\NormalTok{(weight)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 205 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\DecValTok{202}
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

Note that including nothing in the square brackets results in the whole
vector being returned.

Negative numbers in the square brackets tell R to omit the corresponding
value. And a zero as a subscript returns nothing (more precisely, it
returns a length zero vector of the appropriate type).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\OperatorTok{-}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\OperatorTok{-}\KeywordTok{length}\NormalTok{(weight)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{lessWeight <-}\StringTok{ }\NormalTok{weight[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{)]}
\OperatorTok{>}\StringTok{ }\NormalTok{lessWeight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 157 199 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
numeric(0)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 157 123
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in weight[c(-1, 2)]: only 0's may be mixed with negative subscripts
\end{verbatim}

Note that mixing zero and other nonzero subscripts is allowed, but
mixing negative and positive subscripts is not allowed.

What about the (usual) case where we don't know the positions of the
elements we want? For example possibly we want the weights of all
females in the data. Later we will learn how to subset using logical
indices, which is a very powerful way to access desired elements of a
vector.

\subsection{Practice Problem}\label{practice-problem-1}

A bad programming technique that often plagues beginners is a technique
called \emph{hardcoding}. Consider the following simple vector
containing data on the number of tree species found at different sites.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{tree.sp <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{11}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Suppose we are interested in the second to last value of the data set.
One way to do this is to first determine the length of vector using the
\texttt{length()} function, then taking that value and subtracting 1.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{num.sites <-}\StringTok{ }\KeywordTok{length}\NormalTok{(tree.sp)}
\OperatorTok{>}\StringTok{ }\NormalTok{num.sites}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{tree.sp[}\DecValTok{10} \OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9
\end{verbatim}

This is an example of \emph{hardcoding}. But what if we attempt to use
the same code on a second vector of tree species data that has a
different number of sites?

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{tree.sp <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{num.sites <-}\StringTok{ }\KeywordTok{length}\NormalTok{(tree.sp)}
\OperatorTok{>}\StringTok{ }\NormalTok{num.sites}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{tree.sp[}\DecValTok{10} \OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NA
\end{verbatim}

That's clearly not what we want. Fix this code so we can always extract
the second to last value in the vector, regardless of the length of the
vector.

\section{Factors}\label{factors}

Categorical variables such as \texttt{gender} can be represented as
character vectors. In many cases this simple representation is
sufficient. Consider, however, two other categorical variables, one
representing age via categories \texttt{youth}, \texttt{young\ adult},
\texttt{middle\ age}, \texttt{senior}, and another representing income
via categories \texttt{lower}, \texttt{middle}, and \texttt{upper}.
Suppose that for the small health data set, all the people are either
middle aged or senior citizens. If we just represented the variable via
a character vector, there would be no way to know that there are two
other categories, representing youth and senior citizens, which happen
not to be present in the data set. And for the income variable, the
character vector representation does not explicitly indicate that there
is an ordering of the levels.

Factors in R provide a more sophisticated way to represent categorical
variables. Factors explicitly contain all possible levels, and allow
ordering of levels.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{age <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"middle age"}\NormalTok{, }\StringTok{"senior"}\NormalTok{, }\StringTok{"middle age"}\NormalTok{, }\StringTok{"senior"}\NormalTok{,}
\OperatorTok{+}\StringTok{          "senior"}\NormalTok{, }\StringTok{"senior"}\NormalTok{, }\StringTok{"senior"}\NormalTok{, }\StringTok{"middle age"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{income <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"lower"}\NormalTok{, }\StringTok{"lower"}\NormalTok{, }\StringTok{"upper"}\NormalTok{, }\StringTok{"middle"}\NormalTok{, }\StringTok{"upper"}\NormalTok{,}
\OperatorTok{+}\StringTok{             "lower"}\NormalTok{, }\StringTok{"lower"}\NormalTok{, }\StringTok{"middle"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{age}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "middle age" "senior"     "middle age" "senior"    
[5] "senior"     "senior"     "senior"     "middle age"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{income}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "lower"  "lower"  "upper"  "middle" "upper" 
[6] "lower"  "lower"  "middle"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{age <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(age, }\DataTypeTok{levels=}\KeywordTok{c}\NormalTok{(}\StringTok{"youth"}\NormalTok{, }\StringTok{"young adult"}\NormalTok{, }\StringTok{"middle age"}\NormalTok{,}
\OperatorTok{+}\StringTok{                             "senior"}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\NormalTok{age}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] middle age senior     middle age senior    
[5] senior     senior     senior     middle age
Levels: youth young adult middle age senior
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{income <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(income, }\DataTypeTok{levels=}\KeywordTok{c}\NormalTok{(}\StringTok{"lower"}\NormalTok{, }\StringTok{"middle"}\NormalTok{, }\StringTok{"upper"}\NormalTok{),}
\OperatorTok{+}\StringTok{                  }\DataTypeTok{ordered =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{income}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] lower  lower  upper  middle upper  lower  lower 
[8] middle
Levels: lower < middle < upper
\end{verbatim}

In the factor version of \texttt{age} the levels are explicitly listed,
so it is clear that the two included levels are not all the possible
levels. And in the factor version of income, the ordering is explicit.

In many cases the character vector representation of a categorical
variable is sufficient and easier to work with. In this book, factors
will not be used extensively. It is important to note that R often by
default creates a factor when character data are read in, and sometimes
it is necessary to use the argument \texttt{stringsAsFactors\ =\ FALSE}
to explicitly tell R not to do this. This is shown later in the chapter
when data frames are introduced.

\section{Names of Objects in R}\label{names-of-objects-in-r}

There are few hard and fast restrictions on the names of objects (such
as vectors) in R. In addition to these restrictions, there are certain
good practices, and many things to avoid as well.

From the help page for \texttt{make.names} in R, the name of an R object
is ``syntactically valid'' if the name ``consists of letters, numbers
and the dot or underline characters and starts with a letter or the dot
not followed by a number'' and is not one of the ``reserved words'' in R
such as \texttt{if}, \texttt{TRUE}, \texttt{function}, etc. For example,
\texttt{c45t.le\_dog} and \texttt{.ty56} are both syntactically valid
(although not very good names) while \texttt{4cats} and
\texttt{log\#@gopher} are not.

A few important comments about naming objects follow:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  It is important to be aware that names of objects in R are
  case-sensitive, so \texttt{weight} and \texttt{Weight} do not refer to
  the same object.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{Weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in eval(expr, envir, enclos): object 'Weight' not found
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  It is unwise to create an object with the same name as a built in R
  object such as the function \texttt{c} or the function \texttt{mean}.
  In earlier versions of R this could be somewhat disastrous, but even
  in current versions, it is definitely not a good idea!
\item
  As much as possible, choose names that are informative. When creating
  a variable you may initially remember that \texttt{x} contains heights
  and \texttt{y} contains genders, but after a few hours, a few days, or
  a few weeks, you probably will forget this. Better options are
  \texttt{Height} and \texttt{Gender}.
\item
  As much as possible, be consistent in how you name objects. In
  particular, decide how to separate multi-word names. Some options
  include:

  \begin{itemize}
  \tightlist
  \item
    Using case to separate: \texttt{BloodPressure} or
    \texttt{bloodPressure} for example
  \item
    Using underscores to separate: \texttt{blood\_pressure} for example
  \item
    Using a period to separate: \texttt{blood.pressure} for example
  \end{itemize}
\end{enumerate}

\section{Missing Data, Infinity, etc.}\label{missing-data-infinity-etc.}

Most real-world data sets have variables where some observations are
missing. In a longitudinal study participants may drop out. In a survey,
participants may decide not to respond to certain questions. Statistical
software should be able to represent missing data and to analyze data
sets in which some data are missing.

In R, the value \texttt{NA} is used for a missing data value. Since
missing values may occur in numeric, character, and other types of data,
and since R requires that a vector contain only elements of one type,
there are different types of \texttt{NA} values. Usually R determines
the appropriate type of \texttt{NA} value automatically. It is worth
noting that the default type for \texttt{NA} is logical, and that
\texttt{NA} is NOT the same as the character string \texttt{"NA"}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{missingCharacter <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\StringTok{"pig"}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\StringTok{"horse"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{missingCharacter}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog"   "cat"   NA      "pig"   NA      "horse"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.na}\NormalTok{(missingCharacter)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE FALSE  TRUE FALSE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{missingCharacter <-}\StringTok{ }\KeywordTok{c}\NormalTok{(missingCharacter, }\StringTok{"NA"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{missingCharacter}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog"   "cat"   NA      "pig"   NA      "horse"
[7] "NA"   
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.na}\NormalTok{(missingCharacter)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{allMissing <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\OtherTok{NA}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{typeof}\NormalTok{(allMissing)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "logical"
\end{verbatim}

How should missing data be treated in computations, such as finding the
mean or standard deviation of a variable? One possibility is to return
\texttt{NA}. Another is to remove the missing value(s) and then perform
the computation.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\OtherTok{NA}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\OtherTok{NA}\NormalTok{,}\DecValTok{5}\NormalTok{), }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.75
\end{verbatim}

As this example shows, the default behavior for the \texttt{mean()}
function is to return \texttt{NA}. If removal of the missing values and
then computing the mean is desired, the argument \texttt{na.rm} is set
to \texttt{TRUE}. Different R functions have different default
behaviors, and there are other possible actions. Consulting the help for
a function provides the details.

\subsection{Practice Problem}\label{practice-problem-2}

Collecting data is often a messy process resulting in multiple errors in
the data. Consider the following small vector representing the weights
of 10 adults in pounds.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{my.weights <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{150}\NormalTok{, }\DecValTok{138}\NormalTok{, }\DecValTok{289}\NormalTok{, }\DecValTok{239}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{103}\NormalTok{, }\DecValTok{310}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{218}\NormalTok{, }\DecValTok{178}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

As far as I know, it's not possible for an adult to weigh 12 pounds, so
that is most likely an error. Change this value to NA, and then find the
standard deviation of the weights after removing the NA value.

\subsection{Infinity and NaN}\label{infinity-and-nan}

What happens if R code requests division by zero, or results in a number
that is too large to be represented? Here are some examples.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ }\DecValTok{0}\OperatorTok{:}\DecValTok{4}
\OperatorTok{>}\StringTok{ }\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0 1 2 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]    Inf 1.0000 0.5000 0.3333 0.2500
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x}\OperatorTok{/}\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NaN   1   1   1   1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{10000}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\DecValTok{2}\OperatorTok{^}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  1.024e+03 1.072e+301        Inf
\end{verbatim}

\texttt{Inf} and \texttt{-Inf} represent infinity and negative infinity
(and numbers which are too large in magnitude to be represented as
floating point numbers). \texttt{NaN} represents the result of a
calculation where the result is undefined, such as dividing zero by
zero. All of these are common to a variety of programming languages,
including R.

\section{Data Frames}\label{dataFrames}

Commonly, data is rectangular in form, with variables as columns and
cases as rows. Continuing with the (contrived) data on weight, gender,
and blood pressure medication, each of those variables would be a column
of the data set, and each person's measurements would be a row. In R,
such data are represented as a \emph{data frame}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{healthData <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Weight =}\NormalTok{ weight, }\DataTypeTok{Gender=}\NormalTok{gender, }\DataTypeTok{bp.meds =}\NormalTok{ bp,}
\OperatorTok{+}\StringTok{                          }\DataTypeTok{stringsAsFactors=}\OtherTok{FALSE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{healthData}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Weight Gender bp.meds
1    123 female   FALSE
2    157 female    TRUE
3    202   male   FALSE
4    199 female   FALSE
5    223   male    TRUE
6    140   male   FALSE
7    105 female    TRUE
8    194   male   FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(healthData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Weight"  "Gender"  "bp.meds"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{colnames}\NormalTok{(healthData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Weight"  "Gender"  "bp.meds"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(healthData) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Wt"}\NormalTok{, }\StringTok{"Gdr"}\NormalTok{, }\StringTok{"bp"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{healthData}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   Wt    Gdr    bp
1 123 female FALSE
2 157 female  TRUE
3 202   male FALSE
4 199 female FALSE
5 223   male  TRUE
6 140   male FALSE
7 105 female  TRUE
8 194   male FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rownames}\NormalTok{(healthData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "1" "2" "3" "4" "5" "6" "7" "8"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(healthData) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Weight"}\NormalTok{, }\StringTok{"Gender"}\NormalTok{, }\StringTok{"bp.meds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{data.frame} function can be used to create a data frame
(although it's more common to read a data frame into R from an external
file, something that will be introduced later). The names of the
variables in the data frame are given as arguments, as are the vectors
of data that make up the variable's values. The argument
\texttt{stringsAsFactors=FALSE} asks R not to convert character vectors
into factors, which R does by default, to the dismay of many users.
Names of the columns (variables) can be extracted and set via either
\texttt{names} or \texttt{colnames}. In the example, the variable names
are changed to \texttt{Wt,\ Gdr,\ bp} and then changed back to the
original \texttt{Weight,\ Gender,\ bp.meds} in this way. Rows can be
named also. In this case since specific row names were not provided, the
default row names of \texttt{"1",\ "2"} etc. are used.

In the next example a built-in dataset called \texttt{mtcars} is made
available by the \texttt{data} function, and then the first and last six
rows are displayed using \texttt{head} and \texttt{tail}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{data}\NormalTok{(mtcars)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   mpg cyl disp  hp drat    wt  qsec
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02
Datsun 710        22.8   4  108  93 3.85 2.320 18.61
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02
Valiant           18.1   6  225 105 2.76 3.460 20.22
                  vs am gear carb
Mazda RX4          0  1    4    4
Mazda RX4 Wag      0  1    4    4
Datsun 710         1  1    4    1
Hornet 4 Drive     1  0    3    1
Hornet Sportabout  0  0    3    2
Valiant            1  0    3    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{tail}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                mpg cyl  disp  hp drat    wt qsec vs
Porsche 914-2  26.0   4 120.3  91 4.43 2.140 16.7  0
Lotus Europa   30.4   4  95.1 113 3.77 1.513 16.9  1
Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.5  0
Ferrari Dino   19.7   6 145.0 175 3.62 2.770 15.5  0
Maserati Bora  15.0   8 301.0 335 3.54 3.570 14.6  0
Volvo 142E     21.4   4 121.0 109 4.11 2.780 18.6  1
               am gear carb
Porsche 914-2   1    5    2
Lotus Europa    1    5    2
Ford Pantera L  1    5    4
Ferrari Dino    1    5    6
Maserati Bora   1    5    8
Volvo 142E      1    4    2
\end{verbatim}

Note that the \texttt{mtcars} data frame does have non-default row names
which give the make and model of the cars.

\subsection{Accessing Specific Elements of Data
Frames}\label{accessing-specific-elements-of-data-frames}

Data frames are two-dimensional, so to access a specific element (or
elements) we need to specify both the row and column.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mtcars[}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 110
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mtcars[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 160 160 108
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mtcars[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
              cyl disp
Mazda RX4       6  160
Mazda RX4 Wag   6  160
Datsun 710      4  108
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mtcars[,}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2
[11] 17.8 16.4 17.3 15.2 10.4 10.4 14.7 32.4 30.4 33.9
[21] 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7
[31] 15.0 21.4
\end{verbatim}

Note that \texttt{mtcars{[},1{]}} returns ALL elements in the first
column. This agrees with the behavior for vectors, where leaving a
subscript out of the square brackets tells R to return all values. In
this case we are telling R to return all rows, and the first column.

For a data frame there is another way to access specific columns, using
the \texttt{\$} notation.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mtcars}\OperatorTok{$}\NormalTok{mpg}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2
[11] 17.8 16.4 17.3 15.2 10.4 10.4 14.7 32.4 30.4 33.9
[21] 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7
[31] 15.0 21.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mtcars}\OperatorTok{$}\NormalTok{cyl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8
[26] 4 4 4 8 6 8 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mpg}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in eval(expr, envir, enclos): object 'mpg' not found
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{cyl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in eval(expr, envir, enclos): object 'cyl' not found
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

Notice that typing the variable name, such as \texttt{mpg}, without the
name of the data frame (and a dollar sign) as a prefix, does not work.
This is sensible. There may be several data frames that have variables
named \texttt{mpg}, and just typing \texttt{mpg} doesn't provide enough
information to know which is desired. But if there is a vector named
\texttt{mpg} that is created outside a data frame, it will be retrieved
when \texttt{mpg} is typed, which is why typing \texttt{weight} does
work, since \texttt{weight} was created outside of a data frame,
although ultimately it was incorporated into the \texttt{healthData}
data frame.

\section{Lists}\label{lists}

The third main data structure we will work with is a list. Technically a
list is a vector, but one in which elements can be of different types.
For example a list may have one element that is a vector, one element
that is a data frame, and another element that is a function. Consider
designing a function that fits a simple linear regression model to two
quantitative variables. We might want that function to compute and
return several things such as

\begin{itemize}
\tightlist
\item
  The fitted slope and intercept (a numeric vector with two components)
\item
  The residuals (a numeric vector with \(n\) components, where \(n\) is
  the number of data points)
\item
  Fitted values for the data (a numeric vector with \(n\) components,
  where \(n\) is the number of data points)
\item
  The names of the dependent and independent variables (a character
  vector with two components)
\end{itemize}

In fact R has a function, \texttt{lm}, which does this (and much more).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mpgHpLinMod <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(mpg }\OperatorTok{~}\StringTok{ }\NormalTok{hp, }\DataTypeTok{data=}\NormalTok{mtcars)}
\OperatorTok{>}\StringTok{ }\KeywordTok{mode}\NormalTok{(mpgHpLinMod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "list"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(mpgHpLinMod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "coefficients"  "residuals"     "effects"      
 [4] "rank"          "fitted.values" "assign"       
 [7] "qr"            "df.residual"   "xlevels"      
[10] "call"          "terms"         "model"        
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mpgHpLinMod}\OperatorTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept)          hp 
   30.09886    -0.06823 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mpgHpLinMod}\OperatorTok{$}\NormalTok{residuals}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          Mazda RX4       Mazda RX4 Wag 
           -1.59375            -1.59375 
         Datsun 710      Hornet 4 Drive 
           -0.95363            -1.19375 
  Hornet Sportabout             Valiant 
            0.54109            -4.83489 
         Duster 360           Merc 240D 
            0.91707            -1.46871 
           Merc 230            Merc 280 
           -0.81717            -2.50678 
          Merc 280C          Merc 450SE 
           -3.90678            -1.41777 
         Merc 450SL         Merc 450SLC 
           -0.51777            -2.61777 
 Cadillac Fleetwood Lincoln Continental 
           -5.71206            -5.02978 
  Chrysler Imperial            Fiat 128 
            0.29364             6.80421 
        Honda Civic      Toyota Corolla 
            3.84901             8.23598 
      Toyota Corona    Dodge Challenger 
           -1.98072            -4.36462 
        AMC Javelin          Camaro Z28 
           -4.66462            -0.08293 
   Pontiac Firebird           Fiat X1-9 
            1.04109             1.70421 
      Porsche 914-2        Lotus Europa 
            2.10991             8.01093 
     Ford Pantera L        Ferrari Dino 
            3.71340             1.54109 
      Maserati Bora          Volvo 142E 
            7.75761            -1.26198 
\end{verbatim}

The \texttt{lm} function returns a list (which in the code above has
been assigned to the object \texttt{mpgHpLinMod}).\footnote{The
  \texttt{mode} function returns the type or storage mode of an object.}
One component of the list is the length 2 vector of coefficients, while
another component is the length 32 vector of residuals. The code also
illustrates that named components of a list can be accessed using the
dollar sign notation, as with data frames.

The \texttt{list} function is used to create lists.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{first=}\NormalTok{weight, }\DataTypeTok{second=}\NormalTok{healthData,}
\OperatorTok{+}\StringTok{                       }\DataTypeTok{pickle=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{a =} \DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{b=}\NormalTok{healthData))}
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$first
[1] 123 157 202 199 223 140 105 194

$second
  Weight Gender bp.meds
1    123 female   FALSE
2    157 female    TRUE
3    202   male   FALSE
4    199 female   FALSE
5    223   male    TRUE
6    140   male   FALSE
7    105 female    TRUE
8    194   male   FALSE

$pickle
$pickle$a
 [1]  1  2  3  4  5  6  7  8  9 10

$pickle$b
  Weight Gender bp.meds
1    123 female   FALSE
2    157 female    TRUE
3    202   male   FALSE
4    199 female   FALSE
5    223   male    TRUE
6    140   male   FALSE
7    105 female    TRUE
8    194   male   FALSE
\end{verbatim}

Here, for illustration, I assembled a list to hold some of the R data
structures we have been working with in this chapter. The first list
element, named \texttt{first}, holds the \texttt{weight} vector we
created in Section \ref{vector}, the second list element, named
\texttt{second}, holds the \texttt{healthData} data frame, and the third
list element, named \texttt{pickle}, holds a list with elements named
\texttt{a} and \texttt{b} that hold a vector of values 1 through 10 and
another copy of the \texttt{healthData} data frame, respectively. As
this example shows, a list can contain another list.

\subsection{Accessing Specific Elements of
Lists}\label{accessing-specific-elements-of-lists}

We already have seen the dollar sign notation works for lists. In
addition, the square bracket subsetting notation can be used. There is
an added, somewhat subtle wrinkle---using either single or double square
brackets.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList}\OperatorTok{$}\NormalTok{first}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mode}\NormalTok{(temporaryList}\OperatorTok{$}\NormalTok{first)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "numeric"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mode}\NormalTok{(temporaryList[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "numeric"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$first
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mode}\NormalTok{(temporaryList[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "list"
\end{verbatim}

Note the dollar sign and double bracket notation return a numeric
vector, while the single bracket notation returns a list. Notice also
the difference in results below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$first
[1] 123 157 202 199 223 140 105 194

$second
  Weight Gender bp.meds
1    123 female   FALSE
2    157 female    TRUE
3    202   male   FALSE
4    199 female   FALSE
5    223   male    TRUE
6    140   male   FALSE
7    105 female    TRUE
8    194   male   FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList[[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 157
\end{verbatim}

The single bracket form returns the first and second elements of the
list, while the double bracket form returns the second element in the
first element of the list. Generally, do not put a vector of indices or
names in a double bracket, you will likely get unexpected results. See,
for example, the results below.\footnote{Try this example using only
  single brackets\(\ldots\) it will return a list holding elements
  \texttt{first}, \texttt{second}, and \texttt{pickle}.}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryList[[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in temporaryList[[c(1, 2, 3)]]: recursive indexing failed at level 2
\end{verbatim}

So, in summary, there are two main differences between using the single
bracket \texttt{{[}{]}} and double bracket \texttt{{[}{[}{]}{]}}. First,
the single bracket will return a list that holds the object(s) held at
the given indices or names placed in the bracket, whereas the double
brackets will return the actual object held at the index or name placed
in the innermost bracket. Put differently, a single bracket can be used
to access a range of list elements and will return a list, and a double
bracket can only access a single element in the list and will return the
object held at the index.

\section{Subsetting with Logical Vectors}\label{subsetting}

Consider the \texttt{healthData} data frame. How can we access only
those weights which are more than 200? How can we access the genders of
those whose weights are more than 200? How can we compute the mean
weight of males and the mean weight of females? Or consider the
\texttt{mtcars} data frame. How can we obtain the miles per gallon for
all six cylinder cars? Both of these data sets are small enough that it
would not be too onerous to extract the values by hand. But for larger
or more complex data sets, this would be very difficult or impossible to
do in a reasonable amount of time, and would likely result in errors.

R has a powerful method for solving these sorts of problems using a
variant of the subsetting methods that we already have learned. When
given a logical vector in square brackets, R will return the values
corresponding to \texttt{TRUE}. To begin, focus on the \texttt{weight}
and \texttt{gender} vectors created in Section \ref{vector}.

The R code \texttt{weight\ \textgreater{}\ 200} returns a \texttt{TRUE}
for each value of \texttt{weight} which is more than 200, and a
\texttt{FALSE} for each value of \texttt{weight} which is less than or
equal to 200. Similarly \texttt{gender\ ==\ "female"} returns
\texttt{TRUE} or \texttt{FALSE} depending on whether an element of
\texttt{gender} is equal to \texttt{female}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight }\OperatorTok{>}\StringTok{ }\DecValTok{200}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender[weight }\OperatorTok{>}\StringTok{ }\DecValTok{200}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "male" "male"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[weight }\OperatorTok{>}\StringTok{ }\DecValTok{200}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 202 223
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender }\OperatorTok{==}\StringTok{ "female"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight[gender }\OperatorTok{==}\StringTok{ "female"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 199 105
\end{verbatim}

Consider the lines of R code one by one.

\begin{itemize}
\tightlist
\item
  \texttt{weight} instructs R to display the values in the vector
  \texttt{weight}.
\item
  \texttt{weight\ \textgreater{}\ 200} instructs R to check whether each
  value in \texttt{weight} is greater than 200, and to return
  \texttt{TRUE} if so, and \texttt{FALSE} otherwise.
\item
  The next line, \texttt{gender{[}weight\ \textgreater{}\ 200{]}}, does
  two things. First, inside the square brackets, it does the same thing
  as the second line, namely, returning \texttt{TRUE} or \texttt{FALSE}
  depending on whether a value of \texttt{weight} is or is not greater
  than 200. Second, each element of \texttt{gender} is matched with the
  corresponding \texttt{TRUE} or \texttt{FALSE} value, and is returned
  if and only if the corresponding value is \texttt{TRUE}. For example
  the first value of \texttt{gender} is \texttt{gender{[}1{]}}. Since
  the first \texttt{TRUE} or \texttt{FALSE} value is \texttt{FALSE}, the
  first value of \texttt{gender} is not returned. Only the third and
  fifth values of \texttt{gender}, both of which happen to be
  \texttt{male}, are returned. Briefly, this line returns the genders of
  those people whose weight is over 200 pounds.
\item
  The fourth line of code,
  \texttt{weight{[}weight\ \textgreater{}\ 200{]}}, again begins by
  returning \texttt{TRUE} or \texttt{FALSE} depending on whether
  elements of \texttt{weight} are larger than 200. Then those elements
  of \texttt{weight} corresponding to \texttt{TRUE} values, are
  returned. So this line returns the weights of those people whose
  weights are more than 200 pounds.
\item
  The fifth line returns \texttt{TRUE} or \texttt{FALSE} depending on
  whether elements of \texttt{gender} are equal to \texttt{female} or
  not.
\item
  The sixth line returns the weights of those whose gender is
  \texttt{female}.
\end{itemize}

There are six comparison operators in R,
\texttt{\textgreater{},\ \textless{},\ \textgreater{}=,\ \textless{}=,\ ==,\ !=}.
Note that to test for equality a ``double equals sign'' is used, while
\texttt{!=} tests for inequality.

\subsection{Modifying or Creating Objects via
Subsetting}\label{modifying-or-creating-objects-via-subsetting}

The results of subsetting can be assigned to a new (or existing) R
object, and subsetting on the left side of an assignment is a common way
to modify an existing R object.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 202 199 223 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{lightweight <-}\StringTok{ }\NormalTok{weight[weight }\OperatorTok{<}\StringTok{ }\DecValTok{200}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{lightweight}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 123 157 199 140 105 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{10}
\OperatorTok{>}\StringTok{ }\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x[x }\OperatorTok{<}\StringTok{ }\DecValTok{5}\NormalTok{] <-}\StringTok{ }\DecValTok{0}
\OperatorTok{>}\StringTok{ }\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  0  0  0  0  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{y <-}\StringTok{ }\OperatorTok{-}\DecValTok{3}\OperatorTok{:}\DecValTok{9}
\OperatorTok{>}\StringTok{ }\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] -3 -2 -1  0  1  2  3  4  5  6  7  8  9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{y[y }\OperatorTok{<}\StringTok{ }\DecValTok{0}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\OperatorTok{>}\StringTok{ }\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] NA NA NA  0  1  2  3  4  5  6  7  8  9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rm}\NormalTok{(x)}
\OperatorTok{>}\StringTok{ }\KeywordTok{rm}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\subsection{Logical Subsetting and Data
Frames}\label{logical-subsetting-and-data-frames}

First consider the small and simple \texttt{healthData} data frame.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{healthData}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Weight Gender bp.meds
1    123 female   FALSE
2    157 female    TRUE
3    202   male   FALSE
4    199 female   FALSE
5    223   male    TRUE
6    140   male   FALSE
7    105 female    TRUE
8    194   male   FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{healthData}\OperatorTok{$}\NormalTok{Weight[healthData}\OperatorTok{$}\NormalTok{Gender }\OperatorTok{==}\StringTok{ "male"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 202 223 140 194
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{healthData[healthData}\OperatorTok{$}\NormalTok{Gender }\OperatorTok{==}\StringTok{ "female"}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Weight Gender bp.meds
1    123 female   FALSE
2    157 female    TRUE
4    199 female   FALSE
7    105 female    TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{healthData[healthData}\OperatorTok{$}\NormalTok{Weight }\OperatorTok{>}\StringTok{ }\DecValTok{190}\NormalTok{, }\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Gender bp.meds
3   male   FALSE
4 female   FALSE
5   male    TRUE
8   male   FALSE
\end{verbatim}

The first example is really just subsetting a vector, since the
\texttt{\$} notation creates vectors. The second two examples return
subsets of the whole data frame. Note that the logical vector subsets
the rows of the data frame, choosing those rows where the gender is
female or the weight is more than 190. Note also that the specification
for the columns (after the comma) is left blank in the first case,
telling R to return all the columns. In the second case the second and
third columns are requested explicitly.

Next consider the much larger and more complex \texttt{WorldBank} data
frame. Recall, the \texttt{str} function displays the ``structure'' of
an R object. Here is a look at the structure of several R objects.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   32 obs. of  11 variables:
 $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
 $ disp: num  160 160 108 258 360 ...
 $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
 $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
 $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
 $ qsec: num  16.5 17 18.6 19.4 17 ...
 $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
 $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
 $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
 $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(temporaryList)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
List of 3
 $ first : num [1:8] 123 157 202 199 223 140 105 194
 $ second:'data.frame': 8 obs. of  3 variables:
  ..$ Weight : num [1:8] 123 157 202 199 223 140 105 194
  ..$ Gender : chr [1:8] "female" "female" "male" "female" ...
  ..$ bp.meds: logi [1:8] FALSE TRUE FALSE FALSE TRUE FALSE ...
 $ pickle:List of 2
  ..$ a: int [1:10] 1 2 3 4 5 6 7 8 9 10
  ..$ b:'data.frame':   8 obs. of  3 variables:
  .. ..$ Weight : num [1:8] 123 157 202 199 223 140 105 194
  .. ..$ Gender : chr [1:8] "female" "female" "male" "female" ...
  .. ..$ bp.meds: logi [1:8] FALSE TRUE FALSE FALSE TRUE FALSE ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(WorldBank)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   11880 obs. of  15 variables:
 $ iso2c                       : chr  "AD" "AD" "AD" "AD" ...
 $ country                     : chr  "Andorra" "Andorra" "Andorra" "Andorra" ...
 $ year                        : int  1978 1979 1977 2007 1976 2011 2012 2008 1980 1972 ...
 $ fertility.rate              : num  NA NA NA 1.18 NA NA NA 1.25 NA NA ...
 $ life.expectancy             : num  NA NA NA NA NA NA NA NA NA NA ...
 $ population                  : num  33746 34819 32769 81292 31781 ...
 $ GDP.per.capita.Current.USD  : num  9128 11820 7751 39923 7152 ...
 $ X15.to.25.yr.female.literacy: num  NA NA NA NA NA NA NA NA NA NA ...
 $ iso3c                       : chr  "AND" "AND" "AND" "AND" ...
 $ region                      : chr  "Europe & Central Asia (all income levels)" "Europe & Central Asia (all income levels)" "Europe & Central Asia (all income levels)" "Europe & Central Asia (all income levels)" ...
 $ capital                     : chr  "Andorra la Vella" "Andorra la Vella" "Andorra la Vella" "Andorra la Vella" ...
 $ longitude                   : num  1.52 1.52 1.52 1.52 1.52 ...
 $ latitude                    : num  42.5 42.5 42.5 42.5 42.5 ...
 $ income                      : chr  "High income: nonOECD" "High income: nonOECD" "High income: nonOECD" "High income: nonOECD" ...
 $ lending                     : chr  "Not classified" "Not classified" "Not classified" "Not classified" ...
\end{verbatim}

First we see that \texttt{mtcars} is a data frame which has 32
observations (rows) on each of 11 variables (columns). The names of the
variables are given, along with their type (in this case, all numeric),
and the first few values of each variable is given.

Second we see that \texttt{temporaryList} is a list with three
components. Each of the components is described separately, with the
first few values again given.

Third we examine the structure of \texttt{WorldBank}. It is a data frame
with 11880 observations on each of 15 variables. Some of these are
character variables, some are numeric, and one (\texttt{year}) is
integer. Looking at the first few values we see that some variables have
missing values.

Consider creating a data frame which only has the observations from one
year, say 1971. That's relatively easy. Just choose rows for which
\texttt{year} is equal to 1971.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{WorldBank1971 <-}\StringTok{ }\NormalTok{WorldBank[WorldBank}\OperatorTok{$}\NormalTok{year }\OperatorTok{==}\StringTok{ }\DecValTok{1971}\NormalTok{, ]}
\OperatorTok{>}\StringTok{ }\KeywordTok{dim}\NormalTok{(WorldBank1971)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 216  15
\end{verbatim}

The \texttt{dim} function returns the dimensions of a data frame, i.e.,
the number of rows and the number of columns. From \texttt{dim} we see
that there are \texttt{dim(WorldBank1971){[}1{]}} cases from 1971.

Next, how can we create a data frame which only contains data from 1971,
and also only contains cases for which there are no missing values in
the fertility rate variable? R has a built in function \texttt{is.na}
which returns \texttt{TRUE} if the observation is missing and returns
\texttt{FALSE} otherwise. And \texttt{!is.na} returns the negation,
i.e., it returns \texttt{FALSE} if the observation is missing and
\texttt{TRUE} if the observation is not missing.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{WorldBank1971}\OperatorTok{$}\NormalTok{fertility.rate[}\DecValTok{1}\OperatorTok{:}\DecValTok{25}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]    NA 6.512 7.671 3.517 4.933 3.118 7.264 3.104
 [9]    NA 2.200 2.961 2.788 4.479 2.260 2.775 2.949
[17] 6.942 2.210 6.657 2.100 6.293 7.329 6.786    NA
[25] 5.771
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(WorldBank1971}\OperatorTok{$}\NormalTok{fertility.rate[}\DecValTok{1}\OperatorTok{:}\DecValTok{25}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
 [9] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[17]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
[25]  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{WorldBank1971 <-}\StringTok{ }\NormalTok{WorldBank1971[}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(WorldBank1971}\OperatorTok{$}\NormalTok{fertility.rate),]}
\OperatorTok{>}\StringTok{ }\KeywordTok{dim}\NormalTok{(WorldBank1971)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 193  15
\end{verbatim}

From \texttt{dim} we see that there are
\texttt{dim(WorldBank1971){[}1{]}} cases from 1971 with non-missing
fertility rate data.

Return attention now to the original \texttt{WorldBank} data frame with
data not only from 1971. How can we extract only those cases (rows)
which have NO missing data? Consider the following simple example:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryDataFrame <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{V1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\OtherTok{NA}\NormalTok{),}
\OperatorTok{+}\StringTok{                                  }\DataTypeTok{V2 =} \KeywordTok{c}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\OtherTok{NA}\NormalTok{),}
\OperatorTok{+}\StringTok{                                  }\DataTypeTok{V3 =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\NormalTok{temporaryDataFrame}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  V1 V2 V3
1  1 NA  1
2  2  1  2
3  3  4  3
4  4  5  5
5 NA NA  7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{is.na}\NormalTok{(temporaryDataFrame)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        V1    V2    V3
[1,] FALSE  TRUE FALSE
[2,] FALSE FALSE FALSE
[3,] FALSE FALSE FALSE
[4,] FALSE FALSE FALSE
[5,]  TRUE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rowSums}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(temporaryDataFrame))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 0 0 0 2
\end{verbatim}

First notice that \texttt{is.na} will test each element of a data frame
for missingness. Also recall that if R is asked to sum a logical vector,
it will first convert the logical vector to numeric and then compute the
sum, which effectively counts the number of elements in the logical
vector which are \texttt{TRUE}. The \texttt{rowSums} function computes
the sum of each row. So \texttt{rowSums(is.na(temporaryDataFrame))}
returns a vector with as many elements as there are rows in the data
frame. If an element is zero, the corresponding row has no missing
values. If an element is greater than zero, the value is the number of
variables which are missing in that row. This gives a simple method to
return all the cases which have no missing data.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{dim}\NormalTok{(WorldBank)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 11880    15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{WorldBankComplete <-}\StringTok{ }\NormalTok{WorldBank[}\KeywordTok{rowSums}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(WorldBank)) }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{,]}
\OperatorTok{>}\StringTok{ }\KeywordTok{dim}\NormalTok{(WorldBankComplete)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 564  15
\end{verbatim}

Out of the \texttt{dim(WorldBankComplete){[}1{]}} rows in the original
data frame, only \texttt{dim(WorldBankComplete){[}1{]}} have no missing
observations!

\section{Patterned Data}\label{patterned-data}

Sometimes it is useful to generate all the integers from 1 through 20,
to generate a sequence of 100 points equally spaced between 0 and 1,
etc. The R functions \texttt{seq()} and \texttt{rep()} as well as the
``colon operator'' \texttt{:} help to generate such sequences.

The colon operator generates a sequence of values with increments of
\(1\) or \(-1\).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{10}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\OperatorTok{-}\DecValTok{5}\OperatorTok{:}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -5 -4 -3 -2 -1  0  1  2  3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{10}\OperatorTok{:}\DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 10  9  8  7  6  5  4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{pi}\OperatorTok{:}\DecValTok{7}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.142 4.142 5.142 6.142
\end{verbatim}

The \texttt{seq()} function generates either a sequence of pre-specified
length or a sequence with pre-specified increments.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{0}\NormalTok{, }\DataTypeTok{to =} \DecValTok{1}\NormalTok{, }\DataTypeTok{length =} \DecValTok{11}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{1}\NormalTok{, }\DataTypeTok{to =} \DecValTok{5}\NormalTok{, }\DataTypeTok{by =} \DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 1.000 1.333 1.667 2.000 2.333 2.667 3.000 3.333
 [9] 3.667 4.000 4.333 4.667 5.000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{3}\NormalTok{, }\DataTypeTok{to =} \OperatorTok{-}\DecValTok{1}\NormalTok{, }\DataTypeTok{length =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  3.0000  2.5556  2.1111  1.6667  1.2222  0.7778
 [7]  0.3333 -0.1111 -0.5556 -1.0000
\end{verbatim}

The \texttt{rep()} function replicates the values in a given vector.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{), }\DataTypeTok{length =} \DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 4 1 2 4 1 2 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{), }\DataTypeTok{times =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 4 1 2 4 1 2 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{), }\DataTypeTok{times =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{7}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "a" "a" "a" "b" "b" "c" "c" "c" "c" "c" "c" "c"
\end{verbatim}

\subsection{Practice Problem}\label{practice-problem-3}

Often when using R you will want to simulate data from a specific
probability distribution (i.e.~normal/Gaussian, bionmial, Poisson). R
has a vast suite of functions for working with statistical
distributions. To generate values from a statistical distribution, the
function has a name beginning with an ``r'' followed by some
abbreviation of the probability distribution. For example to simulate
from the three distributions mentioned above, we can use the functions
\texttt{rnorm()}, \texttt{rbinom}, and \texttt{rpois}.

Use the \texttt{rnorm()} function to generate 10,000 values from the
standard normal distribution (the normal distribution with mean = 0 and
variance = 1). Consult the help page for \texttt{rnorm()} if you need
to. Save this vector of variables to a vector named \texttt{sim.vals}.
Then use the \texttt{hist()} function to draw a histogram of the
simulated data. Does the data look like it follows a normal
distribution?

\section{Exercises}\label{exercises-1}

\textbf{Exercise 3} Learning objectives: create, subset, and manipulate
vector contents and attributes; summarize vector data using R
\texttt{table()} and other functions; generate basic graphics using
vector data.

\textbf{Exercise 4} Learning objectives: use functions to describe data
frame characteristics; summarize and generate basic graphics for
variables held in data frames; apply the subset function with logical
operators; illustrate \texttt{NA}, \texttt{NaN}, \texttt{Inf}, and other
special values occur; recognize the implications of using floating point
arithmetic with logical operators.

\textbf{Exercise 5} Learning objectives: practice with lists, data
frames, and associated functions; summarize variables held in lists and
data frames; work with R's linear regression \texttt{lm()} function
output; review logical subsetting of vectors for partitioning and
assigning of new values; generate and visualize data from mathematical
functions.

\chapter{\texorpdfstring{Graphics in R Part 1:
\texttt{ggplot2}}{Graphics in R Part 1: ggplot2}}\label{graphics-in-r-part-1-ggplot2}

R can be used to create a vast array of graphical representations of
data. Creating ``standard'' graphical displays is straightforward, but a
main strength of R is the ability to customize graphical displays to
create either non-standard graphics or to modify more standard graphical
displays to create publication-ready versions.

There are several packages available in R for creating graphics. The two
leading packages are the \texttt{graphics} package, which comes with
your base installation of R, and the \texttt{ggplot2} package, which
must be installed and made available by the user.\footnote{Other
  graphics packages include \texttt{lattice} and \texttt{grid}} For
beginners \texttt{ggplot2} has somewhat simpler syntax, and also
produces excellent graphics without much tinkering. However, the
\texttt{graphics} package seemingly provides more control over different
graphical parameters, and can sometimes be more intuitive than
\texttt{ggplot2}.

Knowing how to use both the \texttt{graphics} and \texttt{ggplot2}
packages is worthwhile, so we denote one chapter to \texttt{ggplot2} and
a second chapter to \texttt{graphics}. We use \texttt{ggplot2}
throughout the text, and thus require you to read this chapter on
\texttt{ggplot2} while Chapter \ref{graphics} on the \texttt{graphics}
package is optional. You'll notice that the chapters are essentially the
same, producing the same graphs (with a few exceptions) to let you
decide which graphing style you prefer. We simply want to present you
with both sets of tools so that in the future when you have graphs to
produce you can use whichever package floats your boat! For now we'll
start off with \texttt{ggplot2} and get to \texttt{graphics} in Chapter
\ref{graphics}.

The \texttt{gg} in \texttt{ggplot2} stands for \emph{Grammar of
Graphics}. The package provides a unified and logical way to describe
graphical displays such as scatter plots, histograms, bar charts, and
many other types of graphics. The grammar describes the mapping from
data to the graphical display's aesthetic attributes (color, shape,
size) of geometric objects (points, lines, bars). As will become
obvious, once this grammar is mastered for a particular type of plot,
such as a scatter plot, it is easy to transfer this knowledge to other
types of graphics.

Once you work through this chapter, the best place to learn more about
\texttt{ggplot2} is from the package's official book
\citet{WickhamGgplot2Book} by Hadley Wickham. It is available on-line in
digital format from MSU's library. The book goes into much more depth on
the theory underlying the grammar and syntax, and has many examples on
solving practical graphical problems. In addition to the free on-line
version available through MSU, the book's source code is available at
\url{https://github.com/hadley/ggplot2-book}.

Another useful resource is the \texttt{ggplot2} extensions guide
\texttt{http://www.ggplot2-exts.org}. This site lists packages that
extend \texttt{ggplot2}. It's a good place to start if you're trying to
do something that seems hard with \texttt{ggplot2}. We'll explore a few
of these extension packages toward the end of this chapter.

\section{Scatter Plots}\label{scatter-plots}

Scatter plots are a workhorse of data visualization and provide a good
entry point to the \texttt{ggplot2} system. Begin by considering a
simple and classic data set sometimes called \emph{Fisher's Iris Data}.
These data are available in R.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{data}\NormalTok{(iris)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

The data contain measurements on petal and sepal length and width for
\texttt{dim(iris){[}1{]}} iris plants. The plants are from one of three
species, and the species information is also included in the data frame.
The data are commonly used to test classification methods, where the
goal would be to correctly determine the species based on the four
length and width measurements. To get a preliminary sense of how this
might work, we can draw some scatter plots of length versus width.
Recall that \texttt{ggplot2} is not available by default, so we first
have to download and install the package.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{install.packages}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Once this is done the package is installed on the local hard drive, and
we can use the \texttt{library} function to make the package available
during the current R session.

Next a basic scatter plot is drawn. We'll keep the focus on sepal length
and width, but of course similar plots could be drawn using petal length
and width. The prompt is not displayed below, since the continuation
prompt \texttt{+} can cause confusion.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-58-1.pdf}

In this case the first argument to the \texttt{ggplot} function is the
name of the data frame. Second, the \texttt{aes} (short for aesthetics)
function specifies the mapping to the \texttt{x} and \texttt{y} axes. By
itself the \texttt{ggplot} function as written doesn't tell R what sort
of graphical display is desired. That is done by adding a \texttt{geom}
(short for geometry) specification, in this case \texttt{geom\_point}.

Looking at the scatter plot and thinking about the focus of finding a
method to classify the species, two thoughts come to mind. First, the
plot might be improved by increasing the size of the points. And second,
using different colors for the points corresponding to the three species
would help.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{4}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-59-1.pdf}

Notice that a legend showing what the colors represent is automatically
generated and included in the graphic. Next, the size of the points
seems a bit big now, and it might be helpful to use different shapes for
the different species.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species, }\DataTypeTok{shape=}\NormalTok{Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-60-1.pdf}

Here we see that the legend automatically changes to include species
specific color and shape. The size of the points seems more appropriate.

\subsection{\texorpdfstring{Structure of a Typical
\texttt{ggplot}}{Structure of a Typical ggplot}}\label{structure-of-a-typical-ggplot}

The examples above start with the function \texttt{ggplot()}, which
takes as arguments the data frame containing the data to be plotted as
well as a mapping from the data to the axes, enclosed by the
\texttt{aes()} function. Next a \texttt{geom} function, in the above
case \texttt{geom\_point()}, is added. It might just specify the
geometry, but also might specify aspects such as size, color, or shape.

Typically many graphics are created and discarded in the search for an
informative graphic, and often the initial specification of data and
basic aesthetics from \texttt{ggplot()} stays the same in all the
attempts. In such a case it can be helpful to assign that portion of the
graphic to an R object, both to minimize the amount of typing and to
keep certain aspects of all the graphics constant. Here's how that could
be done for the graphics above.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris.p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }
\NormalTok{iris.p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-61-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris.p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{3}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species, }\DataTypeTok{shape=}\NormalTok{Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-61-2.pdf}

\subsection{Adding lines to a scatter
plot}\label{adding-lines-to-a-scatter-plot}

To add a fitted least squares line to a scatter plot, use
\texttt{stat\_smooth}, which adds a smoother (possibly a least squares
line, possibly a smooth curve fit to the data, etc.). The argument
\texttt{method\ =\ lm} specifies a line fitted by least squares, and the
argument \texttt{se\ =\ FALSE} suppresses the default display of a
confidence band around the line or curve which was fit to the data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size=}\DecValTok{3}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-62-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size=}\DecValTok{3}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{stat_smooth}\NormalTok{(}\DataTypeTok{method =}\NormalTok{ lm, }\DataTypeTok{se=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-62-2.pdf}

For the iris data, it probably makes more sense to fit separate lines by
species. This can be specified using the \texttt{aes()} function inside
\texttt{stat\_smooth()}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size=}\DecValTok{3}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{stat_smooth}\NormalTok{(}\DataTypeTok{method =}\NormalTok{ lm, }\DataTypeTok{se=}\OtherTok{FALSE}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-63-1.pdf}

In this case we specified the same color aesthetic for the points and
the lines. If we know we want this color aesthetic (colors corresponding
to species) for all aspects of the graphic, we can specify it in the
main \texttt{ggplot()} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width, }\DataTypeTok{color =}\NormalTok{ Species)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size=}\DecValTok{3}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{stat_smooth}\NormalTok{(}\DataTypeTok{method =}\NormalTok{ lm, }\DataTypeTok{se=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-64-1.pdf}

Another common use of line segments in a graphic is to connect the
points in order, accomplished via the \texttt{geom\_line()} function.
Although it is not clear why this helps in understanding the iris data,
the technique is illustrated next, first doing this for all the points
in the graphic, and second doing this separately for the three species.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{4}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species, }\DataTypeTok{shape =}\NormalTok{ Species)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-65-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{4}\NormalTok{, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-66-1.pdf}

\section{Labels, Axes, Text, etc.}\label{labels-axes-text-etc.}

The default settings of \texttt{ggplot2} often produce excellent
graphics, but once a graphic is chosen for dissemination, the user will
likely want to customize things like the title, axes, etc. In this
section some tools for customization are presented. Most will be
illustrated in the context of a data set on crime rates in the 50 states
in the United States. These data were made available by Nathan Yau at
\url{http://flowingdata.com/2010/11/23/how-to-make-bubble-charts/}. The
data include crime rates per 100,000 people for various crimes such as
murder and robbery, and also include each state's population. The crime
rates are from the year 2005, while the population numbers are from the
year 2008, but the difference in population between the years is not
great, and the exact population is not particularly important for what
we'll do below.

First, read in the data, examine its structure, and produce a simple
scatter plot of motor vehicle theft versus burglary.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.crime <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/crimeRatesByState2005.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{crime <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.crime, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(crime)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   50 obs. of  9 variables:
 $ state              : Factor w/ 50 levels "Alabama ","Alaska ",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ murder             : num  8.2 4.8 7.5 6.7 6.9 3.7 2.9 4.4 5 6.2 ...
 $ Forcible_rate      : num  34.3 81.1 33.8 42.9 26 43.4 20 44.7 37.1 23.6 ...
 $ Robbery            : num  141.4 80.9 144.4 91.1 176.1 ...
 $ aggravated_assult  : num  248 465 327 387 317 ...
 $ burglary           : num  954 622 948 1085 693 ...
 $ larceny_theft      : num  2650 2599 2965 2711 1916 ...
 $ motor_vehicle_theft: num  288 391 924 262 713 ...
 $ population         : int  4627851 686293 6500180 2855390 36756666 4861515 3501252 873092 18328340 9685744 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(data <-}\StringTok{ }\NormalTok{crime, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ burglary, }\DataTypeTok{y =}\NormalTok{ motor_vehicle_theft)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-67-1.pdf}

\subsection{Labels}\label{labels}

By default axis and legend labels are the names of the relevant columns
in the data frame. While convenient, we often want to customize these
labels. Here we use \texttt{labs()} to change the x and y axis labels
and other descriptive text.\footnote{Axis and legend labels can also be
  set in the individual scales, see the subsequent sections.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ crime, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ burglary, }\DataTypeTok{y =}\NormalTok{ motor_vehicle_theft)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
         \DataTypeTok{y =} \StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{,}
         \DataTypeTok{title =} \StringTok{"Burglaries vs motor vehicle theft for US states"}\NormalTok{,}
         \DataTypeTok{subtitle =} \StringTok{"2005 crime rates and 2008 population"}\NormalTok{,}
         \DataTypeTok{caption =} \StringTok{"Data from Nathan Yau http://flowingdata.com"}
\NormalTok{         )}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-68-1.pdf}

\section{Customizing Axes}\label{customizing-axes}

\texttt{ggplot} also provides default axis extents (i.e., limits) and
other axis features. These, and other axis features such as tick marks,
labels, and transformations, can be changed using the scale functions.
Here the range of the x and y axis is altered to start at zero and go to
the maximum of the x and y variables.\footnote{\texttt{ggplot2} makes
  the axes extend slightly beyond the given range, since typically this
  is what the user wants.} Here too, axis labels are specified within
the scale function, which is an alterative to using the \texttt{labs()}
function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ crime, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ burglary, }\DataTypeTok{y =}\NormalTok{ motor_vehicle_theft)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
                       \DataTypeTok{limits=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
                       \DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-69-1.pdf}

\subsection{Text, Point Size, and
Color}\label{text-point-size-and-color}

Next we make point size proportional to population, change the color,
and add a state label. Note, in the \texttt{ggplot()} call I scaled
\texttt{population} by 100,000 to help with the interpretability of the
legend. Accordingly, I also changed the ``population'' label on the
legend to ``Population\textbackslash{}n(100,000)'' using the
\texttt{labs()} function\footnote{The \textbackslash{}n is the line
  break and puts ``(100,000)'' below ``Population''.}. We use the
\texttt{geom\_label()} function to add the label, which provides an
outline around the label text and allows you to control the box
characteristics, e.g., I make the boxes slightly transparent using the
\texttt{alpha} argument.\footnote{You can also add labels via
  \texttt{geom\_text()} function or a \texttt{label} argument in the
  \texttt{ggplot()} call.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ crime, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ burglary, }\DataTypeTok{y =}\NormalTok{ motor_vehicle_theft, }
           \DataTypeTok{size=}\NormalTok{population}\OperatorTok{/}\DecValTok{100000}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{color =} \StringTok{"blue"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_label}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ state), }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
                       \DataTypeTok{limits=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
                       \DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{size=}\StringTok{"Population}\CharTok{\textbackslash{}n}\StringTok{(100,000)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-70-1.pdf}

The labels are helpful but just too cluttered. There are some additional
arguments that can go into \texttt{geom\_label()} that allow for label
offset; however, this won't help us much here. Instead, we can try the
\texttt{ggrepel} package by Kamil Slowikowski. This useful package will
automatically adjust labels so that they don't overlap. First we need to
download and add the package using either RStudio's install package
buttons or via \texttt{install.packages("ggrepel")}. Next to make all of
\texttt{ggrepel}'s functions available we can call
\texttt{library(ggrepel)} function or, if we know which function we
want, we can load only that particular function using the \texttt{::}
operators. I use \texttt{::} below to make clear which function is
coming from \texttt{ggrepel} and which is coming from \texttt{ggplot2}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ crime, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ burglary, }\DataTypeTok{y =}\NormalTok{ motor_vehicle_theft, }
           \DataTypeTok{size=}\NormalTok{population}\OperatorTok{/}\DecValTok{100000}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{color =} \StringTok{"blue"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
                       \DataTypeTok{limits=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
                       \DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{size=}\StringTok{"Population}\CharTok{\textbackslash{}n}\StringTok{(100,000)"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\NormalTok{ggrepel}\OperatorTok{::}\KeywordTok{geom_label_repel}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ state), }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-71-1.pdf}

This looks a bit better. We'll resist making additional improvements to
the figure for now.

\subsection{Practice Problem}\label{practice-problem-4}

You run an experiment to see if the number of alcoholic beverages a
person has on average every day is related to weight. You collect 15
data points. Enter these data in R by creating vectors, and then
reproduce the following plot.

\begin{tabular}{rr}
\toprule
\# of Drinks & Weight\\
\midrule
1.0 & 150\\
3.0 & 350\\
2.0 & 200\\
0.5 & 140\\
2.0 & 200\\
\addlinespace
1.0 & 160\\
0.0 & 175\\
0.0 & 140\\
0.0 & 167\\
1.0 & 200\\
\addlinespace
4.0 & 300\\
5.0 & 321\\
2.0 & 250\\
0.5 & 187\\
1.0 & 190\\
\bottomrule
\end{tabular}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-73-1.pdf}

\section{Other Types of Graphics}\label{other-types-of-graphics}

Scatter and line plots, which have just been presented, are common but
certainly not the only graphical displays in common use. Histograms,
boxplots, and bar graphs, as well as more ``mathematical'' displays such
as the graph of a function, are commonly used to represent data.
Examples of each are presented below.

\subsection{Histograms}\label{histograms}

Simon Newcomb conducted several experiments to estimate the speed of
light by measuring the time it took for light to travel from his
laboratory to a mirror at the base of the Washington Monument, and then
back to his lab. This is a distance of \(7.44373\) km, and by dividing
this distance by the measured time, an estimate for the speed of light
is obtained.

The times are of course quite small, and to avoid working with very
small numbers, the data are recoded to be the deviation from \(24800\)
nanoseconds. For example an observation coded as \(28\) represents a
time of \(24828\) nanoseconds, while an observation coded as \(-44\)
represents a time of \(24756\) nanoseconds.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.newcomb <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/Newcomb.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{Newcomb <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.newcomb, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(Newcomb)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Time
1   28
2   26
3   33
4   24
5   34
6  -44
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(Newcomb, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Time)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
`stat_bin()` using `bins = 30`. Pick better value
with `binwidth`.
\end{verbatim}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-75-1.pdf}

The software has an algorithm to calculate bin widths for the histogram.
Sometimes the algorithm makes choices that aren't suitable (hence the R
message above), and these can be changed by specifying a
\texttt{binwidth}. In addition, the appearance of the bars also can be
changed.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(Newcomb, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Time)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{5}\NormalTok{, }\DataTypeTok{color =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"blue"}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-76-1.pdf}

\subsection{Boxplots}\label{boxplots}

Next we consider some data from the gap minder data set to construct
some box plots. These data are available in the \texttt{gapminder}
package, which might need to be installed via
\texttt{install.packages("gapminder")}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(gapminder)}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(gapminder,  year }\OperatorTok{==}\StringTok{ }\DecValTok{2002}\NormalTok{), }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ gdpPercap)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{color =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"lightblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-77-1.pdf}

Here's the same set of boxplots, but with different colors, different
axis labels, and the boxes plotted horizontally rather than vertically.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(gapminder,  year }\OperatorTok{==}\StringTok{ }\DecValTok{2002}\NormalTok{), }
       \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ gdpPercap)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_boxplot}\NormalTok{(}\DataTypeTok{color =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"lightblue"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{scale_x_discrete}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Continent"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Per Capita GDP"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{coord_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-78-1.pdf}

\subsection{Bar Graphs}\label{bar-graphs}

As part of a study, elementary school students were asked which was more
important to them: good grades, popularity, or athletic ability. Here is
a brief look at the data.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.goals <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/StudentGoals.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{StudentGoals <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.goals, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(StudentGoals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Gender Grade Age  Race  Type School   Goals Grades
1    boy     5  11 White Rural    Elm  Sports      1
2    boy     5  10 White Rural    Elm Popular      2
3   girl     5  11 White Rural    Elm Popular      4
4   girl     5  11 White Rural    Elm Popular      2
5   girl     5  10 White Rural    Elm Popular      4
6   girl     5  11 White Rural    Elm Popular      4
  Sports Looks Money
1      2     4     3
2      1     4     3
3      3     1     2
4      3     4     1
5      2     1     3
6      2     1     3
\end{verbatim}

First, a simple bar graph of the most important goal chosen is drawn,
followed by a stacked bar graph which also includes the student's
gender. We then add a side by side bar graph that includes the student's
gender.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(StudentGoals, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Goals)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-80-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(StudentGoals, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Goals, }\DataTypeTok{fill =}\NormalTok{ Gender)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-80-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(StudentGoals, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Goals, }\DataTypeTok{fill =}\NormalTok{ Gender)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \StringTok{"dodge"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-80-3.pdf}

In this example R counted the number of students who had each goal and
used these counts as the height of the bars. Sometimes the data contain
the bar heights as a variable. For example, we create a bar graph of
India's per capita GDP with separate bars for each year in the
data\footnote{R offers a large color palette, run \texttt{colors()} on
  the console to see a list of color names.}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{subset}\NormalTok{(gapminder, country }\OperatorTok{==}\StringTok{ "India"}\NormalTok{), }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ gdpPercap)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat =} \StringTok{"identity"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"steelblue2"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"India's per-capita GDP"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-81-1.pdf}

\subsection{Graphs of Functions}\label{graphs-of-functions}

One way to create a plot of a mathematical function \(f\) is to create a
data frame with \(x\) values in one column and \(f(x)\) values in
another column, and then draw a line plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\NormalTok{pi, pi, }\DataTypeTok{len =} \DecValTok{1000}\NormalTok{)}
\NormalTok{sin.data <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x, }\DataTypeTok{y =} \KeywordTok{sin}\NormalTok{(x))}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ sin.data, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x, }\DataTypeTok{y =}\NormalTok{ y)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"sin(x)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-82-1.pdf}

This method works well, but with a better understanding of functions in
R we will be able to plot mathematical functions in a simpler and more
natural way.

\section{Themes}\label{themes}

The theme defines non-data aspects of the plot's characteristics such as
background color, axes, and grid lines. Default themes include:
\texttt{theme\_bw()}, \texttt{theme\_classic()}, \texttt{theme\_dark()},
\texttt{theme\_gray()}, \texttt{theme\_light()},
\texttt{theme\_linedraw()}, \texttt{theme\_minimal()}, and
\texttt{theme\_void()}. Changing the theme is as easy as adding it to
your initial \texttt{ggplot()} call. Here I replace the default implicit
\texttt{theme\_bw()} theme with the classic theme.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ sin.data, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x, }\DataTypeTok{y =}\NormalTok{ y)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"sin(x)"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-83-1.pdf}

The \texttt{ggthemes} add-on package
{[}\url{https://github.com/jrnold/ggthemes}{]} by Jeffrey Arnold
provides a large selection of themes beyond the eight themes that come
with \texttt{ggplot2}.

\section{Saving Graphics}\label{saving-graphics}

We often want to export our graphics to use in an external document or
share with colleagues. There are several ways to save graphics in a
variety of file formats. The \texttt{ggsave()} function will allow you
to save your most recent \texttt{ggplot()} to a variety of vector (e.g.,
``eps'', ``ps'', ``pdf'', ``svg'') or raster (e.g., ``jpeg'', ``tiff'',
``png'', ``bmp'', ``wmf'') formats \footnote{Vector files comprise lines
  and curves known as paths, whereas raster files are comprised of
  pixels. Vector images are often preferred for publication quality
  graphics because they can be edited, scale well, and provide crisper
  detail.}. The subsequent call to \texttt{ggsave()} saves the
\texttt{sin.data} plot to a pdf file called ``sin-plot.pdf''.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggsave}\NormalTok{(}\DataTypeTok{filename =} \StringTok{"sin-plot.pdf"}\NormalTok{, }\DataTypeTok{device=}\StringTok{"pdf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{ggplot()} function takes additional arguments to control
scale, measurement units, and raster plot resolution, i.e., dots per
inch (dpi).

\section{More Resources}\label{more-resources}

In summary, \texttt{ggplot2} provides a fairly intuitive\footnote{Like
  everything else in this book, it takes practice to get used to the
  syntax.} framework for developing an enormous variety of graphics. In
addition to the resources mentioned at the beginning of this chapter,
there are numerous online \texttt{ggplot2} resources and galleries to
get ideas for creating beautiful graphics to convey the stories in your
data. See, for example,

\begin{itemize}
\tightlist
\item
  \url{http://docs.ggplot2.org}
\item
  \url{http://www.r-graph-gallery.com/portfolio/ggplot2-package}
\item
  \url{http://www.ggplot2-exts.org/gallery}
\item
  \url{http://www.cookbook-r.com/Graphs}
\item
  and of course www.google.com
\end{itemize}

While the built-in \texttt{ggplot2} package documentation (accessible
via the help tab in RStudio) is helpful, the official online
documentation at \url{http://docs.ggplot2.org} is particularly useful
because it provides example plots and easy navigation between related
topics. The large number number of functions and syntax in
\texttt{ggplot2} can be daunting. RStudio provides some handy
cheatsheets to help you along www.rstudio.com/resources/cheatsheets or
direct link
www.rstudio.com/wp-content/uploads/2016/11/ggplot2-cheatsheet-2.1.pdf.

\texttt{ggplot2} also has an active mailing list at
\url{http://groups.google.com/group/ggplot2}. The list is an excellent
resource for users at all stages of experience. Another useful resource
is stackoverflow, \url{http://stackoverflow.com}. There is an active
\texttt{ggplot2} community on stackoverflow, and many common questions
have already been asked and answered. When posting questions on any
programming mailing list, it is best to provide a minimal reproducible
example of your issue. The \texttt{reprex}
\url{https://github.com/jennybc/reprex} package by Jenny Bryan provides
a convenient way to do this, and also includes advice on creating a good
example. The more information you provide about your issue, the more
likely the community is to help you.

\subsection{Practice Problem}\label{practice-problem-5}

Check out the \texttt{ggplot2} cheatsheet found at
\url{https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf}.
Create a plot using the \texttt{iris} data set using something we didn't
mention in this chapter, and describe what is new about the plot. The
plot can be anything you like, just make sure you use something not
mentioned in the chapter!

\section{Exercises}\label{exercises-2}

\textbf{Exercise 6a} Learning objectives: practice using
\texttt{ggplot2} functions; summarize variables using graphics;
introduce \texttt{ggplot2} facets.

\chapter{Working with Data}\label{data2}

Bringing data into R, exporting data from R in a form that is readable
by other software, cleaning and reshaping data, and other data
manipulation tasks are an important and often overlooked component of
data science. The book \citet{SpectorDataManipulation}, while a few
years old, is still an excellent reference for data-related issues. And
the \emph{R Data Import/Export} manual, available online at
\url{http://catalog.lib.msu.edu/record=b7254984~S39a} , is an up-to-date
(and free) reference on importing a wide variety of datasets into R and
on exporting data in various forms.

\section{Reading Data into R}\label{reading-data-into-r}

Data come in a dizzying variety of forms. It might be in a proprietary
format such as an
\href{https://en.wikipedia.org/wiki/Microsoft_Excel}{.xlsx} Excel file,
a \href{https://en.wikipedia.org/wiki/SPSS}{.sav} SPSS file, or a
\href{https://en.wikipedia.org/wiki/Minitab}{.mtw} Minitab file. It
might be structured using a
\href{https://en.wikipedia.org/wiki/Relational_model\%7D\%7Brelational\%20model}{relational
model} comprising many tables that need to be connected via key-value
pairs. It might be a data-interchange format such as
\href{http://www.json.org/}{JSON} (JavaScript Object Notation), or a
markup language such as \href{https://en.wikipedia.org/wiki/XML}{XML}
(Extensible Markup Language), perhaps with specialized standards for
describing ecological information, see
\href{https://en.wikipedia.org/wiki/Ecological_Metadata_Language}{EML}
(Ecological Metadata Language). Both XML and EML are common data
metadata formats (i.e., data that provides information about other
data). Fortunately many datasets are (or can be) saved as plain text
files, and most software can both read and write such files, so our
initial focus will be on reading plain text files into R and saving data
from R in plain text format. RStudio provides a handy
\href{http://www.rstudio.com/resources/cheatsheets}{data import cheat
sheet} for many of the read functions detailed in this section.

The \texttt{foreign} R package provides functions to directly read data
saved in some of the proprietary formats into R, which is sometimes
unavoidable, but if possible it is good to save data from another
package as plain text and then read this plain text file into R. In
Chapter \ref{xml} methods for reading web-based data sets into R will be
discussed.

The function \texttt{read.table()} and its offshoots such as
\texttt{read.csv()} are used to read in rectangular data from a text
file. For example, the file \texttt{BrainAndBody.csv} contains
data\footnote{These data come from the \texttt{MASS} R library.} on the
brain weight, body weight, and name of some terrestrial animals. Here
are the first few lines of that file:

\begin{verbatim}
body,brain,name
1.35,8.1,Mountain beaver
465,423,Cow
36.33,119.5,Grey wolf
27.66,115,Goat
1.04,5.5,Guinea pig
\end{verbatim}

As is evident, the first line of the file contains the names of the
three variables, separated (delimited) by commas. Each subsequent line
contains the body weight, brain weight, and name of a specific
terrestrial animal.

This file is accessible at the url
\url{http://blue.for.msu.edu/FOR875/data/BrainAndBody.csv}. The
\texttt{read.table()} function is used to read these data into an R data
frame.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.bb <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/BrainAndBody.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{BrainBody <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\DataTypeTok{file =}\NormalTok{ u.bb, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{","}\NormalTok{, }
\OperatorTok{+}\StringTok{                         }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(BrainBody)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      body brain            name
1     1.35   8.1 Mountain beaver
2   465.00 423.0             Cow
3    36.33 119.5       Grey wolf
4    27.66 115.0            Goat
5     1.04   5.5      Guinea pig
6 11700.00  50.0     Dipliodocus
\end{verbatim}

The arguments used in this call to \texttt{read.table()} include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{file\ =\ u.bb}, which tells R the location of the file. In
  this case the string
  \texttt{http://blue.for.msu.edu/FOR875/data/BrainAndBody.csv} giving
  the location is rather long, so it was first assigned to the object
  \texttt{u.bb}.
\item
  \texttt{header\ =\ TRUE}, which tells R the first line of the file
  gives the names of the variables.
\item
  \texttt{sep\ =\ ","}, which tells R that a comma separates the fields
  in the file.
\item
  \texttt{stringsAsFactors\ =\ FALSE} which tells R not to convert
  character vectors to factors.
\end{enumerate}

The function \texttt{read.csv()} is the same as \texttt{read.table()}
except the default separator is a comma, whereas the default separator
for \texttt{read.table()} is whitespace.

The file \texttt{BrainAndBody.tsv} contains the same data, except a tab
is used in place of a comma to separate fields. The only change needed
to read in the data in this file is in the \texttt{sep} argument (and of
course the \texttt{file} argument, since the data are stored in a
different file):

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.bb <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/BrainAndBody.tsv"}
\OperatorTok{>}\StringTok{ }\NormalTok{BrainBody2 <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\DataTypeTok{file =}\NormalTok{ u.bb, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{"}\CharTok{\textbackslash{}t}\StringTok{"}\NormalTok{, }
\OperatorTok{+}\StringTok{                          }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(BrainBody2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      body brain            name
1     1.35   8.1 Mountain beaver
2   465.00 423.0             Cow
3    36.33 119.5       Grey wolf
4    27.66 115.0            Goat
5     1.04   5.5      Guinea pig
6 11700.00  50.0     Dipliodocus
\end{verbatim}

File extensions, e.g., \texttt{.csv} or \texttt{.tsv}, are naming
conventions only and are there to remind us how the columns are
separated. In other words, they have no influence on R's file read
functions.

A third file, \texttt{BrainAndBody.txt}, contains the same data, but
also contains a few lines of explanatory text above the names of the
variables. It also uses whitespace rather than a comma or a tab as a
separator. Here are the first several lines of the file.

\begin{verbatim}
This file contains data
on brain and body
weights of several terrestrial animals

"body" "brain" "name"
1.35 8.1 "Mountain beaver"
465 423 "Cow"
36.33 119.5 "Grey wolf"
27.66 115 "Goat"
1.04 5.5 "Guinea pig"
11700 50 "Dipliodocus"
2547 4603 "Asian elephant"
\end{verbatim}

Notice that in this file the values of \texttt{name} are put inside of
quotation marks. This is necessary since instead R would (reasonably)
assume the first line contained the values of four variables, the values
being \texttt{1.35}, \texttt{8.1}, \texttt{Mountain}, and
\texttt{beaver} while in reality there are only three values desired,
with \texttt{Mountain\ beaver} being the third.

To read in this file we need to tell R to skip the first five lines and
to use whitespace as the separator. The \texttt{skip} argument handles
the first, and the \texttt{sep} argument the second. First let's see
what happens if we don't use the \texttt{skip} argument.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.bb <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/BrainAndBody.txt"}
\OperatorTok{>}\StringTok{ }\NormalTok{BrainBody3 <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(u.bb, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{" "}\NormalTok{, }
\OperatorTok{+}\StringTok{                          }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 1 did not have 5 elements
\end{verbatim}

R assumed the first line of the file contained the variable names, since
\texttt{header\ =\ TRUE} was specified, and counted four including
\texttt{This}, \texttt{file}, \texttt{contains}, and \texttt{data}. So
in the first line of actual data, R expected four columns containing
data plus possibly a fifth column containing row names for the data set,
and complained that ``line 1 did not have 5 elements.'' The error
message is somewhat mysterious, since it starts with ``Error in scan.''
This happens because \texttt{read.table()} actually uses a more basic R
function called \texttt{scan()} to do the work.

Here's how to read in the file correctly.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.bb <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/BrainAndBody.txt"}
\OperatorTok{>}\StringTok{ }\NormalTok{BrainBody3 <-}\StringTok{ }\KeywordTok{read.table}\NormalTok{(u.bb, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{" "}\NormalTok{, }
\OperatorTok{+}\StringTok{                          }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{skip =} \DecValTok{4}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{BrainBody3[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       body  brain            name
1      1.35    8.1 Mountain beaver
2    465.00  423.0             Cow
3     36.33  119.5       Grey wolf
4     27.66  115.0            Goat
5      1.04    5.5      Guinea pig
6  11700.00   50.0     Dipliodocus
7   2547.00 4603.0  Asian elephant
8    187.10  419.0          Donkey
9    521.00  655.0           Horse
10    10.00  115.0    Potar monkey
\end{verbatim}

\section{Reading Data with Missing
Observations}\label{reading-data-with-missing-observations}

Missing data are represented in many ways. Sometimes a missing data
point is just that, i.e., the place where it should be in the file is
blank. Other times specific numbers such as \(-9999\) or specific
symbols are used. The \texttt{read.table()} function has an argument
\texttt{na.string} that allows the user to specify how missing data is
indicated in the source file.

The site \url{http://www.wunderground.com/history/} makes weather data
available for locations around the world from dates going back to 1945.
The file \texttt{WeatherKLAN2014.csv} contains weather data for Lansing,
Michigan for the year 2014. Here are the first few lines of that file:

\begin{verbatim}
EST,Max TemperatureF,Min TemperatureF, Events
1/1/14,14,9,Snow
1/2/14,13,-3,Snow
1/3/14,13,-11,Snow
1/4/14,31,13,Snow
1/5/14,29,16,Fog-Snow
1/6/14,16,-12,Fog-Snow
1/7/14,2,-13,Snow
1/8/14,17,-1,Snow
1/9/14,21,2,Snow
1/10/14,39,21,Fog-Rain-Snow
1/11/14,41,32,Fog-Rain
1/12/14,39,31,
\end{verbatim}

Look at the last line, and notice that instead of an \texttt{Event} such
as \texttt{Snow} or \texttt{Fog-Snow} there is nothing after the comma.
This observation is missing, but rather than using an explicit code such
as \texttt{NA}, the site just leaves that entry blank. To read these
data into R we will supply the argument \texttt{na.string\ =\ ""} which
tells R the file indicates missing data by leaving the appropriate entry
blank.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.weather <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/WeatherKLAN2014.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{WeatherKLAN2014 <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.weather, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }
\OperatorTok{+}\StringTok{                             }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{na.string =} \StringTok{""}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{WeatherKLAN2014[}\DecValTok{1}\OperatorTok{:}\DecValTok{15}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       EST Max.TemperatureF Min.TemperatureF
1   1/1/14               14                9
2   1/2/14               13               -3
3   1/3/14               13              -11
4   1/4/14               31               13
5   1/5/14               29               16
6   1/6/14               16              -12
7   1/7/14                2              -13
8   1/8/14               17               -1
9   1/9/14               21                2
10 1/10/14               39               21
11 1/11/14               41               32
12 1/12/14               39               31
13 1/13/14               44               34
14 1/14/14               37               26
15 1/15/14               27               18
          Events
1           Snow
2           Snow
3           Snow
4           Snow
5       Fog-Snow
6       Fog-Snow
7           Snow
8           Snow
9           Snow
10 Fog-Rain-Snow
11      Fog-Rain
12          <NA>
13          Rain
14     Rain-Snow
15          Snow
\end{verbatim}

\section{Summarizing Data Frames}\label{summarizing-data-frames}

Some common data tasks include variable summaries such as means or
standard deviations, transforming an existing variable, and creating new
variables. As with many tasks, there are several ways to accomplish each
of these.

\subsection{Column (and Row) Summaries}\label{column-and-row-summaries}

The file \texttt{WeatherKLAN2014Full.csv} contains a more complete set
of weather data variables than \texttt{WeatherKLAN2014.csv}, from the
same source, \url{http://www.wunderground.com/history}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.weather <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/WeatherKLAN2014Full.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{WeatherKLAN2014Full <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.weather, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }
\OperatorTok{+}\StringTok{                                }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{, }
\OperatorTok{+}\StringTok{                                }\DataTypeTok{na.string =} \StringTok{""}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(WeatherKLAN2014Full)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "EST"                      
 [2] "Max.TemperatureF"         
 [3] "Mean.TemperatureF"        
 [4] "Min.TemperatureF"         
 [5] "Max.Dew.PointF"           
 [6] "MeanDew.PointF"           
 [7] "Min.DewpointF"            
 [8] "Max.Humidity"             
 [9] "Mean.Humidity"            
[10] "Min.Humidity"             
[11] "Max.Sea.Level.PressureIn" 
[12] "Mean.Sea.Level.PressureIn"
[13] "Min.Sea.Level.PressureIn" 
[14] "Max.VisibilityMiles"      
[15] "Mean.VisibilityMiles"     
[16] "Min.VisibilityMiles"      
[17] "Max.Wind.SpeedMPH"        
[18] "Mean.Wind.SpeedMPH"       
[19] "Max.Gust.SpeedMPH"        
[20] "PrecipitationIn"          
[21] "CloudCover"               
[22] "Events"                   
[23] "WindDirDegrees"           
\end{verbatim}

How can we compute the mean for each variable? One possibility is to do
this a variable at a time:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(WeatherKLAN2014Full}\OperatorTok{$}\NormalTok{Mean.TemperatureF)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 45.78
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(WeatherKLAN2014Full}\OperatorTok{$}\NormalTok{Min.TemperatureF)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 36.25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(WeatherKLAN2014Full}\OperatorTok{$}\NormalTok{Max.TemperatureF)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 54.84
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{##Et Cetera}
\end{Highlighting}
\end{Shaded}

This is pretty inefficient. Fortunately there is a \texttt{colMeans()}
function which computes the mean of each column (or a specified number
of columns) in a data frame. Some columns in the current data frame are
not numeric, and obviously we don't want to ask R to compute means for
these columns. We use \texttt{str()} to investigate.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(WeatherKLAN2014Full)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   365 obs. of  23 variables:
 $ EST                      : chr  "2014-1-1" "2014-1-2" "2014-1-3" "2014-1-4" ...
 $ Max.TemperatureF         : int  14 13 13 31 29 16 2 17 21 39 ...
 $ Mean.TemperatureF        : int  12 5 1 22 23 2 -5 8 12 30 ...
 $ Min.TemperatureF         : int  9 -3 -11 13 16 -12 -13 -1 2 21 ...
 $ Max.Dew.PointF           : int  9 7 2 27 27 11 -6 7 18 37 ...
 $ MeanDew.PointF           : int  4 4 -5 18 21 -4 -13 1 8 28 ...
 $ Min.DewpointF            : int  0 -8 -14 3 11 -18 -18 -6 0 19 ...
 $ Max.Humidity             : int  88 76 83 92 92 80 78 88 88 100 ...
 $ Mean.Humidity            : int  76 70 68 73 86 73 72 78 75 92 ...
 $ Min.Humidity             : int  63 63 53 53 80 65 65 67 62 84 ...
 $ Max.Sea.Level.PressureIn : num  30.4 30.4 30.5 30.1 30 ...
 $ Mean.Sea.Level.PressureIn: num  30.3 30.2 30.4 30 29.9 ...
 $ Min.Sea.Level.PressureIn : num  30.2 30.1 30.1 29.9 29.7 ...
 $ Max.VisibilityMiles      : int  10 9 10 10 4 10 10 10 10 9 ...
 $ Mean.VisibilityMiles     : int  4 4 10 6 1 2 6 10 7 3 ...
 $ Min.VisibilityMiles      : int  1 0 5 1 0 0 1 8 2 0 ...
 $ Max.Wind.SpeedMPH        : int  17 22 23 28 22 31 25 15 14 17 ...
 $ Mean.Wind.SpeedMPH       : int  9 13 10 15 11 18 15 7 6 10 ...
 $ Max.Gust.SpeedMPH        : int  22 30 32 36 30 40 31 18 17 22 ...
 $ PrecipitationIn          : chr  "0.08" "0.01" "0.00" "0.12" ...
 $ CloudCover               : int  8 7 1 5 8 8 6 5 7 8 ...
 $ Events                   : chr  "Snow" "Snow" "Snow" "Snow" ...
 $ WindDirDegrees           : int  43 24 205 203 9 262 220 236 147 160 ...
\end{verbatim}

It isn't surprising that \texttt{EST} and \texttt{Events} are not
numeric, but is surprising that \texttt{PrecipitationIn}, which measures
precipitation in inches, also is not numeric, but is character. Let's
investigate further.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{WeatherKLAN2014Full}\OperatorTok{$}\NormalTok{PrecipitationIn[}\DecValTok{1}\OperatorTok{:}\DecValTok{50}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "0.08" "0.01" "0.00" "0.12" "0.78" "0.07" "T"   
 [8] "T"    "0.01" "0.39" "0.16" "0.00" "0.00" "0.01"
[15] "T"    "0.08" "T"    "T"    "T"    "0.01" "0.00"
[22] "0.05" "T"    "T"    "0.07" "0.23" "0.04" "T"   
[29] "T"    "0.03" "T"    "0.37" "T"    "0.00" "T"   
[36] "0.27" "0.01" "T"    "0.04" "0.03" "T"    "0.00"
[43] "0.00" "T"    "T"    "0.00" "0.02" "0.15" "0.08"
[50] "0.01"
\end{verbatim}

Now it's more clear. The original data file included \texttt{T} in the
precipitation column to represent a ``trace'' of precipitation, which is
precipitation greater than \(0\) but less than \(0.01\) inches. One
possibility would be to set all these values to \texttt{"0"}, and then
to convert the column to numeric. For now we will just leave the
\texttt{PrecipitationIn} column out of the columns for which we request
the mean.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{colMeans}\NormalTok{(WeatherKLAN2014Full[,}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{19}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{23}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         Max.TemperatureF         Mean.TemperatureF 
                   54.838                    45.781 
         Min.TemperatureF            Max.Dew.PointF 
                   36.255                    41.800 
           MeanDew.PointF             Min.DewpointF 
                   36.395                    30.156 
             Max.Humidity             Mean.Humidity 
                   88.082                    70.392 
             Min.Humidity  Max.Sea.Level.PressureIn 
                   52.200                    30.130 
Mean.Sea.Level.PressureIn  Min.Sea.Level.PressureIn 
                   30.015                    29.904 
      Max.VisibilityMiles      Mean.VisibilityMiles 
                    9.896                     8.249 
      Min.VisibilityMiles         Max.Wind.SpeedMPH 
                    4.825                    19.101 
       Mean.Wind.SpeedMPH         Max.Gust.SpeedMPH 
                    8.679                        NA 
               CloudCover            WindDirDegrees 
                    4.367                   205.000 
\end{verbatim}

\subsection{\texorpdfstring{The \texttt{apply()}
Function}{The apply() Function}}\label{apply}

R also has functions \texttt{rowMeans()}, \texttt{colSums()}, and
\texttt{rowSums()}. But what if we want to compute the median or
standard deviation of columns of data, or some other summary statistic?
For this the \texttt{apply()} function can be used. This function
applies a user-chosen function to either the rows or columns (or both)
of a data frame. The arguments are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{X}: the data frame of interest
\item
  \texttt{MARGIN}: specifying either rows (\texttt{MARGIN\ =\ 1}) or
  columns (\texttt{MARGIN\ =\ 2})
\item
  \texttt{FUN}: the function to be applied.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{apply}\NormalTok{(}\DataTypeTok{X =}\NormalTok{ WeatherKLAN2014Full[,}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{19}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{23}\NormalTok{)], }\DataTypeTok{MARGIN =} \DecValTok{2}\NormalTok{, }\DataTypeTok{FUN =}\NormalTok{ sd)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         Max.TemperatureF         Mean.TemperatureF 
                  22.2130                   20.9729 
         Min.TemperatureF            Max.Dew.PointF 
                  20.2597                   19.5167 
           MeanDew.PointF             Min.DewpointF 
                  20.0311                   20.8511 
             Max.Humidity             Mean.Humidity 
                   8.1910                    9.3660 
             Min.Humidity  Max.Sea.Level.PressureIn 
                  13.9462                    0.2032 
Mean.Sea.Level.PressureIn  Min.Sea.Level.PressureIn 
                   0.2159                    0.2360 
      Max.VisibilityMiles      Mean.VisibilityMiles 
                   0.5790                    2.1059 
      Min.VisibilityMiles         Max.Wind.SpeedMPH 
                   3.8168                    6.4831 
       Mean.Wind.SpeedMPH         Max.Gust.SpeedMPH 
                   3.8863                        NA 
               CloudCover            WindDirDegrees 
                   2.7798                   90.0673 
\end{verbatim}

As with any R function the arguments don't need to be named as long as
they are specified in the correct order, so

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{apply}\NormalTok{(WeatherKLAN2014Full[,}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{19}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{23}\NormalTok{)], }\DecValTok{2}\NormalTok{, sd)}
\end{Highlighting}
\end{Shaded}

has the same result.

\subsection{Practice Problems}\label{practice-problems}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Notice the output value of \texttt{NA} for the column
  \texttt{Max.Gust.SpeedMPH}. Why does this happen? Figure out a way to
  make the \texttt{apply()} function return a numeric value for this
  column.
\item
  The \texttt{apply()} family of functions is extremely important in R,
  so it gets two Practice Problems :) Use the \texttt{apply()} function
  to compute the median values for all numeric columns in the
  \texttt{iris} data set.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{apply}\NormalTok{(WeatherKLAN2014Full[,}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{19}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{23}\NormalTok{)], }\DecValTok{2}\NormalTok{, sd, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{apply}\NormalTok{(iris[, }\OperatorTok{-}\DecValTok{5}\NormalTok{], }\DecValTok{2}\NormalTok{, median)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Saving Typing Using
\texttt{with()}}{Saving Typing Using with()}}\label{saving-typing-using-with}

Consider calculating the mean of the maximum temperature values for
those days where the cloud cover is less than 4 and when the maximum
humidity is over 85. We can do this using subsetting.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mean}\NormalTok{(WeatherKLAN2014Full}\OperatorTok{$}\NormalTok{Max.TemperatureF[}
\OperatorTok{+}\StringTok{                              }\NormalTok{WeatherKLAN2014Full}\OperatorTok{$}\NormalTok{CloudCover }\OperatorTok{<}\StringTok{ }\DecValTok{4} \OperatorTok{&}\StringTok{ }
\OperatorTok{+}\StringTok{                              }\NormalTok{WeatherKLAN2014Full}\OperatorTok{$}\NormalTok{Max.Humidity }\OperatorTok{>}\StringTok{ }\DecValTok{85}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 69.39
\end{verbatim}

While this works, it requires a lot of typing, since each time we refer
to a variable in the data set we need to preface its name by
\texttt{WeatherKLAN2014Full\$}. The \texttt{with()} function tells R
that we are working with a particular data frame, and we don't need to
keep typing the name of the data frame.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{with}\NormalTok{(WeatherKLAN2014Full, }
\OperatorTok{+}\StringTok{      }\KeywordTok{mean}\NormalTok{(Max.TemperatureF[CloudCover }\OperatorTok{<}\StringTok{ }\DecValTok{4} \OperatorTok{&}\StringTok{ }\NormalTok{Max.Humidity }\OperatorTok{>}\StringTok{ }\DecValTok{85}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 69.39
\end{verbatim}

\section{Transforming a Data Frame}\label{transforming-a-data-frame}

Variables are often added to, removed from, changed in, or rearranged in
a data frame. The subsetting features of R make this reasonably easy. We
will investigate this in the context of the \texttt{gapminder} data
frame. If the \texttt{gapminder} library is not yet installed, use
\texttt{install.packages("gapminder")} to install it locally.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(gapminder)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  6 variables:
 $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
 $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap: num  779 821 853 836 740 ...
\end{verbatim}

\subsection{Adding Variables}\label{adding-variables}

The data frame contains per capita GDP and population, and it might be
interesting to create a variable that gives the total GDP by multiplying
these two variables. (If we were interested in an accurate value for the
total GDP we would probably be better off getting this information
directly, since it is likely that the per capita GDP values in the data
frame are rounded substantially.)

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{TotalGDP <-}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{gdpPercap }\OperatorTok{*}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{pop}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  7 variables:
 $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
 $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap: num  779 821 853 836 740 ...
 $ TotalGDP : num  6.57e+09 7.59e+09 8.76e+09 9.65e+09 9.68e+09 ...
\end{verbatim}

Analogous to the \texttt{with()} function, there is a function
\texttt{within()} which can simplify the syntax. Whereas \texttt{with()}
does not change the data frame, \texttt{within()} can. Note, below I
first remove the altered gapminder dataframe using \texttt{rm()} then
bring a clean copy back in by reloading the \texttt{gapminder} package.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rm}\NormalTok{(gapminder)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(gapminder)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  6 variables:
 $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
 $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap: num  779 821 853 836 740 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder <-}\StringTok{ }\KeywordTok{within}\NormalTok{(gapminder, TotalGDP <-}\StringTok{ }\NormalTok{gdpPercap }\OperatorTok{*}\StringTok{ }\NormalTok{pop)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  7 variables:
 $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
 $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap: num  779 821 853 836 740 ...
 $ TotalGDP : num  6.57e+09 7.59e+09 8.76e+09 9.65e+09 9.68e+09 ...
\end{verbatim}

A nice feature of \texttt{within()} is its ability to add more than one
variable at a time to a data frame. In this case the two or more
formulas creating new variables must be enclosed in braces.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder <-}\StringTok{ }\KeywordTok{within}\NormalTok{(gapminder, \{TotalGDP <-}\StringTok{ }\NormalTok{gdpPercap }\OperatorTok{*}\StringTok{ }\NormalTok{pop}
\OperatorTok{+}\StringTok{     }\NormalTok{lifeExpMonths <-}\StringTok{ }\NormalTok{lifeExp }\OperatorTok{*}\StringTok{ }\DecValTok{12}\NormalTok{\})}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  8 variables:
 $ country      : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent    : Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year         : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp      : num  28.8 30.3 32 34 36.1 ...
 $ pop          : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap    : num  779 821 853 836 740 ...
 $ TotalGDP     : num  6.57e+09 7.59e+09 8.76e+09 9.65e+09 9.68e+09 ...
 $ lifeExpMonths: num  346 364 384 408 433 ...
\end{verbatim}

\subsection{Removing Variables}\label{removing-variables}

After reflection we may realize the new variables we added to the
\texttt{gapminder} data frame are not useful, and should be removed.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  8 variables:
 $ country      : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent    : Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year         : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp      : num  28.8 30.3 32 34 36.1 ...
 $ pop          : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap    : num  779 821 853 836 740 ...
 $ TotalGDP     : num  6.57e+09 7.59e+09 8.76e+09 9.65e+09 9.68e+09 ...
 $ lifeExpMonths: num  346 364 384 408 433 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder <-}\StringTok{ }\NormalTok{gapminder[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  6 variables:
 $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
 $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
 $ gdpPercap: num  779 821 853 836 740 ...
\end{verbatim}

The same result could be obtained via
\texttt{gapminder\ \textless{}-\ gapminder{[},\ 1:6{]}}. The first
method uses the fact that a data frame is also a list, and uses list
subsetting methods. It is slightly preferable, since even if only one
variable is retained, the object will still be a data frame, while the
other method can return a vector in this case. Note this difference in
the resulting \texttt{x} variable below (again this behavior can be
frustrating at times if it is not anticipated).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{a <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"pig"}\NormalTok{), }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{z =} \KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{1}\NormalTok{, }\DataTypeTok{to =} \DecValTok{2}\NormalTok{, }\DataTypeTok{length =} \DecValTok{3}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  x   y   z
1 1 dog 1.0
2 2 cat 1.5
3 3 pig 2.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{a <-}\StringTok{ }\NormalTok{a[}\DecValTok{1}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{a }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  x
1 1
2 2
3 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{a <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"pig"}\NormalTok{), }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{z =} \KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{1}\NormalTok{, }\DataTypeTok{to =} \DecValTok{2}\NormalTok{, }\DataTypeTok{length =} \DecValTok{3}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\NormalTok{a }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  x   y   z
1 1 dog 1.0
2 2 cat 1.5
3 3 pig 2.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{a <-}\StringTok{ }\NormalTok{a[,}\DecValTok{1}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 3
\end{verbatim}

One can also use a negative sign in front of the variable number(s). For
example, \texttt{a{[}-(2:3){]}} would drop the first two columns of
\texttt{a}. Some care is needed when removing variables using the
negative sign.

An alternative approach is to set the variables you'd like to remove to
\texttt{NULL}. For example,
\texttt{a{[}c("y","z"){]}\ \textless{}-\ NULL} and
\texttt{a{[},2:3{]}\ \textless{}-\ NULL} produce the same result as
above.

\subsection{Practice Problem}\label{practice-problem-6}

What happens if you write \texttt{a{[}-2:3{]}} instead of
\texttt{a{[}-(2:3){]}}? Why are the parentheses important here?

\subsection{Transforming Variables}\label{transforming-variables}

Consider the gapminder data again. Possibly we don't want to add a new
variable that gives life expectancy in months, but rather want to modify
the existing variable to measure life expectancy in months. Here are two
ways to accomplish this.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rm}\NormalTok{(gapminder)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(gapminder)}
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{lifeExp[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 28.80 30.33 32.00 34.02 36.09
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{lifeExp <-}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{lifeExp }\OperatorTok{*}\StringTok{ }\DecValTok{12}
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{lifeExp[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 345.6 364.0 384.0 408.2 433.1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rm}\NormalTok{(gapminder)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(gapminder)}
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{lifeExp[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 28.80 30.33 32.00 34.02 36.09
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder <-}\StringTok{ }\KeywordTok{within}\NormalTok{(gapminder, lifeExp <-}\StringTok{ }\NormalTok{lifeExp }\OperatorTok{*}\StringTok{ }\DecValTok{12}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{gapminder}\OperatorTok{$}\NormalTok{lifeExp[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 345.6 364.0 384.0 408.2 433.1
\end{verbatim}

\section{Rearranging Variables}\label{rearranging-variables}

Consider the full weather data set again.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.weather <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/WeatherKLAN2014Full.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{WeatherKLAN2014Full <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.weather, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }
\OperatorTok{+}\StringTok{                                 }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{,}
\OperatorTok{+}\StringTok{                                 }\DataTypeTok{na.string =} \StringTok{""}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(WeatherKLAN2014Full)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "EST"                      
 [2] "Max.TemperatureF"         
 [3] "Mean.TemperatureF"        
 [4] "Min.TemperatureF"         
 [5] "Max.Dew.PointF"           
 [6] "MeanDew.PointF"           
 [7] "Min.DewpointF"            
 [8] "Max.Humidity"             
 [9] "Mean.Humidity"            
[10] "Min.Humidity"             
[11] "Max.Sea.Level.PressureIn" 
[12] "Mean.Sea.Level.PressureIn"
[13] "Min.Sea.Level.PressureIn" 
[14] "Max.VisibilityMiles"      
[15] "Mean.VisibilityMiles"     
[16] "Min.VisibilityMiles"      
[17] "Max.Wind.SpeedMPH"        
[18] "Mean.Wind.SpeedMPH"       
[19] "Max.Gust.SpeedMPH"        
[20] "PrecipitationIn"          
[21] "CloudCover"               
[22] "Events"                   
[23] "WindDirDegrees"           
\end{verbatim}

If we want the wind speed variables to come right after the date, we can
again use subsetting.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{WeatherKLAN2014Full <-}\StringTok{ }\NormalTok{WeatherKLAN2014Full[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{2}\OperatorTok{:}\DecValTok{16}\NormalTok{, }\DecValTok{20}\OperatorTok{:}\DecValTok{23}\NormalTok{)]}
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(WeatherKLAN2014Full)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "EST"                      
 [2] "Max.Wind.SpeedMPH"        
 [3] "Mean.Wind.SpeedMPH"       
 [4] "Max.Gust.SpeedMPH"        
 [5] "Max.TemperatureF"         
 [6] "Mean.TemperatureF"        
 [7] "Min.TemperatureF"         
 [8] "Max.Dew.PointF"           
 [9] "MeanDew.PointF"           
[10] "Min.DewpointF"            
[11] "Max.Humidity"             
[12] "Mean.Humidity"            
[13] "Min.Humidity"             
[14] "Max.Sea.Level.PressureIn" 
[15] "Mean.Sea.Level.PressureIn"
[16] "Min.Sea.Level.PressureIn" 
[17] "Max.VisibilityMiles"      
[18] "Mean.VisibilityMiles"     
[19] "Min.VisibilityMiles"      
[20] "PrecipitationIn"          
[21] "CloudCover"               
[22] "Events"                   
[23] "WindDirDegrees"           
\end{verbatim}

\section{Reshaping Data}\label{reshaping-data}

A data set can be represented in several different formats. Consider a
(fictitious) data set on incomes of three people during three different
years. Here is one representation of the data:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{yearlyIncomeWide}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          name income1990 income2000 income2010
1   John Smith      29784      39210      41213
2     Jane Doe      56789      89321     109321
3 Albert Jones       2341      34567      56781
\end{verbatim}

Here is another representation of the same data:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{yearlyIncomeLong}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          name       year income
1   John Smith income1990  29784
2     Jane Doe income1990  56789
3 Albert Jones income1990   2341
4   John Smith income2000  39210
5     Jane Doe income2000  89321
6 Albert Jones income2000  34567
7   John Smith income2010  41213
8     Jane Doe income2010 109321
9 Albert Jones income2010  56781
\end{verbatim}

For hopefully obvious reasons, the first representation is called a
\emph{wide} representation of the data, and the second is called a
\emph{long} representation. Each has its merits. The first
representation is probably easier for people to read, while the second
is often the form needed for analysis by statistical software such as R.
There are of course other representations. For example the rows and
columns could be interchanged to create a different wide representation,
or the long representation, which currently groups data by year, could
group by name instead.

Whatever the relative merits of wide and long representations of data,
transforming data from wide to long or long to wide is often required.
As with many tasks, there are several ways to accomplish this in R. We
will focus on a library called \texttt{tidyr} written by Hadley Wickham
that performs the transformations and more.

\subsection{\texorpdfstring{\texttt{tidyr}}{tidyr}}\label{tidyr}

The R library \texttt{tidyr} has functions for converting data between
formats. To illustrate its use, we examine a simple data set that
explores the relationship between religion and income in the United
States. The data come from a Pew survey, and are used in the
\texttt{tidyr} documentation to illustrate transforming data from wide
to long format.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.rel <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/religion2.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{religion <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.rel, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(religion)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            religion under10k btw10and20k btw20and30k
1           Agnostic       27          34          60
2            Atheist       12          27          37
3           Buddhist       27          21          30
4           Catholic      418         617         732
5 DoNotKnowOrRefused       15          14          15
6    EvangelicalProt      575         869        1064
  btw30and40k btw40and50k btw50and75k btw75and100k
1          81          76         137          122
2          52          35          70           73
3          34          33          58           62
4         670         638        1116          949
5          11          10          35           21
6         982         881        1486          949
  btw100and150k over150k DoNotKnowOrRefused
1           109       84                 96
2            59       74                 76
3            39       53                 54
4           792      633               1489
5            17       18                116
6           723      414               1529
\end{verbatim}

As given, the columns include religion and income level, and there are
counts for each of the combinations of religion and income level. For
example, there are 27 people who are Agnostic and whose income is less
than 10 thousand dollars, and there are 617 people who are Catholic and
whose income is between 10 and 20 thousand dollars.

The \texttt{gather()} function can transform data from wide to long
format.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(tidyr)}
\OperatorTok{>}\StringTok{ }\NormalTok{religionLong <-}\StringTok{ }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ religion, }\DataTypeTok{key =}\NormalTok{ IncomeLevel, }
\OperatorTok{+}\StringTok{                        }\DataTypeTok{value =}\NormalTok{ Frequency, }\DecValTok{2}\OperatorTok{:}\DecValTok{11}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(religionLong)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            religion IncomeLevel Frequency
1           Agnostic    under10k        27
2            Atheist    under10k        12
3           Buddhist    under10k        27
4           Catholic    under10k       418
5 DoNotKnowOrRefused    under10k        15
6    EvangelicalProt    under10k       575
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{tail}\NormalTok{(religionLong)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
               religion        IncomeLevel Frequency
175              Muslim DoNotKnowOrRefused        22
176            Orthodox DoNotKnowOrRefused        73
177      OtherChristian DoNotKnowOrRefused        18
178         OtherFaiths DoNotKnowOrRefused        71
179 OtherWorldReligions DoNotKnowOrRefused         8
180        Unaffiliated DoNotKnowOrRefused       597
\end{verbatim}

To use \texttt{gather()} we specified the data frame
(\texttt{data\ =\ religion}), the name we want to give to the column
created from the income levels (\texttt{key\ =\ IncomeLevel}), the name
we want to give to the column containing the frequency values
(\texttt{value\ =\ Frequency}) and the columns to gather
(\texttt{2:11}).

Columns to be gathered can be specified by name also, and we can also
specify which columns should be omitted using a negative sign in front
of the name(s). So the following creates an equivalent data frame:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{religionLong <-}\StringTok{ }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ religion, }\DataTypeTok{key =}\NormalTok{ IncomeLevel, }
\OperatorTok{+}\StringTok{                        }\DataTypeTok{value =}\NormalTok{ Frequency, }\OperatorTok{-}\NormalTok{religion)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(religionLong)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            religion IncomeLevel Frequency
1           Agnostic    under10k        27
2            Atheist    under10k        12
3           Buddhist    under10k        27
4           Catholic    under10k       418
5 DoNotKnowOrRefused    under10k        15
6    EvangelicalProt    under10k       575
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{religionWide <-}\StringTok{ }\KeywordTok{spread}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ religionLong, }\DataTypeTok{key =}\NormalTok{ IncomeLevel, }
\OperatorTok{+}\StringTok{                        }\DataTypeTok{value =}\NormalTok{ Frequency)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(religionWide)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            religion btw100and150k btw10and20k
1           Agnostic           109          34
2            Atheist            59          27
3           Buddhist            39          21
4           Catholic           792         617
5 DoNotKnowOrRefused            17          14
6    EvangelicalProt           723         869
  btw20and30k btw30and40k btw40and50k btw50and75k
1          60          81          76         137
2          37          52          35          70
3          30          34          33          58
4         732         670         638        1116
5          15          11          10          35
6        1064         982         881        1486
  btw75and100k DoNotKnowOrRefused over150k under10k
1          122                 96       84       27
2           73                 76       74       12
3           62                 54       53       27
4          949               1489      633      418
5           21                116       18       15
6          949               1529      414      575
\end{verbatim}

Here we specify the data frame (\texttt{religionLong}), the column
(\texttt{IncomeLevel}) to be spread, and the column of values
(\texttt{Frequency}) to be spread among the newly created columns. As
can be seen, this particular call to \texttt{spread()} yields the
original data frame.

\texttt{tidyr} provides two other useful functions to separate and unite
variables based on some deliminator. Consider again the
\texttt{yearlyIncomeWide} table. Say we want to split the \texttt{name}
variable into first and last name. This can be done using the
\texttt{separate()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{firstLast <-}\StringTok{ }\KeywordTok{separate}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ yearlyIncomeLong, }\DataTypeTok{col =}\NormalTok{ name, }
\OperatorTok{+}\StringTok{                       }\DataTypeTok{into =} \KeywordTok{c}\NormalTok{(}\StringTok{"first"}\NormalTok{, }\StringTok{"last"}\NormalTok{), }\DataTypeTok{sep=}\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{s"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{print}\NormalTok{(firstLast)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   first  last       year income
1   John Smith income1990  29784
2   Jane   Doe income1990  56789
3 Albert Jones income1990   2341
4   John Smith income2000  39210
5   Jane   Doe income2000  89321
6 Albert Jones income2000  34567
7   John Smith income2010  41213
8   Jane   Doe income2010 109321
9 Albert Jones income2010  56781
\end{verbatim}

Now say, you're not happy with that and you want to combine the name
column again, but this time separate the first and last name with a
underscore. This is done using the \texttt{unite()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unite}\NormalTok{(firstLast, }\DataTypeTok{col=}\NormalTok{name, first, last, }\DataTypeTok{sep=}\StringTok{"_"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          name       year income
1   John_Smith income1990  29784
2     Jane_Doe income1990  56789
3 Albert_Jones income1990   2341
4   John_Smith income2000  39210
5     Jane_Doe income2000  89321
6 Albert_Jones income2000  34567
7   John_Smith income2010  41213
8     Jane_Doe income2010 109321
9 Albert_Jones income2010  56781
\end{verbatim}

\subsection{Practice Problem}\label{practice-problem-7}

The \texttt{separate()} function from the \texttt{tidyr} library is
especially useful when working with real data as multiple pieces of
information can be combined into one column in a data set. For example,
consider the following data frame

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{data.birds}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  birds recordingInfo
1    10 LA-2017-01-01
2    38 DF-2011-03-02
3    29 OG-2078-05-11
4    88 YA-2000-11-18
5    42 LA-2019-03-17
6   177 OG-2016-10-10
7   200 YA-2001-03-22
\end{verbatim}

``RecordingInfo'' that contains the site where data was collected, as
well as the year, month, and date the data was recorded. The data are
coded as follows: \texttt{site-year-month-day}. Write a line of code
that will extract the desired data from the \texttt{data.birds} data
frame into separate columns named \texttt{site}, \texttt{year},
\texttt{month} and \texttt{day}.

\section{\texorpdfstring{Manipulating Data with
\texttt{dplyr}}{Manipulating Data with dplyr}}\label{dplyr}

Much of the effort (a figure of 80\% is sometimes suggested) in data
analysis is spent cleaning the data and getting it ready for analysis.
Having effective tools for this task can save substantial time and
effort. The R package \texttt{dplyr} written by Hadley Wickham is
designed, in Hadley's words, to be ``a grammar of data manipulation,
providing a consistent set of verbs that help you solve the most common
data manipulation challenges.'' Casting data analysis tasks in terms of
``grammar'' should be familiar from our work with the \texttt{ggplot2}
package, which was also authored by Hadley. Functions provided by
\texttt{dplyr} do in fact capture key data analysis actions (i.e.,
verbs). These functions include

\begin{itemize}
\tightlist
\item
  \texttt{mutate()} adds new variables that are functions of existing
  variables
\item
  \texttt{select()} picks variables based on their names
\item
  \texttt{filter()} picks cases based on their values
\item
  \texttt{summarize()} reduces multiple values down to a single summary
\item
  \texttt{arrange()} changes the ordering of the rows.
\end{itemize}

These all combine naturally with a \texttt{group\_by()} function that
allows you to perform any operation grouped by values of one or more
variables. All the tasks done using \texttt{dplyr} can be accomplished
using tools already covered in this text; however, \texttt{dplyr}'s
functions provide a potentially more efficient and convenient framework
to accomplish these tasks. RStudio provides a convenient
\href{https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf}{data
wrangling cheat sheet} that covers many aspects of the \texttt{tidyr}
and \texttt{dplyr} packages.

This somewhat long section on \texttt{dplyr} adapts the nice
introduction by Jenny Bryan, available at
\url{http://stat545-ubc.github.io/block010_dplyr-end-single-table.html}.

\subsection{Improved Data Frames}\label{improved-data-frames}

The \texttt{dplyr} package provides a couple functions that offer
improvements on data frames. First, \texttt{tibble} creates a tibble
from a series of vectors\footnote{Reminds me of
  \href{https://en.wikipedia.org/wiki/The_Trouble_with_Tribbles}{The
  Trouble with Tribbles}}. A tibble has two advantages over a data
frame. First, when printing, it only prints the first ten rows and the
columns that fit on the page, as well as some additional information
about the table's dimension, data type of variables, and non-printed
columns. Second, recall that subsetting a data frame can sometimes
return a vector rather than a data frame (if only one row or column is
the result of the subset), a tibble does not have this behavior. Second,
we can use the \texttt{as\_tibble()} function to convert an existing
data frame or list into a tibble. Here is an example using the
\texttt{religionWide} data frame.\footnote{The text printed immediately
  after \texttt{library(dplyr)} means the \texttt{stats} and
  \texttt{base} packages, which are automatically loaded when you start
  R, have functions with the same name as functions in \texttt{dplyr}.
  So, for example, if you call the \texttt{filter()} or \texttt{lag()}
  functions, R will use \texttt{library(dplyr)}`s functions. Use the
  \texttt{::} operator to explicity identify which packages' function
  you want to use, e.g., if you want \texttt{stats}'s \texttt{lag()}
  then call \texttt{stats::lag()}.}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dplyr)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(religionWide)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            religion btw100and150k btw10and20k
1           Agnostic           109          34
2            Atheist            59          27
3           Buddhist            39          21
4           Catholic           792         617
5 DoNotKnowOrRefused            17          14
6    EvangelicalProt           723         869
  btw20and30k btw30and40k btw40and50k btw50and75k
1          60          81          76         137
2          37          52          35          70
3          30          34          33          58
4         732         670         638        1116
5          15          11          10          35
6        1064         982         881        1486
  btw75and100k DoNotKnowOrRefused over150k under10k
1          122                 96       84       27
2           73                 76       74       12
3           62                 54       53       27
4          949               1489      633      418
5           21                116       18       15
6          949               1529      414      575
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{religionWide[,}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "Agnostic"              "Atheist"              
 [3] "Buddhist"              "Catholic"             
 [5] "DoNotKnowOrRefused"    "EvangelicalProt"      
 [7] "Hindu"                 "HistoricallyBlackProt"
 [9] "JehovahsWitness"       "Jewish"               
[11] "MainlineProt"          "Mormon"               
[13] "Muslim"                "Orthodox"             
[15] "OtherChristian"        "OtherFaiths"          
[17] "OtherWorldReligions"   "Unaffiliated"         
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{religionWideTbl <-}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{(religionWide)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(religionWideTbl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 11
  religion btw100and150k btw10and20k btw20and30k
  <chr>            <int>       <int>       <int>
1 Agnostic           109          34          60
2 Atheist             59          27          37
3 Buddhist            39          21          30
4 Catholic           792         617         732
5 DoNotKn~            17          14          15
6 Evangel~           723         869        1064
# ... with 7 more variables: btw30and40k <int>,
#   btw40and50k <int>, btw50and75k <int>,
#   btw75and100k <int>, DoNotKnowOrRefused <int>,
#   over150k <int>, under10k <int>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{religionWideTbl[,}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 18 x 1
   religion             
   <chr>                
 1 Agnostic             
 2 Atheist              
 3 Buddhist             
 4 Catholic             
 5 DoNotKnowOrRefused   
 6 EvangelicalProt      
 7 Hindu                
 8 HistoricallyBlackProt
 9 JehovahsWitness      
10 Jewish               
11 MainlineProt         
12 Mormon               
13 Muslim               
14 Orthodox             
15 OtherChristian       
16 OtherFaiths          
17 OtherWorldReligions  
18 Unaffiliated         
\end{verbatim}

As seen above, note that once the data frame is reduced to one dimension
by subsetting to one column, it is no longer a data frame and has been
\emph{simplified} to a vector. This might not seem like a big deal;
however, it can be very frustrating and potentially break your code when
you expect an object to behave like a data frame and it doesn't because
it's now a vector. Alternatively, once we convert \texttt{religionWide}
to a \texttt{tibble} via the \texttt{as\_tibble()} function the object
remains a data frame even when subsetting down to one dimension (there
is no automatic simplification). Converting data frames using
\texttt{as\_tibble()} is not required for using \texttt{dplyr} but is
convenient. Also, it is important to note that \texttt{tibble} is simply
a wrapper around a data frame that provides some additional behaviors.
The newly formed \texttt{tibble} object will still behave like a data
frame (because it technically still is a data frame) but will have some
added niceties (some of which are illustrated below).

\subsection{Filtering Data by Row}\label{filtering-data-by-row}

Recall the \texttt{gapminder} data. These data are available in
tab-separated format in \texttt{gapminder.tsv}, and can be read in using
\texttt{read.delim()} (or the related read functions described
previously). The \texttt{read.delim()} function defaults to
\texttt{header\ =\ TRUE} so this doesn't need to be specified
explicitly. In this section we will be working with the
\texttt{gapminder} data often, so we will use a short name for the data
frame to save typing.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.gm <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/gapminder.tsv"}
\OperatorTok{>}\StringTok{ }\NormalTok{gm <-}\StringTok{ }\KeywordTok{read.delim}\NormalTok{(u.gm)}
\OperatorTok{>}\StringTok{ }\NormalTok{gm <-}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{(gm)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(gm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Classes 'tbl_df', 'tbl' and 'data.frame':   1704 obs. of  6 variables:
 $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
 $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...
 $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
 $ gdpPercap: num  779 821 853 836 740 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(gm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 6
  country      year     pop continent lifeExp gdpPercap
  <fct>       <int>   <dbl> <fct>       <dbl>     <dbl>
1 Afghanistan  1952  8.43e6 Asia         28.8      779.
2 Afghanistan  1957  9.24e6 Asia         30.3      821.
3 Afghanistan  1962  1.03e7 Asia         32.0      853.
4 Afghanistan  1967  1.15e7 Asia         34.0      836.
5 Afghanistan  1972  1.31e7 Asia         36.1      740.
6 Afghanistan  1977  1.49e7 Asia         38.4      786.
\end{verbatim}

Filtering helps us to examine subsets of the data such as data from a
particular country, from several specified countries, from certain
years, from countries with certain populations, etc. Some examples:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{filter}\NormalTok{(gm, country }\OperatorTok{==}\StringTok{ "Brazil"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 6
   country  year       pop continent lifeExp gdpPercap
   <fct>   <int>     <dbl> <fct>       <dbl>     <dbl>
 1 Brazil   1952  56602560 Americas     50.9     2109.
 2 Brazil   1957  65551171 Americas     53.3     2487.
 3 Brazil   1962  76039390 Americas     55.7     3337.
 4 Brazil   1967  88049823 Americas     57.6     3430.
 5 Brazil   1972 100840058 Americas     59.5     4986.
 6 Brazil   1977 114313951 Americas     61.5     6660.
 7 Brazil   1982 128962939 Americas     63.3     7031.
 8 Brazil   1987 142938076 Americas     65.2     7807.
 9 Brazil   1992 155975974 Americas     67.1     6950.
10 Brazil   1997 168546719 Americas     69.4     7958.
11 Brazil   2002 179914212 Americas     71.0     8131.
12 Brazil   2007 190010647 Americas     72.4     9066.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{filter}\NormalTok{(gm, country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Brazil"}\NormalTok{, }\StringTok{"Mexico"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 24 x 6
   country  year       pop continent lifeExp gdpPercap
   <fct>   <int>     <dbl> <fct>       <dbl>     <dbl>
 1 Brazil   1952  56602560 Americas     50.9     2109.
 2 Brazil   1957  65551171 Americas     53.3     2487.
 3 Brazil   1962  76039390 Americas     55.7     3337.
 4 Brazil   1967  88049823 Americas     57.6     3430.
 5 Brazil   1972 100840058 Americas     59.5     4986.
 6 Brazil   1977 114313951 Americas     61.5     6660.
 7 Brazil   1982 128962939 Americas     63.3     7031.
 8 Brazil   1987 142938076 Americas     65.2     7807.
 9 Brazil   1992 155975974 Americas     67.1     6950.
10 Brazil   1997 168546719 Americas     69.4     7958.
# ... with 14 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{filter}\NormalTok{(gm, country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Brazil"}\NormalTok{, }\StringTok{"Mexico"}\NormalTok{) }\OperatorTok{&}\StringTok{ }\NormalTok{year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1952}\NormalTok{, }\DecValTok{1972}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 6
  country  year       pop continent lifeExp gdpPercap
  <fct>   <int>     <dbl> <fct>       <dbl>     <dbl>
1 Brazil   1952  56602560 Americas     50.9     2109.
2 Brazil   1972 100840058 Americas     59.5     4986.
3 Mexico   1952  30144317 Americas     50.8     3478.
4 Mexico   1972  55984294 Americas     62.4     6809.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{filter}\NormalTok{(gm, pop }\OperatorTok{>}\StringTok{ }\DecValTok{300000000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 25 x 6
   country  year        pop continent lifeExp gdpPercap
   <fct>   <int>      <dbl> <fct>       <dbl>     <dbl>
 1 China    1952     5.56e8 Asia         44        400.
 2 China    1957     6.37e8 Asia         50.5      576.
 3 China    1962     6.66e8 Asia         44.5      488.
 4 China    1967     7.55e8 Asia         58.4      613.
 5 China    1972     8.62e8 Asia         63.1      677.
 6 China    1977     9.43e8 Asia         64.0      741.
 7 China    1982     1.00e9 Asia         65.5      962.
 8 China    1987     1.08e9 Asia         67.3     1379.
 9 China    1992     1.16e9 Asia         68.7     1656.
10 China    1997     1.23e9 Asia         70.4     2289.
# ... with 15 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{filter}\NormalTok{(gm, pop }\OperatorTok{>}\StringTok{ }\DecValTok{300000000} \OperatorTok{&}\StringTok{ }\NormalTok{year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 6
  country     year      pop continent lifeExp gdpPercap
  <fct>      <int>    <dbl> <fct>       <dbl>     <dbl>
1 China       2007   1.32e9 Asia         73.0     4959.
2 India       2007   1.11e9 Asia         64.7     2452.
3 United St~  2007   3.01e8 Americas     78.2    42952.
\end{verbatim}

Notice the full results are not printed. For example, when we asked for
the data for Brazil and Mexico, only the first ten rows were printed.
This is an effect of using the \texttt{as\_tibble()} function. Of course
if we wanted to analyze the results (as we will below) the full set of
data would be available.

\subsection{Selecting variables by
column}\label{selecting-variables-by-column}

Continuing with the \texttt{gapminder} data, another common task is to
restrict attention to some subset of variables in the data set. The
\texttt{select()} function does this.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{select}\NormalTok{(gm, country, year, lifeExp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 3
   country      year lifeExp
   <fct>       <int>   <dbl>
 1 Afghanistan  1952    28.8
 2 Afghanistan  1957    30.3
 3 Afghanistan  1962    32.0
 4 Afghanistan  1967    34.0
 5 Afghanistan  1972    36.1
 6 Afghanistan  1977    38.4
 7 Afghanistan  1982    39.9
 8 Afghanistan  1987    40.8
 9 Afghanistan  1992    41.7
10 Afghanistan  1997    41.8
# ... with 1,694 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{select}\NormalTok{(gm, }\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 3
    year      pop continent
   <int>    <dbl> <fct>    
 1  1952  8425333 Asia     
 2  1957  9240934 Asia     
 3  1962 10267083 Asia     
 4  1967 11537966 Asia     
 5  1972 13079460 Asia     
 6  1977 14880372 Asia     
 7  1982 12881816 Asia     
 8  1987 13867957 Asia     
 9  1992 16317921 Asia     
10  1997 22227415 Asia     
# ... with 1,694 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{select}\NormalTok{(gm, }\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 3
   country     lifeExp gdpPercap
   <fct>         <dbl>     <dbl>
 1 Afghanistan    28.8      779.
 2 Afghanistan    30.3      821.
 3 Afghanistan    32.0      853.
 4 Afghanistan    34.0      836.
 5 Afghanistan    36.1      740.
 6 Afghanistan    38.4      786.
 7 Afghanistan    39.9      978.
 8 Afghanistan    40.8      852.
 9 Afghanistan    41.7      649.
10 Afghanistan    41.8      635.
# ... with 1,694 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{select}\NormalTok{(gm, }\KeywordTok{starts_with}\NormalTok{(}\StringTok{"c"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 2
   country     continent
   <fct>       <fct>    
 1 Afghanistan Asia     
 2 Afghanistan Asia     
 3 Afghanistan Asia     
 4 Afghanistan Asia     
 5 Afghanistan Asia     
 6 Afghanistan Asia     
 7 Afghanistan Asia     
 8 Afghanistan Asia     
 9 Afghanistan Asia     
10 Afghanistan Asia     
# ... with 1,694 more rows
\end{verbatim}

Notice a few things. Variables can be selected by name or column number.
As usual, a negative sign tells R to leave something out. And there are
special functions such as \texttt{starts\_with} that provide ways to
match part of a variable's name.

\subsection{Practice Problem}\label{practice-problem-8}

Use the \texttt{contains()} function to select only the columns that
contain a \texttt{c}

\subsection{Pipes}\label{pipes}

Consider selecting the country, year, and population for countries in
Asia or Europe. One possibility is to nest a \texttt{filter()} function
inside a \texttt{select()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{select}\NormalTok{(}\KeywordTok{filter}\NormalTok{(gm, continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Asia"}\NormalTok{, }\StringTok{"Europe"}\NormalTok{)), country, year, pop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 756 x 3
   country      year      pop
   <fct>       <int>    <dbl>
 1 Afghanistan  1952  8425333
 2 Afghanistan  1957  9240934
 3 Afghanistan  1962 10267083
 4 Afghanistan  1967 11537966
 5 Afghanistan  1972 13079460
 6 Afghanistan  1977 14880372
 7 Afghanistan  1982 12881816
 8 Afghanistan  1987 13867957
 9 Afghanistan  1992 16317921
10 Afghanistan  1997 22227415
# ... with 746 more rows
\end{verbatim}

Even a two-step process like this becomes hard to follow in this nested
form, and often we will want to perform more than two operations. There
is a nice feature in \texttt{dplyr} that allows us to ``feed'' results
of one function into the first argument of a subsequent function.
Another way of saying this is that we are ``piping'' the results into
another function. The \texttt{\%\textgreater{}\%} operator does the
piping. Here we again restrict attention to country, year, and
population for countries in Asia or Europe\footnote{Notice the
  indentation used in the code. This is not necessary, as the code could
  be all on one line, but I often find it easier to read in this more
  organized format}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Asia"}\NormalTok{, }\StringTok{"Europe"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(country, year, pop)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 756 x 3
   country      year      pop
   <fct>       <int>    <dbl>
 1 Afghanistan  1952  8425333
 2 Afghanistan  1957  9240934
 3 Afghanistan  1962 10267083
 4 Afghanistan  1967 11537966
 5 Afghanistan  1972 13079460
 6 Afghanistan  1977 14880372
 7 Afghanistan  1982 12881816
 8 Afghanistan  1987 13867957
 9 Afghanistan  1992 16317921
10 Afghanistan  1997 22227415
# ... with 746 more rows
\end{verbatim}

It can help to think of \texttt{\%\textgreater{}\%} as representing the
word ``then''. The above can be read as, ``Start with the data frame
\texttt{gm} \emph{then} filter it to select data from the continents
Asia and Europe \emph{then} select the variables country, year, and
population from these data''.

The pipe operator \texttt{\%\textgreater{}\%} is not restricted to
functions in \texttt{dplyr}. In fact the pipe operator itself was
introduced in another package called \texttt{magrittr}, but is included
in \texttt{dplyr} as a convenience.

\subsection{Arranging Data by Row}\label{arranging-data-by-row}

By default the \texttt{gapminder} data are arranged by country and then
by year.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(gm, }\DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 15 x 6
   country     year     pop continent lifeExp gdpPercap
   <fct>      <int>   <dbl> <fct>       <dbl>     <dbl>
 1 Afghanist~  1952  8.43e6 Asia         28.8      779.
 2 Afghanist~  1957  9.24e6 Asia         30.3      821.
 3 Afghanist~  1962  1.03e7 Asia         32.0      853.
 4 Afghanist~  1967  1.15e7 Asia         34.0      836.
 5 Afghanist~  1972  1.31e7 Asia         36.1      740.
 6 Afghanist~  1977  1.49e7 Asia         38.4      786.
 7 Afghanist~  1982  1.29e7 Asia         39.9      978.
 8 Afghanist~  1987  1.39e7 Asia         40.8      852.
 9 Afghanist~  1992  1.63e7 Asia         41.7      649.
10 Afghanist~  1997  2.22e7 Asia         41.8      635.
11 Afghanist~  2002  2.53e7 Asia         42.1      727.
12 Afghanist~  2007  3.19e7 Asia         43.8      975.
13 Albania     1952  1.28e6 Europe       55.2     1601.
14 Albania     1957  1.48e6 Europe       59.3     1942.
15 Albania     1962  1.73e6 Europe       64.8     2313.
\end{verbatim}

Possibly arranging the data by year and then country would be desired.
The \texttt{arrange()} function makes this easy. We will again use
pipes.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(year, country)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 6
   country     year     pop continent lifeExp gdpPercap
   <fct>      <int>   <dbl> <fct>       <dbl>     <dbl>
 1 Afghanist~  1952  8.43e6 Asia         28.8      779.
 2 Albania     1952  1.28e6 Europe       55.2     1601.
 3 Algeria     1952  9.28e6 Africa       43.1     2449.
 4 Angola      1952  4.23e6 Africa       30.0     3521.
 5 Argentina   1952  1.79e7 Americas     62.5     5911.
 6 Australia   1952  8.69e6 Oceania      69.1    10040.
 7 Austria     1952  6.93e6 Europe       66.8     6137.
 8 Bahrain     1952  1.20e5 Asia         50.9     9867.
 9 Bangladesh  1952  4.69e7 Asia         37.5      684.
10 Belgium     1952  8.73e6 Europe       68       8343.
# ... with 1,694 more rows
\end{verbatim}

How about the data for Rwanda, arranged in order of life expectancy.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "Rwanda"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(lifeExp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 6
   country  year     pop continent lifeExp gdpPercap
   <fct>   <int>   <dbl> <fct>       <dbl>     <dbl>
 1 Rwanda   1992 7290203 Africa       23.6      737.
 2 Rwanda   1997 7212583 Africa       36.1      590.
 3 Rwanda   1952 2534927 Africa       40        493.
 4 Rwanda   1957 2822082 Africa       41.5      540.
 5 Rwanda   1962 3051242 Africa       43        597.
 6 Rwanda   2002 7852401 Africa       43.4      786.
 7 Rwanda   1987 6349365 Africa       44.0      848.
 8 Rwanda   1967 3451079 Africa       44.1      511.
 9 Rwanda   1972 3992121 Africa       44.6      591.
10 Rwanda   1977 4657072 Africa       45        670.
11 Rwanda   1982 5507565 Africa       46.2      882.
12 Rwanda   2007 8860588 Africa       46.2      863.
\end{verbatim}

Possibly we want these data to be in decreasing (descending) order.
Here, \texttt{desc()} is one of many \texttt{dplyr} helper functions.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "Rwanda"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(lifeExp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 6
   country  year     pop continent lifeExp gdpPercap
   <fct>   <int>   <dbl> <fct>       <dbl>     <dbl>
 1 Rwanda   2007 8860588 Africa       46.2      863.
 2 Rwanda   1982 5507565 Africa       46.2      882.
 3 Rwanda   1977 4657072 Africa       45        670.
 4 Rwanda   1972 3992121 Africa       44.6      591.
 5 Rwanda   1967 3451079 Africa       44.1      511.
 6 Rwanda   1987 6349365 Africa       44.0      848.
 7 Rwanda   2002 7852401 Africa       43.4      786.
 8 Rwanda   1962 3051242 Africa       43        597.
 9 Rwanda   1957 2822082 Africa       41.5      540.
10 Rwanda   1952 2534927 Africa       40        493.
11 Rwanda   1997 7212583 Africa       36.1      590.
12 Rwanda   1992 7290203 Africa       23.6      737.
\end{verbatim}

Possibly we want to include only the year and life expectancy, to make
the message more stark.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "Rwanda"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(year, lifeExp) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(lifeExp)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 2
    year lifeExp
   <int>   <dbl>
 1  2007    46.2
 2  1982    46.2
 3  1977    45  
 4  1972    44.6
 5  1967    44.1
 6  1987    44.0
 7  2002    43.4
 8  1962    43  
 9  1957    41.5
10  1952    40  
11  1997    36.1
12  1992    23.6
\end{verbatim}

For analyzing data in R, the order shouldn't matter. But for
presentation to human eyes, the order is important.

\subsection{Practice Problem}\label{practice-problem-9}

It is worth your while to get comfortable with using pipes. Here is some
hard-to-read code. Convert it into more easier to read code by using
pipes.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{select}\NormalTok{(}\KeywordTok{filter}\NormalTok{(gm, country }\OperatorTok{==}\StringTok{ "Afghanistan"}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\StringTok{"year"}\NormalTok{, }\StringTok{"lifeExp"}\NormalTok{)), }\DataTypeTok{desc =}\NormalTok{ lifeExp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 2
    year lifeExp
   <int>   <dbl>
 1  1952    28.8
 2  1957    30.3
 3  1962    32.0
 4  1967    34.0
 5  1972    36.1
 6  1977    38.4
 7  1982    39.9
 8  1987    40.8
 9  1992    41.7
10  1997    41.8
11  2002    42.1
12  2007    43.8
\end{verbatim}

\subsection{Renaming Variables}\label{renaming-variables}

The \texttt{dplyr} package has a \texttt{rename} function that makes
renaming variables in a data frame quite easy.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm <-}\StringTok{ }\KeywordTok{rename}\NormalTok{(gm, }\DataTypeTok{population =}\NormalTok{ pop)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(gm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 6
  country   year population continent lifeExp gdpPercap
  <fct>    <int>      <dbl> <fct>       <dbl>     <dbl>
1 Afghani~  1952    8425333 Asia         28.8      779.
2 Afghani~  1957    9240934 Asia         30.3      821.
3 Afghani~  1962   10267083 Asia         32.0      853.
4 Afghani~  1967   11537966 Asia         34.0      836.
5 Afghani~  1972   13079460 Asia         36.1      740.
6 Afghani~  1977   14880372 Asia         38.4      786.
\end{verbatim}

\subsection{Data Summaries and
Grouping}\label{data-summaries-and-grouping}

The \texttt{summarize()} function computes summary statistics using user
provided functions for one or more columns of data in a data frame.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{summarize}\NormalTok{(gm, }\DataTypeTok{meanpop =} \KeywordTok{mean}\NormalTok{(population), }\DataTypeTok{medpop =} \KeywordTok{median}\NormalTok{(population))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 2
    meanpop   medpop
      <dbl>    <dbl>
1 29601212. 7023596.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{##or}
\ErrorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{meanpop =} \KeywordTok{mean}\NormalTok{(population), }\DataTypeTok{medpop =} \KeywordTok{median}\NormalTok{(population))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 2
    meanpop   medpop
      <dbl>    <dbl>
1 29601212. 7023596.
\end{verbatim}

Often we want summaries for specific components of the data. For
example, we might want the median life expectancy for each continent
separately. One option is subsetting:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{median}\NormalTok{(gm}\OperatorTok{$}\NormalTok{lifeExp[gm}\OperatorTok{$}\NormalTok{continent }\OperatorTok{==}\StringTok{ "Africa"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 47.79
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{median}\NormalTok{(gm}\OperatorTok{$}\NormalTok{lifeExp[gm}\OperatorTok{$}\NormalTok{continent }\OperatorTok{==}\StringTok{ "Asia"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 61.79
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{median}\NormalTok{(gm}\OperatorTok{$}\NormalTok{lifeExp[gm}\OperatorTok{$}\NormalTok{continent }\OperatorTok{==}\StringTok{ "Europe"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 72.24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{median}\NormalTok{(gm}\OperatorTok{$}\NormalTok{lifeExp[gm}\OperatorTok{$}\NormalTok{continent }\OperatorTok{==}\StringTok{ "Americas"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 67.05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{median}\NormalTok{(gm}\OperatorTok{$}\NormalTok{lifeExp[gm}\OperatorTok{$}\NormalTok{continent }\OperatorTok{==}\StringTok{ "Oceania"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 73.66
\end{verbatim}

The \texttt{group\_by()} function makes this easier, and makes the
output more useful.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{medLifeExp =} \KeywordTok{median}\NormalTok{(lifeExp)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 5 x 2
  continent medLifeExp
  <fct>          <dbl>
1 Africa          47.8
2 Americas        67.0
3 Asia            61.8
4 Europe          72.2
5 Oceania         73.7
\end{verbatim}

Or if we want the results ordered by the median life expectancy:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{medLifeExp =} \KeywordTok{median}\NormalTok{(lifeExp)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(medLifeExp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 5 x 2
  continent medLifeExp
  <fct>          <dbl>
1 Africa          47.8
2 Asia            61.8
3 Americas        67.0
4 Europe          72.2
5 Oceania         73.7
\end{verbatim}

As another example, we calculate the number of observations we have per
continent (using the \texttt{n()} helper function), and then, among
continents, how many distinct countries are represented (using
\texttt{n\_distinct()}).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{numObs =} \KeywordTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 5 x 2
  continent numObs
  <fct>      <int>
1 Africa       624
2 Americas     300
3 Asia         396
4 Europe       360
5 Oceania       24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n_obs =} \KeywordTok{n}\NormalTok{(), }\DataTypeTok{n_countries =} \KeywordTok{n_distinct}\NormalTok{(country))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 5 x 3
  continent n_obs n_countries
  <fct>     <int>       <int>
1 Africa      624          52
2 Americas    300          25
3 Asia        396          33
4 Europe      360          30
5 Oceania      24           2
\end{verbatim}

Here is a bit more involved example that calculates the minimum and
maximum life expectancies for countries in Africa by year.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Africa"}\NormalTok{) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{min_lifeExp =} \KeywordTok{min}\NormalTok{(lifeExp), }\DataTypeTok{max_lifeExp =} \KeywordTok{max}\NormalTok{(lifeExp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 3
    year min_lifeExp max_lifeExp
   <int>       <dbl>       <dbl>
 1  1952        30          52.7
 2  1957        31.6        58.1
 3  1962        32.8        60.2
 4  1967        34.1        61.6
 5  1972        35.4        64.3
 6  1977        36.8        67.1
 7  1982        38.4        69.9
 8  1987        39.9        71.9
 9  1992        23.6        73.6
10  1997        36.1        74.8
11  2002        39.2        75.7
12  2007        39.6        76.4
\end{verbatim}

This is interesting, but the results don't include the countries that
achieved the minimum and maximum life expectancies. Here is one way to
achieve that. We will start with the minimum life expectancy. Note the
rank of the minimum value will be 1.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(country, continent, year, lifeExp) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(year) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(}\KeywordTok{rank}\NormalTok{(lifeExp) }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 12 x 4
# Groups:   year [12]
   country      continent  year lifeExp
   <fct>        <fct>     <int>   <dbl>
 1 Afghanistan  Asia       1952    28.8
 2 Afghanistan  Asia       1957    30.3
 3 Afghanistan  Asia       1962    32.0
 4 Afghanistan  Asia       1967    34.0
 5 Sierra Leone Africa     1972    35.4
 6 Cambodia     Asia       1977    31.2
 7 Sierra Leone Africa     1982    38.4
 8 Angola       Africa     1987    39.9
 9 Rwanda       Africa     1992    23.6
10 Rwanda       Africa     1997    36.1
11 Zambia       Africa     2002    39.2
12 Swaziland    Africa     2007    39.6
\end{verbatim}

Next we add the maximum life expectancy. Here we need to better
understand the \texttt{desc()} function, which will transform a vector
into a numeric vector which will be sorted in descending order. Here are
some examples.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{desc}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -1 -2 -3 -4 -5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{desc}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\OperatorTok{-}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -2 -3 -1 -5 -6  4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{desc}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"w"}\NormalTok{, }\StringTok{"e"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -1 -3 -2 -5 -4
\end{verbatim}

We now use this to extract the maximum life expectancy. Recall that
\texttt{\textbar{}} represents ``or''. Also by default only the first
few rows of a \texttt{tibble} object will be printed. To see all the
rows we pipe the output to \texttt{print(n\ =\ 24)} to ask for all 24
rows to be printed.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(country, continent, year, lifeExp) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(year) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(}\KeywordTok{rank}\NormalTok{(lifeExp) }\OperatorTok{==}\StringTok{ }\DecValTok{1} \OperatorTok{|}\StringTok{ }\KeywordTok{rank}\NormalTok{(}\KeywordTok{desc}\NormalTok{(lifeExp)) }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{print}\NormalTok{(}\DataTypeTok{n=}\DecValTok{24}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 24 x 4
# Groups:   year [12]
   country      continent  year lifeExp
   <fct>        <fct>     <int>   <dbl>
 1 Afghanistan  Asia       1952    28.8
 2 Norway       Europe     1952    72.7
 3 Afghanistan  Asia       1957    30.3
 4 Iceland      Europe     1957    73.5
 5 Afghanistan  Asia       1962    32.0
 6 Iceland      Europe     1962    73.7
 7 Afghanistan  Asia       1967    34.0
 8 Sweden       Europe     1967    74.2
 9 Sierra Leone Africa     1972    35.4
10 Sweden       Europe     1972    74.7
11 Cambodia     Asia       1977    31.2
12 Iceland      Europe     1977    76.1
13 Japan        Asia       1982    77.1
14 Sierra Leone Africa     1982    38.4
15 Angola       Africa     1987    39.9
16 Japan        Asia       1987    78.7
17 Japan        Asia       1992    79.4
18 Rwanda       Africa     1992    23.6
19 Japan        Asia       1997    80.7
20 Rwanda       Africa     1997    36.1
21 Japan        Asia       2002    82  
22 Zambia       Africa     2002    39.2
23 Japan        Asia       2007    82.6
24 Swaziland    Africa     2007    39.6
\end{verbatim}

\subsection{Creating New Variables}\label{creating-new-variables}

The \texttt{\$} notation provides a simple way to create new variables
in a data frame. The \texttt{mutate()} function provides another,
sometimes cleaner way to do this. We will use \texttt{mutate()} along
with the \texttt{lag()} function to investigate changes in life
expectancy over five years for the \texttt{gapminder} data. We'll do
this in a few steps. First, we create a variable that measures the
change in life expectancy and remove the population and GDP variables
that are not of interest. We have to be careful to first group by
country, since we want to calculate the change in life expectancy by
country.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(country) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{changeLifeExp =}\NormalTok{ lifeExp }\OperatorTok{-}\StringTok{ }\KeywordTok{lag}\NormalTok{(lifeExp, }\DataTypeTok{order_by =}\NormalTok{ year)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(population, gdpPercap))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 5
# Groups:   country [142]
   country      year continent lifeExp changeLifeExp
   <fct>       <int> <fct>       <dbl>         <dbl>
 1 Afghanistan  1952 Asia         28.8       NA     
 2 Afghanistan  1957 Asia         30.3        1.53  
 3 Afghanistan  1962 Asia         32.0        1.66  
 4 Afghanistan  1967 Asia         34.0        2.02  
 5 Afghanistan  1972 Asia         36.1        2.07  
 6 Afghanistan  1977 Asia         38.4        2.35  
 7 Afghanistan  1982 Asia         39.9        1.42  
 8 Afghanistan  1987 Asia         40.8        0.968 
 9 Afghanistan  1992 Asia         41.7        0.852 
10 Afghanistan  1997 Asia         41.8        0.0890
# ... with 1,694 more rows
\end{verbatim}

Next, summarize by computing the largest drop in life expectancy.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(country) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{changeLifeExp =}\NormalTok{ lifeExp }\OperatorTok{-}\StringTok{ }\KeywordTok{lag}\NormalTok{(lifeExp, }\DataTypeTok{order_by =}\NormalTok{ year)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(population, gdpPercap)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{largestDropLifeExp =} \KeywordTok{min}\NormalTok{(changeLifeExp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 142 x 2
   country     largestDropLifeExp
   <fct>                    <dbl>
 1 Afghanistan                 NA
 2 Albania                     NA
 3 Algeria                     NA
 4 Angola                      NA
 5 Argentina                   NA
 6 Australia                   NA
 7 Austria                     NA
 8 Bahrain                     NA
 9 Bangladesh                  NA
10 Belgium                     NA
# ... with 132 more rows
\end{verbatim}

Oops. We forgot that since we don't have data from before 1952, the
first drop will be \texttt{NA}. Let's try again.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(country) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{changeLifeExp =}\NormalTok{ lifeExp }\OperatorTok{-}\StringTok{ }\KeywordTok{lag}\NormalTok{(lifeExp, }\DataTypeTok{order_by =}\NormalTok{ year)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(population, gdpPercap)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{largestDropLifeExp =} \KeywordTok{min}\NormalTok{(changeLifeExp, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 142 x 2
   country     largestDropLifeExp
   <fct>                    <dbl>
 1 Afghanistan             0.0890
 2 Albania                -0.419 
 3 Algeria                 1.31  
 4 Angola                 -0.036 
 5 Argentina               0.492 
 6 Australia               0.170 
 7 Austria                 0.490 
 8 Bahrain                 0.84  
 9 Bangladesh              1.67  
10 Belgium                 0.5   
# ... with 132 more rows
\end{verbatim}

That's not quite what we wanted. We could arrange the results by the
life expectancy drop, but it would be good to have both the continent
and year printed out also. So we'll take a slightly different approach,
by arranging the results in increasing order.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(country) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{changeLifeExp =}\NormalTok{ lifeExp }\OperatorTok{-}\StringTok{ }\KeywordTok{lag}\NormalTok{(lifeExp, }\DataTypeTok{order_by =}\NormalTok{ year)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(population, gdpPercap)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(changeLifeExp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 5
# Groups:   country [142]
   country       year continent lifeExp changeLifeExp
   <fct>        <int> <fct>       <dbl>         <dbl>
 1 Rwanda        1992 Africa       23.6        -20.4 
 2 Zimbabwe      1997 Africa       46.8        -13.6 
 3 Lesotho       2002 Africa       44.6        -11.0 
 4 Swaziland     2002 Africa       43.9        -10.4 
 5 Botswana      1997 Africa       52.6        -10.2 
 6 Cambodia      1977 Asia         31.2         -9.10
 7 Namibia       2002 Africa       51.5         -7.43
 8 South Africa  2002 Africa       53.4         -6.87
 9 Zimbabwe      2002 Africa       40.0         -6.82
10 China         1962 Asia         44.5         -6.05
# ... with 1,694 more rows
\end{verbatim}

That's still not quite right. Because the data are grouped by country, R
did the ordering within group. If we want to see the largest drops
overall, we need to remove the grouping.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gm }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(country) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{changeLifeExp =}\NormalTok{ lifeExp }\OperatorTok{-}\StringTok{ }\KeywordTok{lag}\NormalTok{(lifeExp, }\DataTypeTok{order_by =}\NormalTok{ year)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(population, gdpPercap)) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(changeLifeExp) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{print}\NormalTok{(}\DataTypeTok{n=}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,704 x 5
   country       year continent lifeExp changeLifeExp
   <fct>        <int> <fct>       <dbl>         <dbl>
 1 Rwanda        1992 Africa       23.6        -20.4 
 2 Zimbabwe      1997 Africa       46.8        -13.6 
 3 Lesotho       2002 Africa       44.6        -11.0 
 4 Swaziland     2002 Africa       43.9        -10.4 
 5 Botswana      1997 Africa       52.6        -10.2 
 6 Cambodia      1977 Asia         31.2         -9.10
 7 Namibia       2002 Africa       51.5         -7.43
 8 South Africa  2002 Africa       53.4         -6.87
 9 Zimbabwe      2002 Africa       40.0         -6.82
10 China         1962 Asia         44.5         -6.05
11 Botswana      2002 Africa       46.6         -5.92
12 Zambia        1997 Africa       40.2         -5.86
13 Iraq          1992 Asia         59.5         -5.58
14 Liberia       1992 Africa       40.8         -5.23
15 Cambodia      1972 Asia         40.3         -5.10
16 Kenya         1997 Africa       54.4         -4.88
17 Somalia       1992 Africa       39.7         -4.84
18 Zambia        1992 Africa       46.1         -4.72
19 Swaziland     2007 Africa       39.6         -4.26
20 Uganda        1997 Africa       44.6         -4.25
# ... with 1,684 more rows
\end{verbatim}

\subsection{Practice Problem}\label{practice-problem-10}

As you progress in your data science related career, we are sure you
will find \texttt{dplyr} as one of the most useful packages for your
initial data exploration. Here is one more Practice Problem to get more
comfortable with the syntax.

Recall the \texttt{iris} data set we have worked with multiple times. We
want to look at the ratio of \texttt{Sepal.Length} to
\texttt{Petal.Length} in the three different species. Write a series of
\texttt{dplyr} statements that groups the data by species, creates a new
column called \texttt{s.p.ratio} that is the \texttt{Sepal.Length}
divided by \texttt{Petal.Length}, then computes the mean of this column
for each species in a column called \texttt{mean.ratio}. Display the
data in descending order of \texttt{mean.ratio}.

\section{Exercises}\label{exercises-3}

\textbf{Exercise 7} Learning objectives: introduce \texttt{with()},
\texttt{tapply()}, and \texttt{cut()} functions; summarize data using
the \texttt{table()} function with logical subsetting; practice using
factor data types.

\textbf{Exercise 8} Learning objectives: work with messy data; import
data from an external spreadsheet; practice using functions in
\texttt{tidyr} and graphing functions.\}

\textbf{Exercise 9} \{Learning objectives: work with several key
\textbf{dplyr} functions; manipulate data frames (actually tibbles);
summarize and visualize data from large data files.\}

\chapter{Functions and Programming}\label{functions}

We have been working with a wide variety of R functions, from simple
functions such as \texttt{mean()} and \texttt{sd()} to more complex
functions such as \texttt{ggplot()} and \texttt{apply()}. Gaining a
better understanding of existing functions and the ability to write your
own functions dramatically increases what we can do with R. Learning
about R's programming capabilities is an important step in gaining
facility with functions.

\section{R Functions}\label{r-functions}

Data on the yield (pounds per acre) of two types of corn seeds (regular
and kiln dried) were collected. Each of the 11 plots of land was split
into two subplots, and one of the subplots was planted in regular corn
while the other was planted in kiln dried corn. These data were analyzed
in a famous paper authored by William Gosset. Here are the data.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.corn =}\StringTok{ "http://blue.for.msu.edu/FOR875/data/corn.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{corn =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.corn, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{corn}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   regular kiln_dried
1     1903       2009
2     1935       1915
3     1910       2011
4     2496       2463
5     2108       2180
6     1961       1925
7     2060       2122
8     1444       1482
9     1612       1542
10    1316       1443
11    1511       1535
\end{verbatim}

A paired t test, or a confidence interval for the mean difference, may
be used to assess the difference in yield between the two varieties. Of
course R has a function \texttt{t.test} that performs a paired t test
and computes a confidence interval, but we will perform the test without
using that function. We will focus for now on testing the hypotheses
\(H_0\colon \mu_d = 0\) versus \(H_a\colon \mu_d \neq 0\) and on a
two-sided confidence interval for \(\mu_d\). Here \(\mu_d\) represents
the population mean difference.

The paired \(t\) statistic is defined by

\begin{equation}
t = \frac{\overline d}{S_d/\sqrt{n}}
\end{equation}

where \(\overline d\) is the mean of the differences, \(S_d\) is the
standard deviation of the differences, and \(n\) is the sample size. The
p-value is twice the area to the right of \(|t_{\text{obs}}|\), where
\(t_{\text{obs}}\) is the observed \(t\) statistic, and a confidence
interval is given by

\begin{equation}
\overline d \pm t^* (S_d/\sqrt{n}).
\end{equation}

Here \(t^*\) is an appropriate quantile of a \(t\) distribution with
\(n-1\) degrees of freedom.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{dbar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(corn}\OperatorTok{$}\NormalTok{kiln_dried }\OperatorTok{-}\StringTok{ }\NormalTok{corn}\OperatorTok{$}\NormalTok{regular)}
\OperatorTok{>}\StringTok{ }\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(corn}\OperatorTok{$}\NormalTok{regular)}
\OperatorTok{>}\StringTok{ }\NormalTok{S_d <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(corn}\OperatorTok{$}\NormalTok{kiln_dried }\OperatorTok{-}\StringTok{ }\NormalTok{corn}\OperatorTok{$}\NormalTok{regular)}
\OperatorTok{>}\StringTok{ }\NormalTok{t_obs <-}\StringTok{ }\NormalTok{dbar}\OperatorTok{/}\NormalTok{(S_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\OperatorTok{>}\StringTok{ }\NormalTok{t_obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.69
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{pval <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(t_obs), n}\OperatorTok{-}\DecValTok{1}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\NormalTok{pval}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1218
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{(S_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\OperatorTok{>}\StringTok{ }\NormalTok{lcl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{-}\StringTok{ }\NormalTok{margin}
\OperatorTok{>}\StringTok{ }\NormalTok{ucl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{+}\StringTok{ }\NormalTok{margin}
\OperatorTok{>}\StringTok{ }\NormalTok{lcl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -10.73
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{ucl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 78.18
\end{verbatim}

With a few lines of R code we have calculated the t statistic, the
p-value, and the confidence interval. Since paired t tests are pretty
common, however, it would be helpful to automate this procedure. One
obvious reason is to save time and effort, but another important reason
is to avoid mistakes. It would be easy to make a mistake (e.g., using
\(n\) instead of \(n-1\) as the degrees of freedom) when repeating the
above computations.

Here is a first basic function which automates the computation.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{paired_t <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(x1)}
\OperatorTok{+}\StringTok{     }\NormalTok{dbar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{s_d <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{tstat <-}\StringTok{ }\NormalTok{dbar}\OperatorTok{/}\NormalTok{(s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\OperatorTok{+}\StringTok{     }\NormalTok{pval <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(tstat), n}\OperatorTok{-}\DecValTok{1}\NormalTok{))}
\OperatorTok{+}\StringTok{     }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}
\OperatorTok{+}\StringTok{     }\NormalTok{lcl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{-}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\NormalTok{ucl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{+}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{tstat =}\NormalTok{ tstat, }\DataTypeTok{pval =}\NormalTok{ pval, }\DataTypeTok{lcl=}\NormalTok{lcl, }\DataTypeTok{ucl=}\NormalTok{ucl))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And here is the function in action

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(}\DataTypeTok{x1 =}\NormalTok{ corn}\OperatorTok{$}\NormalTok{kiln_dried, }\DataTypeTok{x2 =}\NormalTok{ corn}\OperatorTok{$}\NormalTok{regular)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$tstat
[1] 1.69

$pval
[1] 0.1218

$lcl
[1] -10.73

$ucl
[1] 78.18
\end{verbatim}

An explanation and comments on the function are in order.

\begin{itemize}
\tightlist
\item
  \texttt{paired\_t\ \textless{}-\ function(x1,\ x2)} assigns a function
  of two variables, \texttt{x1} and \texttt{x2}, to an R object called
  \texttt{paired\_t}.
\item
  The \emph{compound expression}, i.e., the code that makes up the body
  of the function, is enclosed in curly braces \texttt{\{\}}.
\item
  \texttt{return(list(tstat\ =\ tstat,\ pval\ =\ pval,\ lcl=lcl,\ ucl=ucl))}
  indicates the object(s) returned by the function. In this case the
  function returns a list with four components.
\item
  The body of the function basically mimics the computations required to
  compute the t statistic, the p-value, and the confidence interval.
\item
  Several objects such as \texttt{n} and \texttt{dbar} are created in
  the body of the function. These objects are NOT available outside the
  function. We will discuss this further when we cover environments and
  scope in R.
\end{itemize}

Our function has automated the basic calculations. But it is still
somewhat limited in usefulness. For example, it only computes a 95\%
confidence interval, while a user may want a different confidence level.
And the function only performs a two-sided test, while a user may want a
one-sided procedure. We modify the function slightly to allow the user
to specify the confidence level next.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{paired_t <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2, }\DataTypeTok{cl =} \FloatTok{0.95}\NormalTok{)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(x1)}
\OperatorTok{+}\StringTok{     }\NormalTok{dbar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{s_d <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{tstat <-}\StringTok{ }\NormalTok{dbar}\OperatorTok{/}\NormalTok{(s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\OperatorTok{+}\StringTok{     }\NormalTok{pval <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(tstat), n}\OperatorTok{-}\DecValTok{1}\NormalTok{))}
\OperatorTok{+}\StringTok{     }\NormalTok{pctile <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{cl)}\OperatorTok{/}\DecValTok{2}
\OperatorTok{+}\StringTok{     }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(pctile, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}
\OperatorTok{+}\StringTok{     }\NormalTok{lcl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{-}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\NormalTok{ucl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{+}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{tstat =}\NormalTok{ tstat, }\DataTypeTok{pval =}\NormalTok{ pval, }\DataTypeTok{lcl =}\NormalTok{ lcl, }\DataTypeTok{ucl=}\NormalTok{ucl))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(corn}\OperatorTok{$}\NormalTok{kiln_dried, corn}\OperatorTok{$}\NormalTok{regular)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$tstat
[1] 1.69

$pval
[1] 0.1218

$lcl
[1] -10.73

$ucl
[1] 78.18
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(corn}\OperatorTok{$}\NormalTok{kiln_dried, corn}\OperatorTok{$}\NormalTok{regular, }\DataTypeTok{cl =} \FloatTok{0.99}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$tstat
[1] 1.69

$pval
[1] 0.1218

$lcl
[1] -29.5

$ucl
[1] 96.96
\end{verbatim}

Two things to note. First, arguments do not have to be named. So

\begin{verbatim}
paired_t(corn$kiln_dried, corn$regular)
\end{verbatim}

and

\begin{verbatim}
paired_t(x1 = corn$kiln_dried, x2 = corn$regular)
\end{verbatim}

are equivalent. But we need to be careful if we do not name arguments
because then we have to know the ordering of the arguments in the
function declaration.

Second, in the declaration of the function, the third argument
\texttt{cl} was given a default value of \texttt{0.95}. If a user does
not specify a value for \texttt{cl} it will silently be set to
\texttt{0.95}. But of course a user can override this, as we did in

\begin{verbatim}
paired_t(corn$kiln_dried, corn$regular, cl = 0.99)
\end{verbatim}

\subsection{Practice Problem}\label{practice-problem-11}

Like all things in R, getting the hang of writing functions just
requires practice. Create a simple function called \texttt{FtoK} that is
given a temperature in Farenheit and converts it to Kelvin using the
following formula

\[
K = (F - 32) * \frac{5}{9} + 273.15
\]

You should get the following if your function is correct

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{FtoK}\NormalTok{(}\DecValTok{80}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 299.8
\end{verbatim}

\subsection{Creating Functions}\label{creating-functions}

Creating very short functions at the command prompt is a reasonable
strategy. For longer functions, one option is to write the function in a
script and then submit the whole function. Or a function can be written
in any text editor, saved as a plain text file (possibly with a
\texttt{.r} extension), and then read into R using the \texttt{source()}
function.

\section{Programming: Conditional
Statements}\label{programming-conditional-statements}

The \texttt{paired\_t} function is somewhat useful, but could be
improved in several ways. For example, consider the following:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in x1 - x2: longer object length is not a
multiple of shorter object length

Warning in x1 - x2: longer object length is not a
multiple of shorter object length
\end{verbatim}

\begin{verbatim}
$tstat
[1] 1

$pval
[1] 0.3739

$lcl
[1] -1.421

$ucl
[1] 3.021
\end{verbatim}

The user specified data had different numbers of observations in
\texttt{x1} and \texttt{x2}, which of course can't be data tested by a
paired t test. Rather than stopping and letting the user know that this
is a problem, the function continued and produced meaningless output.

Also, the function as written only allows testing against a two-sided
alternative hypothesis, and it would be good to allow one-sided
alternatives.

First we will address some checks on arguments specified by the user.
For this we will use an \texttt{if()} function and a \texttt{stop()}
function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{paired_t <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2, }\DataTypeTok{cl =} \FloatTok{0.95}\NormalTok{)\{}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(}\KeywordTok{length}\NormalTok{(x1) }\OperatorTok{!=}\StringTok{ }\KeywordTok{length}\NormalTok{(x2))\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{stop}\NormalTok{(}\StringTok{"The input vectors  must have the same length"}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(x1)}
\OperatorTok{+}\StringTok{     }\NormalTok{dbar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{s_d <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{tstat <-}\StringTok{ }\NormalTok{dbar}\OperatorTok{/}\NormalTok{(s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\OperatorTok{+}\StringTok{     }\NormalTok{pval <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(tstat), n}\OperatorTok{-}\DecValTok{1}\NormalTok{))}
\OperatorTok{+}\StringTok{     }\NormalTok{pctile <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{cl)}\OperatorTok{/}\DecValTok{2}
\OperatorTok{+}\StringTok{     }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(pctile, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}
\OperatorTok{+}\StringTok{     }\NormalTok{lcl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{-}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\NormalTok{ucl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{+}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{tstat =}\NormalTok{ tstat, }\DataTypeTok{pval =}\NormalTok{ pval, }\DataTypeTok{lcl =}\NormalTok{ lcl, }\DataTypeTok{ucl=}\NormalTok{ucl))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in paired_t(1:5, 1:4): The input vectors  must have the same length
\end{verbatim}

The argument to the \texttt{if()} function is evaluated. If the argument
returns \texttt{TRUE} the ensuing code is executed. Otherwise, the
ensuing code is skipped and the rest of the function is evaluated. If a
\texttt{stop()} function is executed, the function is exited and the
argument of \texttt{stop()} is printed.

To better understand and use \texttt{if()} statements, we need to
understand comparison operators and logical operators.

\subsection{Comparison and Logical
Operators}\label{comparison-and-logical-operators}

We have made use of some of the comparison operators in R. These include

\begin{itemize}
\tightlist
\item
  Equal: \texttt{==}
\item
  Not equal: \texttt{!=}
\item
  Greater than: \texttt{\textgreater{}}
\item
  Less than: \texttt{\textless{}}
\item
  Greater than or equal to: \texttt{\textgreater{}=}
\item
  Less than or equal to: \texttt{\textless{}=}
\end{itemize}

Special care needs to be taken with the \texttt{==} and \texttt{!=}
operators because of how numbers are represented on computers, see
Section \ref{arith}.

There are also three logical operators, with two variants of the ``and''
operator and the ``or'' operator.

\begin{itemize}
\tightlist
\item
  and: Either \texttt{\&} or \texttt{\&\&}
\item
  or: Either \texttt{\textbar{}} or \texttt{\textbar{}\textbar{}}
\item
  not: \texttt{!}
\end{itemize}

The ``double'' operators \texttt{\&\&} and \texttt{\textbar{}\textbar{}}
just examine the first element of the two vectors, whereas the
``single'' operators \texttt{\&} and \texttt{\textbar{}} compare element
by element.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{) }\OperatorTok{||}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{) }\OperatorTok{|}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  TRUE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{) }\OperatorTok{&&}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{) }\OperatorTok{&}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE  TRUE FALSE
\end{verbatim}

We can use the logical operators to check whether a user-specified
confidence level is between 0 and 1.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{paired_t <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2, }\DataTypeTok{cl =} \FloatTok{0.95}\NormalTok{)\{}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(}\KeywordTok{length}\NormalTok{(x1) }\OperatorTok{!=}\StringTok{ }\KeywordTok{length}\NormalTok{(x2))\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{stop}\NormalTok{(}\StringTok{"The input vectors  must have the same length"}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(cl }\OperatorTok{<=}\StringTok{ }\DecValTok{0} \OperatorTok{||}\StringTok{ }\NormalTok{cl }\OperatorTok{>=}\StringTok{ }\DecValTok{1}\NormalTok{)\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{stop}\NormalTok{(}\StringTok{"The confidence level must be between 0 and 1"}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(x1)}
\OperatorTok{+}\StringTok{     }\NormalTok{dbar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{s_d <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{tstat <-}\StringTok{ }\NormalTok{dbar}\OperatorTok{/}\NormalTok{(s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\OperatorTok{+}\StringTok{     }\NormalTok{pval <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(tstat), n}\OperatorTok{-}\DecValTok{1}\NormalTok{))}
\OperatorTok{+}\StringTok{     }\NormalTok{pctile <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{cl)}\OperatorTok{/}\DecValTok{2}
\OperatorTok{+}\StringTok{     }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(pctile, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}
\OperatorTok{+}\StringTok{     }\NormalTok{lcl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{-}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\NormalTok{ucl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{+}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{tstat =}\NormalTok{ tstat, }\DataTypeTok{pval =}\NormalTok{ pval, }\DataTypeTok{lcl =}\NormalTok{ lcl, }\DataTypeTok{ucl=}\NormalTok{ucl))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{2}\OperatorTok{:}\DecValTok{6}\NormalTok{, }\DataTypeTok{cl=}\DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in paired_t(1:5, 2:6, cl = 15): The confidence level must be between 0 and 1
\end{verbatim}

\subsection{If else statements}\label{if-else-statements}

The \texttt{if()} statement we have used so far has the form

\begin{verbatim}
if (condition) {
  expression
}
\end{verbatim}

Often we want to evaluate one expression if the condition is true, and
evaluate a different expression if the condition is false. That is
accomplished by the \texttt{if\ else} statement. Here we determine
whether a number is positive, negative, or zero.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{Sign <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(x }\OperatorTok{<}\StringTok{ }\DecValTok{0}\NormalTok{)\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{print}\NormalTok{(}\StringTok{"the number is negative"}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{(x }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{)\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{print}\NormalTok{(}\StringTok{"the number is positive"}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}\ControlFlowTok{else}\NormalTok{\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{print}\NormalTok{(}\StringTok{"the number is zero"}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{Sign}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the number is positive"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{Sign}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the number is negative"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{Sign}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the number is zero"
\end{verbatim}

Notice the ``different expression'' for the first \texttt{if} statement
was itself an \texttt{if} statement.

Next we modify the \texttt{paired\_t} function to allow two-sided and
one-sided alternatives.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{paired_t <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2, }\DataTypeTok{cl =} \FloatTok{0.95}\NormalTok{, }\DataTypeTok{alternative=}\StringTok{"not.equal"}\NormalTok{)\{}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(}\KeywordTok{length}\NormalTok{(x1) }\OperatorTok{!=}\StringTok{ }\KeywordTok{length}\NormalTok{(x2))\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{stop}\NormalTok{(}\StringTok{"The input vectors must be of the same length"}\NormalTok{)}
\OperatorTok{+}\StringTok{         }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(cl }\OperatorTok{<=}\StringTok{ }\DecValTok{0} \OperatorTok{||}\StringTok{ }\NormalTok{cl }\OperatorTok{>=}\StringTok{ }\DecValTok{1}\NormalTok{)\{}
\OperatorTok{+}\StringTok{         }\KeywordTok{stop}\NormalTok{(}\StringTok{"The confidence level must be between 0 and 1"}\NormalTok{)}
\OperatorTok{+}\StringTok{         }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\NormalTok{n <-}\StringTok{ }\KeywordTok{length}\NormalTok{(x1)}
\OperatorTok{+}\StringTok{     }\NormalTok{dbar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{s_d <-}\StringTok{ }\KeywordTok{sd}\NormalTok{(x1 }\OperatorTok{-}\StringTok{ }\NormalTok{x2)}
\OperatorTok{+}\StringTok{     }\NormalTok{tstat <-}\StringTok{ }\NormalTok{dbar}\OperatorTok{/}\NormalTok{(s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n))}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(alternative }\OperatorTok{==}\StringTok{ "not.equal"}\NormalTok{)\{}
\OperatorTok{+}\StringTok{         }\NormalTok{pval <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{pt}\NormalTok{(}\KeywordTok{abs}\NormalTok{(tstat), n}\OperatorTok{-}\DecValTok{1}\NormalTok{))}
\OperatorTok{+}\StringTok{         }\NormalTok{pctile <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{cl)}\OperatorTok{/}\DecValTok{2}
\OperatorTok{+}\StringTok{         }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(pctile, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}
\OperatorTok{+}\StringTok{         }\NormalTok{lcl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{-}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{         }\NormalTok{ucl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{+}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{(alternative }\OperatorTok{==}\StringTok{ "greater"}\NormalTok{)\{}
\OperatorTok{+}\StringTok{         }\NormalTok{pval <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{pt}\NormalTok{(tstat, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\OperatorTok{+}\StringTok{         }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(cl, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}
\OperatorTok{+}\StringTok{         }\NormalTok{lcl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{-}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{         }\NormalTok{ucl <-}\StringTok{ }\OtherTok{Inf}
\OperatorTok{+}\StringTok{     }\NormalTok{\} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{(alternative }\OperatorTok{==}\StringTok{ "less"}\NormalTok{)\{}
\OperatorTok{+}\StringTok{         }\NormalTok{pval <-}\StringTok{ }\KeywordTok{pt}\NormalTok{(tstat, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\OperatorTok{+}\StringTok{         }\NormalTok{margin <-}\StringTok{ }\KeywordTok{qt}\NormalTok{(cl, n}\OperatorTok{-}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{s_d}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(n)}
\OperatorTok{+}\StringTok{         }\NormalTok{lcl <-}\StringTok{ }\OperatorTok{-}\OtherTok{Inf}
\OperatorTok{+}\StringTok{         }\NormalTok{ucl <-}\StringTok{ }\NormalTok{dbar }\OperatorTok{+}\StringTok{ }\NormalTok{margin}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{tstat =}\NormalTok{ tstat, }\DataTypeTok{pval =}\NormalTok{ pval, }\DataTypeTok{lcl=}\NormalTok{lcl, }\DataTypeTok{ucl=}\NormalTok{ucl))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(corn}\OperatorTok{$}\NormalTok{kiln_dried, corn}\OperatorTok{$}\NormalTok{regular)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$tstat
[1] 1.69

$pval
[1] 0.1218

$lcl
[1] -10.73

$ucl
[1] 78.18
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(corn}\OperatorTok{$}\NormalTok{kiln_dried, corn}\OperatorTok{$}\NormalTok{regular, }\DataTypeTok{alternative =} \StringTok{"less"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$tstat
[1] 1.69

$pval
[1] 0.9391

$lcl
[1] -Inf

$ucl
[1] 69.89
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paired_t}\NormalTok{(corn}\OperatorTok{$}\NormalTok{kiln_dried, corn}\OperatorTok{$}\NormalTok{regular, }\DataTypeTok{alternative =} \StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$tstat
[1] 1.69

$pval
[1] 0.06091

$lcl
[1] -2.434

$ucl
[1] Inf
\end{verbatim}

\section{Computer Arithmetic}\label{arith}

Like most software, R does not perform exact arithmetic. Rather, R
follows the IEEE 754 floating point standards. This can have profound
effects on how computational algorithms are implemented, but is also
important when considering things like comparisons.

Note first that computer arithmetic does not follow some of the rules of
ordinary arithmetic. For example, it is not associative.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{2}\OperatorTok{^-}\DecValTok{30}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0000000009313
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{2}\OperatorTok{^-}\DecValTok{30} \OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{2}\OperatorTok{^}\DecValTok{30} \OperatorTok{-}\StringTok{ }\DecValTok{2}\OperatorTok{^}\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0000000009313
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{(}\DecValTok{2}\OperatorTok{^-}\DecValTok{30} \OperatorTok{+}\StringTok{ }\DecValTok{2}\OperatorTok{^}\DecValTok{30}\NormalTok{) }\OperatorTok{-}\StringTok{ }\DecValTok{2}\OperatorTok{^}\DecValTok{30}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0
\end{verbatim}

Computer arithmetic is not exact.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\FloatTok{1.5} \OperatorTok{-}\StringTok{ }\FloatTok{1.4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\FloatTok{1.5} \OperatorTok{-}\StringTok{ }\FloatTok{1.4} \OperatorTok{==}\StringTok{ }\FloatTok{0.1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{(}\FloatTok{1.5} \OperatorTok{-}\StringTok{ }\FloatTok{1.4}\NormalTok{) }\OperatorTok{-}\StringTok{ }\FloatTok{0.1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.00000000000000008327
\end{verbatim}

So for example an \texttt{if} statement that uses an equality test may
not give the expected answer. One way to avoid this problem is to test
``near equality'' using \texttt{all.equal()}. The function takes as
arguments two objects to be compared, and a tolerance. If the objects
are within the tolerance of each other, the function returns
\texttt{TRUE}. The tolerance has a default value of about
\(1.5\times 10^{-8}\), which works well in many cases.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{all.equal}\NormalTok{((}\FloatTok{1.5} \OperatorTok{-}\StringTok{ }\FloatTok{1.4}\NormalTok{), }\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

\section{Loops}\label{loops}

Loops are an important component of any programming language, including
R. Vectorized calculations and functions such as \texttt{apply()} make
loops a bit less central to R than to many other languages, but an
understanding of the three looping structures in R is still quite
important.

We will investigate loops in the context of computing what is sometimes
called the ``machine epsilon.'' Because of the inexact representation of
numbers in R (and other languages) sometimes R cannot distinguish
between the numbers \texttt{1} and \texttt{\textbar{}1\ +\ x\textbar{}}
for small values of \texttt{x}. The smallest value of \texttt{x} such
that \texttt{1} and \texttt{\textbar{}1+x\textbar{}} are not declared
equal is the machine epsilon.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1} \OperatorTok{==}\StringTok{ }\DecValTok{1}\OperatorTok{+}\DecValTok{10}\OperatorTok{^-}\DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1} \OperatorTok{==}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\DecValTok{10}\OperatorTok{^-}\DecValTok{50}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

Clearly the machine epsilon is somewhere between \(10^{-4}\) and
\(10^{-50}\). How can we find its value exactly? Since floating point
numbers use a binary representation, we know that the machine epsilon
will be equal to \(1/2^k\) for some value of \(k\). So to find the
machine epsilon, we can keep testing whether \(1\) and \(1+1/2^k\) are
equal, until we find a value \(k\) where the two are equal. Then the
machine epsilon will be \(1/2^{k-1}\), since it is the smallest value
for which the two are NOT equal.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1} \OperatorTok{==}\StringTok{ }\DecValTok{1}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1} \OperatorTok{==}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\DecValTok{1}\OperatorTok{/}\DecValTok{2}\OperatorTok{^}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1} \OperatorTok{==}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\DecValTok{1}\OperatorTok{/}\DecValTok{2}\OperatorTok{^}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

Testing by hand like this gets tedious quickly. A loop can automate the
process. We will do this with two R loop types, \texttt{repeat} and
\texttt{while}.

\subsection{A Repeat Loop}\label{a-repeat-loop}

A \texttt{repeat} loop just repeats a given expression over and over
again until a \texttt{break} statement is encountered.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{k <-}\StringTok{ }\DecValTok{1}
\OperatorTok{>}\StringTok{ }\ControlFlowTok{repeat}\NormalTok{\{}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(}\DecValTok{1} \OperatorTok{==}\StringTok{ }\DecValTok{1}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\OperatorTok{^}\NormalTok{k)\{}
\OperatorTok{+}\StringTok{         }\ControlFlowTok{break}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}\ControlFlowTok{else}\NormalTok{\{}
\OperatorTok{+}\StringTok{         }\NormalTok{k <-}\StringTok{ }\NormalTok{k}\OperatorTok{+}\DecValTok{1}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 53
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1}\OperatorTok{/}\DecValTok{2}\OperatorTok{^}\NormalTok{(k}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.000000000000000222
\end{verbatim}

This code initializes \texttt{k} at 1. The body of the loop initially
checks whether \(1\) and \(1+1/2^k\) are equal. If they are equal, the
\texttt{break} statement is executed and control is transferred outside
the loop. If they are not equal, \texttt{k} is increased by 1, and we
return to the beginning of the top of the body of the loop.

\subsection{A While Loop}\label{a-while-loop}

A \texttt{while} loop has the form

\begin{verbatim}
while (condition) {
  expression
}
\end{verbatim}

As long as the \texttt{condition} is \texttt{TRUE} the
\texttt{expression} is evaluated. Once the \texttt{condition} is
\texttt{FALSE} control is transferred outside the loop.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{k <-}\StringTok{ }\DecValTok{1}
\OperatorTok{>}\StringTok{ }\ControlFlowTok{while}\NormalTok{(}\DecValTok{1} \OperatorTok{!=}\StringTok{ }\DecValTok{1}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\OperatorTok{^}\NormalTok{k)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{k <-}\StringTok{ }\NormalTok{k}\OperatorTok{+}\DecValTok{1} 
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\NormalTok{k}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 53
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\DecValTok{1}\OperatorTok{/}\DecValTok{2}\OperatorTok{^}\NormalTok{(k}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.000000000000000222
\end{verbatim}

\subsection{A For Loop}\label{a-for-loop}

A \texttt{for} loop has the form

\begin{verbatim}
for (variable in vector) {
  expression
}
\end{verbatim}

The \texttt{for} loop sets the \texttt{variable} equal to each element
of the \texttt{vector} in succession, and evaluates the
\texttt{expression} each time. Here are two different ways to use a
\texttt{for} loop to calculate the sum of the elements in a vector.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{10}
\OperatorTok{>}\StringTok{ }\NormalTok{S <-}\StringTok{ }\DecValTok{0}
\OperatorTok{>}\StringTok{ }\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(x))\{}
\OperatorTok{+}\StringTok{     }\NormalTok{S <-}\StringTok{ }\NormalTok{S }\OperatorTok{+}\StringTok{ }\NormalTok{x[i]}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\NormalTok{S}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 55
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{S =}\StringTok{ }\DecValTok{0}
\OperatorTok{>}\StringTok{ }\ControlFlowTok{for}\NormalTok{(value }\ControlFlowTok{in}\NormalTok{ x)\{}
\OperatorTok{+}\StringTok{   }\NormalTok{S =}\StringTok{ }\NormalTok{S }\OperatorTok{+}\StringTok{ }\NormalTok{value}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\NormalTok{S}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 55
\end{verbatim}

In the first case we loop over the positions of the vector elements,
while in the second case we loop over the elements themselves.

\subsection{Practice Problem}\label{practice-problem-12}

Often when students initially learn about \texttt{if()} statements and
\texttt{for()} loops, they use them more often than is necessary,
leading to over complications and often slower, less sophisticated code.
Many simple \texttt{if()} statements can be accomplished using logical
subsetting and vectorization. Using the ideas you used above, and what
you learned in Chapters \ref{structures} and \ref{data2}, we can use
logical subsetting to replace the simplest of \texttt{if()} statements.
Rewrite the following \texttt{if()} statement and \texttt{for()} loop
using logical subsetting.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{a <-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1000}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(a)) \{}
\OperatorTok{>}\StringTok{   }\ControlFlowTok{if}\NormalTok{ (a[i] }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\OperatorTok{>}\StringTok{     }\NormalTok{a[i] <-}\StringTok{ }\DecValTok{0}
\OperatorTok{>}\StringTok{   }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Efficiency Considerations}\label{efficiency-considerations}

In many contexts R and modern computers are fast enough that the user
does not need to worry about writing efficient code. There are a few
simple ways to write efficient code that are easy enough, and provide
enough speed-up, that they are worth following as often as possible. The
R function \texttt{system.time()} reports how long a set of R code takes
to execute, and we will use this function to compare different ways to
accomplish objectives in R.

\subsection{Growing Objects}\label{growing-objects}

Consider two ways to create a sequence of integers from 1 to n,
implemented in functions \texttt{f1} and \texttt{f2}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with a zero-length vector, and let it grow:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{f1 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{x <-}\StringTok{ }\KeywordTok{numeric}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)\{}
\OperatorTok{+}\StringTok{         }\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(x,i)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\NormalTok{x}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Start with a vector of length \(n\) and fill in the values:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{f2 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{x <-}\StringTok{ }\KeywordTok{numeric}\NormalTok{(n)}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)\{}
\OperatorTok{+}\StringTok{         }\NormalTok{x[i] <-}\StringTok{ }\NormalTok{i}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\NormalTok{x}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here are the two functions in action, with \(n = 100000\).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{n <-}\StringTok{ }\DecValTok{100000}
\OperatorTok{>}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\KeywordTok{f1}\NormalTok{(n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   user  system elapsed 
 11.986   0.016  12.094 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\KeywordTok{f2}\NormalTok{(n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   user  system elapsed 
  0.010   0.000   0.011 
\end{verbatim}

It is \emph{much} more efficient to start with a full-length vector and
then fill in values.\footnote{Roughly speaking, the first option is
  slower because each time the vector is increased in size, R must
  resize the vector and re-allocate memory.}

Of course another way to create a vector of integers from 1 to n is to
use \texttt{1:n}. Let's see how fast this is.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   user  system elapsed 
      0       0       0 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{n <-}\StringTok{ }\DecValTok{1000000}
\OperatorTok{>}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n)      }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   user  system elapsed 
      0       0       0 
\end{verbatim}

For \(n=100000\) this is so fast the system time is very close to zero.
Even when \(n\) is 1000000 the time is very small. So another important
lesson is to use built-in R functions whenever possible, since they have
had substantial development focused on efficiency, correctness, etc.

\subsection{Vectorization}\label{vectorization}

Next consider calculating the sum of the squared entries in each column
of a matrix. For example with the matrix \(M\),

\[
M = \left(\begin{array}{ccc}
1 & 2 & 3 \\
4 & 5 & 6
\end{array}\right),
\]

the sums would be \(1^2 + 4^2 = 17\), \(2^2 + 5^2 = 29\), and
\(3^2 + 6^2 = 45\). One possibility is to have an outer loop that
traverses the columns and an inner loop that traverses the rows within a
column, squaring the entries and adding them together.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{test_matrix <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{, }\DataTypeTok{byrow=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{nrow=}\DecValTok{2}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{test_matrix}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{ss1 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(M)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{n <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(M)[}\DecValTok{1}\NormalTok{]}
\OperatorTok{+}\StringTok{     }\NormalTok{m <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(M)[}\DecValTok{2}\NormalTok{]}
\OperatorTok{+}\StringTok{     }\NormalTok{out <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,m)}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{m)\{}
\OperatorTok{+}\StringTok{         }\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)\{}
\OperatorTok{+}\StringTok{             }\NormalTok{out[j] <-}\StringTok{ }\NormalTok{out[j] }\OperatorTok{+}\StringTok{ }\NormalTok{M[i,j]}\OperatorTok{^}\DecValTok{2}
\OperatorTok{+}\StringTok{         }\NormalTok{\} }
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(out)}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{ss1}\NormalTok{(test_matrix)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 17 29 45
\end{verbatim}

Another possibility eliminates the inner loop, using the \texttt{sum()}
function to compute the sum of the squared entries in the column
directly.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{ss2 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(M)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{m <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(M)[}\DecValTok{2}\NormalTok{]}
\OperatorTok{+}\StringTok{     }\NormalTok{out <-}\StringTok{ }\KeywordTok{numeric}\NormalTok{(m)}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{m)\{}
\OperatorTok{+}\StringTok{         }\NormalTok{out[j] <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(M[,j]}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\NormalTok{\}}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(out) }
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{ss2}\NormalTok{(test_matrix)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 17 29 45
\end{verbatim}

A third possibility uses the \texttt{colSums()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{ss3 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(M)\{}
\OperatorTok{+}\StringTok{     }\NormalTok{out <-}\StringTok{ }\KeywordTok{colSums}\NormalTok{(M}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(out)}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{ss3}\NormalTok{(test_matrix)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 17 29 45
\end{verbatim}

Here is a speed comparison, using a \(1000\times 10000\) matrix.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mm <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10000000}\NormalTok{, }\DataTypeTok{byrow =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{1000}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\KeywordTok{ss1}\NormalTok{(mm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   user  system elapsed 
  1.169   0.000   1.181 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\KeywordTok{ss2}\NormalTok{(mm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   user  system elapsed 
  0.075   0.000   0.076 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\KeywordTok{ss3}\NormalTok{(mm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   user  system elapsed 
  0.120   0.008   0.129 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{rm}\NormalTok{(mm)}
\end{Highlighting}
\end{Shaded}

\section{More on Functions}\label{more-on-functions}

Understanding functions deeply requires a careful study of R's scoping
rules, as well as a good understanding of environments in R. That's
beyond the scope of this book, but we will briefly discuss some issues
that are most salient. For a more in-depth treatment, see ``Advanced R''
by Hadley Wickham, especially the chapters on functions and
environments.

\section{Calling Functions}\label{calling-functions}

When using a function, the functions arguments can be specified in three
ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  By the full name of the argument.
\item
  By the position of the argument.
\item
  By a partial name of the argument.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{tmp_function <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(first.arg, second.arg, third.arg, fourth.arg)\{}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(}\KeywordTok{c}\NormalTok{(first.arg, second.arg, third.arg, fourth.arg))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{tmp_function}\NormalTok{(}\DecValTok{34}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DataTypeTok{third.arg =} \DecValTok{11}\NormalTok{, }\DataTypeTok{fou =} \DecValTok{99}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 34 15 11 99
\end{verbatim}

Positional matching of arguments is convenient, but should be used
carefully, and probably limited to the first few, and most commonly
used, arguments in a function. Partial does have pitfalls. A partially
specified argument must unambiguously match exactly one argument---a
requirement that's not met below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{tmp_function <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(first.arg, fourth.arg)\{}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(}\KeywordTok{c}\NormalTok{(first.arg, fourth.arg))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{tmp_function}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{f=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in tmp_function(1, f = 2): argument 2 matches multiple formal arguments
\end{verbatim}

\subsection{\texorpdfstring{The \texttt{...}
argument}{The ... argument}}\label{the-...-argument}

In defining a function, a special argument denoted by \texttt{...} can
be used. Sometimes this is called the ``ellipsis'' argument, sometimes
the ``three dot'' argument, sometimes the ``dot dot dot'' argument, etc.
The R language definition
\url{https://cran.r-project.org/doc/manuals/r-release/R-lang.html}
describes the argument in this way:

\begin{quote}
The special type of argument `\ldots{}' can contain any number of
supplied arguments. It is used for a variety of purposes. It allows you
to write a function that takes an arbitrary number of arguments. It can
be used to absorb some arguments into an intermediate function which can
then be extracted by functions called subsequently.
\end{quote}

Consider for example the \texttt{sum()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 112
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{90}\NormalTok{), }\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 118
\end{verbatim}

Think about writing such a function. There is no way to predict in
advance the number of arguments a user might specify. So the function is
defined with \texttt{...} as the first argument:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{sum}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
function (..., na.rm = FALSE)  .Primitive("sum")
\end{verbatim}

This is true of many commonly-used functions in R such as \texttt{c()}
among others.

Next, consider a function that calls another function in its body. For
example, suppose that a collaborator always supplies comma delimited
files that have five lines of description, followed by a line containing
variable names, followed by the data. You are tired of having to specify
\texttt{skip\ =\ 5}, \texttt{header\ =\ TRUE}, and \texttt{sep\ =\ ","}
to \texttt{read.table()} and want to create a function
\texttt{my.read()} which uses these as defaults.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{my.read <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(file, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{","}\NormalTok{, }\DataTypeTok{skip =} \DecValTok{5}\NormalTok{, ...)\{}
\OperatorTok{+}\StringTok{     }\KeywordTok{read.table}\NormalTok{(}\DataTypeTok{file =}\NormalTok{ file, }\DataTypeTok{header =}\NormalTok{ header, }\DataTypeTok{sep =}\NormalTok{ sep, }\DataTypeTok{skip =}\NormalTok{ skip, ...)}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The \texttt{...} in the definition of \texttt{my.read()} allows the user
to specify other arguments, for example,
\texttt{stringsAsFactors\ =\ FALSE}. These will be passed on to the
\texttt{read.table()} function. In fact, that is how \texttt{read.csv()}
is defined.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{read.csv}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
function (file, header = TRUE, sep = ",", quote = "\"", dec = ".", 
    fill = TRUE, comment.char = "", ...) 
read.table(file = file, header = header, sep = sep, quote = quote, 
    dec = dec, fill = fill, comment.char = comment.char, ...)
<bytecode: 0x55608c93cde8>
<environment: namespace:utils>
\end{verbatim}

\subsection{Lazy Evaluation}\label{lazy-evaluation}

Arguments to R functions are not evaluated until they are needed,
sometimes called \emph{lazy} evaluation.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{f <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(a,b)\{}
\OperatorTok{+}\StringTok{     }\KeywordTok{print}\NormalTok{(a}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\KeywordTok{print}\NormalTok{(a}\OperatorTok{^}\DecValTok{3}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\KeywordTok{print}\NormalTok{(a}\OperatorTok{*}\NormalTok{b)}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{f}\NormalTok{(}\DataTypeTok{a=}\DecValTok{3}\NormalTok{, }\DataTypeTok{b=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9
[1] 27
[1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{f}\NormalTok{(}\DataTypeTok{a=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9
[1] 27
\end{verbatim}

\begin{verbatim}
Error in print(a * b): argument "b" is missing, with no default
\end{verbatim}

The first call specified both of the arguments \texttt{a} and
\texttt{b}, and produced the expected output. In the second call the
argument \texttt{b} was not specified. Since it was not needed until the
third \texttt{print} statement, R happily executed the first two
\texttt{print} statements, and only reported an error in the third
statement, when \texttt{b} was needed to compute \texttt{a*b}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{f <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(a,}\DataTypeTok{b =}\NormalTok{ a}\OperatorTok{^}\DecValTok{3}\NormalTok{)\{}
\OperatorTok{+}\StringTok{     }\KeywordTok{return}\NormalTok{(a}\OperatorTok{*}\NormalTok{b)}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{f}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{f}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 20
\end{verbatim}

In the first call, since \texttt{b} was not specified, it was computed
as \texttt{a\^{}3}. In the second call, \texttt{b} was specified, and
the specified value was used.

\section{Exercises}\label{exercises-4}

\textbf{Exercise 10} Learning objectives: translate statistical notation
into coded functions; learn about tools for checking validity of
function arguments; practice writing functions that return multiple
objects.

\chapter{Spatial Data Visualization and Analysis}\label{sp}

\section{Overview}\label{overview}

Recall, a data structure is a format for organizing and storing data.
The structure is designed so that data can be accessed and worked with
in specific ways. Statistical software and programming languages have
methods (or functions) designed to operate on different kinds of data
structures.

This chapter focuses on spatial data structures and some of the R
functions that work with these data. Spatial data comprise values
associated with locations, such as temperature data at a given latitude,
longitude, and perhaps elevation. Spatial data are typically organized
into \textbf{vector} or \textbf{raster} data types. (See Figure
\ref{fig:raster}).

\begin{itemize}
\tightlist
\item
  Vector data represent features such as discrete points, lines, and
  polygons.
\item
  Raster data represent surfaces as a rectangular matrix of square cells
  or pixels.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/Raster_vector_tikz} 

}

\caption{Raster/Vector Comparison [@imageRaster]}\label{fig:raster}
\end{figure}

Whether or not you use vector or raster data depends on the type of
problem, the type of maps you need, and the data source. Each data
structure has strengths and weaknesses in terms of functionality and
representation. As you gain more experience working with spatial data,
you will be able to determine which structure to use for a particular
application.

There is a large set of R packages available for working with spatial
(and space-time) data. These packages are described in the
\href{https://CRAN.R-project.org/view=Spatial}{Cran Task View: Analysis
of Spatial Data}. The CRAN task view attempts to organize the various
packages into categories, such as \emph{Handling spatial data},
\emph{Reading and writing spatial data}, \emph{Visualization}, and
\emph{Disease mapping and areal data analysis}, so users can quickly
identify package options given their project needs.

Exploring the extent of the excellent spatial data tools available in R
is beyond the scope of this book. Rather, we would point you to subject
texts like \emph{Applied Spatial Data Analysis with R} by
\citet{Bivand13} (available for free via the MSU library system), and
numerous online tutorials on pretty much any aspect of spatial data
analysis with R. These tools make R a full-blown
\href{https://en.wikipedia.org/wiki/Geographic_information_system}{Geographic
Information System} (GIS) capable of spatial data manipulation and
analysis on par with commercial GIS systems such as
\href{http://www.esri.com/arcgis/about-arcgis}{ESRI's ArcGIS}.

\subsection{Some Spatial Data
Packages}\label{some-spatial-data-packages}

This chapter will focus on a few R packages for manipulating and
visualizing spatial data. Specifically we will touch on the following
packages

\begin{itemize}
\tightlist
\item
  \texttt{sp}: spatial data structures and methods
\item
  \texttt{rgdal}: interface to the C/C\texttt{++} spatial data
  Geospatial Data Abstraction Library
\item
  \texttt{ggmap}: extends \texttt{ggplot2} language to handle spatial
  data
\item
  \texttt{leaflet}: generates dynamic online maps
\end{itemize}

\section{Motivating Data}\label{motivating-data}

We motivate the topics introduced in this chapter using some forestry
data from the
\href{https://www.nrs.fs.fed.us/ef/locations/me/penobscot\%7D\%7BPenobscot\%20Experimental\%20Forest}{Penobscot
Experimental Forest} (PEF) located in Maine. The PEF is a long-term
experimental forest that is used to understand the effects of
silviculture (i.e., science of tending trees) treatments on forest
growth and composition. The PEF is divided into non-overlapping
management units that receive different harvesting treatments. Within
each management unit is a series of observation point locations (called
forest inventory plots) where forest variables have been measured.
Ultimately, we want to summarize the inventory plots measurements by
management unit and map the results.

\section{Reading Spatial Data into R}\label{reading-spatial-data-into-r}

Spatial data come in a variety of file formats. Examples of popular
vector file formats for points, lines, and polygons, include ESRI's
\href{https://en.wikipedia.org/wiki/Shapefile}{shapefile} and open
standard \href{https://en.wikipedia.org/wiki/GeoJSON}{GeoJSON}. Common
raster file formats include
\href{https://en.wikipedia.org/wiki/GeoTIFF}{GeoTIFF} and
\href{https://en.wikipedia.org/wiki/NetCDF}{netCDF}\footnote{A longer
  list of spatial data file formats is available at
  \url{https://en.wikipedia.org/wiki/GIS_file_formats}.}.

The \texttt{rgdal} function \texttt{readOGR} will read a large variety
of vector data file formats (there is also a \texttt{writeOGR()} for
writing vector data files). Raster data file formats can be read using
the \texttt{rgdal} function \texttt{readGDAL} (yup, also a
\texttt{writeGDAL()}) or read functions in the \texttt{raster} package.
All of these functions automatically cast the data into an appropriate R
spatial data object (i.e., data structure), which are defined in the
\texttt{sp} or \texttt{raster} packages. Table \ref{tab:spatialObjs}
provides an abbreviated list of these R spatial objects\footnote{A more
  complete list of the \texttt{sp} package's spatial data classes and
  methods is detailed in the package's vignette
  \url{https://cran.r-project.org/web/packages/sp/vignettes/intro_sp.pdf}.}.
The \emph{Without attributes }column gives the \texttt{sp} package's
spatial data object classes for points, lines, polygons, and raster
pixels that do not have data associated with the spatial objects (i.e.,
without attributes in GIS speak). \texttt{DataFrame} is appended to the
object class name once data, in the form of variables, are added to the
spatial object.

\begin{table}[t]

\caption{\label{tab:spatialObjs}An abbreviated list of `sp` and `raster` data objects and associated classes for the fundamental spatial data types}
\centering
\begin{tabular}{lll}
\toprule
 & Without Attributes & With Attributes\\
\midrule
Polygons & SpatialPolygons & SpatialPolygonsDataFrame\\
Points & SpatialPoints & SpatialPointsDataFrame\\
Lines & SpatialLines & SpatialLinesDataFrame\\
Raster & SpatialGrid & SpatialGridDataFrame\\
Raster & SpatialPixels & SpatialPixelsDataFrame\\
\addlinespace
Raster &  & RasterLayer\\
Raster &  & RasterBrick\\
Raster &  & RasterStack\\
\bottomrule
\end{tabular}
\end{table}

You can create your own spatial data objects in R. Below, for example,
we create a \texttt{SpatialPoints} object consisting of four points.
Then add some data to the points to make it a
\texttt{SpatialPointsDataFrame}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(sp)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dplyr)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{coords <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(x, y)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{sp.pts <-}\StringTok{ }\KeywordTok{SpatialPoints}\NormalTok{(coords)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(sp.pts)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "SpatialPoints"
attr(,"package")
[1] "sp"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{some.data <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{var.1 =} \KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{), }\DataTypeTok{var.2 =} \DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{sp.pts.df <-}\StringTok{ }\KeywordTok{SpatialPointsDataFrame}\NormalTok{(sp.pts, some.data)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(sp.pts.df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"
\end{verbatim}

If, for example, you already have a data frame that includes the spatial
coordinate columns and other variables, then you can promote it to a
\texttt{SpatialPointsDataFrame} by indicating which columns contain
point coordinates. You can extract or access the data frame associated
with the spatial object using \texttt{@data}. You can also access
individual variables directly from the spatial object using \texttt{\$}
or by name or column number to the right of the comma in
\texttt{{[},{]}} (analogues to accessing variables in a data frame).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{), }\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{), }\DataTypeTok{var.1 =} \KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"d"}\NormalTok{), }\DataTypeTok{var.2 =} \DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "data.frame"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\CommentTok{#promote to a SpatialPointsDataFrame}
\ErrorTok{>}\StringTok{ }\KeywordTok{coordinates}\NormalTok{(df) <-}\StringTok{ }\ErrorTok{~}\NormalTok{x}\OperatorTok{+}\NormalTok{y}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\CommentTok{#access entire data frame}
\ErrorTok{>}\StringTok{ }\NormalTok{df}\OperatorTok{@}\NormalTok{data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  var.1 var.2
1     a     1
2     b     2
3     c     3
4     d     4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(df}\OperatorTok{@}\NormalTok{data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "data.frame"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\CommentTok{#access columns directly}
\ErrorTok{>}\StringTok{ }\NormalTok{df}\OperatorTok{$}\NormalTok{var.}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] a b c d
Levels: a b c d
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{df[,}\KeywordTok{c}\NormalTok{(}\StringTok{"var.1"}\NormalTok{,}\StringTok{"var.2"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  coordinates var.1 var.2
1      (3, 2)     a     1
2      (2, 5)     b     2
3      (5, 6)     c     3
4      (6, 7)     d     4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{df[,}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  coordinates var.2
1      (3, 2)     1
2      (2, 5)     2
3      (5, 6)     3
4      (6, 7)     4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\CommentTok{#get the bounding box}
\ErrorTok{>}\StringTok{ }\KeywordTok{bbox}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  min max
x   2   6
y   2   7
\end{verbatim}

Here, the data frame \texttt{df} is promoted to a
\texttt{SpatialPointsDataFrame} by indicating the column names that hold
the longitude and latitude (i.e., \texttt{x} and \texttt{y}
respectively) using the \texttt{coordinates} function. Here too, the
\texttt{@data} is used to retrieve the data frame associated with the
points. We also illustrate how variables can be accessed directly from
the spatial object. The \texttt{bbox} function is used to return the
bounding box that is defined by the spatial extent of the point
coordinates. The other spatial objects noted in Table
\ref{tab:spatialObjs} can be created, and their data accessed, in a
similar way\footnote{This cheatsheet
  \url{http://www.maths.lancs.ac.uk/~rowlings/Teaching/UseR2012/cheatsheet.html}
  written by Barry Rowlingson is a useful reference
  \url{http://www.maths.lancs.ac.uk/~rowlings/Teaching/UseR2012/cheatsheet.html}}.

More than often we find ourselves reading existing spatial data files
into R. The code below uses the \texttt{downloader} package to download
all of the PEF data we'll use in this chapter. The data are compressed
in a single zip file, which is then extracted into the working directory
using the \texttt{unzip} function. A look into the PEF directory using
\texttt{list.files} shows nine files\footnote{The \texttt{list.files}
  function does not read data into R; it simply prints the contents of a
  directory.}. Those named \texttt{MU-bounds.*} comprise the shapefile
that holds the PEF's management unit boundaries in the form of polygons.
Like other spatial data file formats, shapefiles are made up of several
different files (with different file extensions) that are linked
together to form a spatial data object. The \texttt{plots.csv} file
holds the spatial coordinates and other information about the PEF's
forest inventory plots. The \texttt{roads.*} shapefile holds roads and
trails in and around the PEF.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(downloader)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{download}\NormalTok{(}\StringTok{"http://blue.for.msu.edu/FOR875/data/PEF.zip"}\NormalTok{, }
\OperatorTok{+}\StringTok{          }\DataTypeTok{destfile=}\StringTok{"./PEF.zip"}\NormalTok{, }\DataTypeTok{mode=}\StringTok{"wb"}\NormalTok{) }
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{unzip}\NormalTok{(}\StringTok{"PEF.zip"}\NormalTok{, }\DataTypeTok{exdir =} \StringTok{"."}\NormalTok{)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{list.files}\NormalTok{(}\StringTok{"PEF"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "MU-bounds.dbf" "MU-bounds.prj" "MU-bounds.qpj"
 [4] "MU-bounds.shp" "MU-bounds.shx" "plots.csv"    
 [7] "plots.dbf"     "plots.prj"     "plots.qpj"    
[10] "plots.shp"     "plots.shx"     "roads.dbf"    
[13] "roads.prj"     "roads.shp"     "roads.shx"    
\end{verbatim}

Next we read the MU-bounds shapefile into R using
\texttt{readOGR()}\footnote{The authors of the \texttt{rgdal} library
  decided to have some information about the version of GDAL and other
  software specifics be printed when the library is loaded. Don't let it
  distract you.} and explore the resulting \texttt{mu} object. Notice
that when we read a shapefile into R, we do not include a file extension
with the shapefile name because a shapefile is always composed of
multiple files.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(rgdal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
rgdal: version: 1.4-4, (SVN revision 833)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20
 Path to GDAL shared files: /usr/share/gdal/2.2
 GDAL binary built with GEOS: TRUE 
 Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493]
 Path to PROJ.4 shared files: (autodetected)
 Linking to sp version: 1.3-1 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu <-}\StringTok{ }\KeywordTok{readOGR}\NormalTok{(}\StringTok{"PEF"}\NormalTok{, }\StringTok{"MU-bounds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
OGR data source with driver: ESRI Shapefile 
Source: "/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/PEF", layer: "MU-bounds"
with 40 features
It has 1 fields
\end{verbatim}

When called, the \texttt{readOGR} function provides a bit of information
about the object being read in. Here, we see that it read the MU-bounds
shapefile from PEF directory and the shapefile had 40 features (i.e.,
polygons) and 1 field (i.e., field is synonymous with column or variable
in the data frame).

You can think of the resulting \texttt{mu} object as a data frame where
each row corresponds to a polygon and each column holds information
about the polygon\footnote{Much of the actual spatial information is
  hidden from you in other parts of the data structure, but is available
  if you ask nicely for it (see subsequent sections).}. More
specifically, the \texttt{mu} object is a
\texttt{SpatialPolygonsDataFrame}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(mu)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
\end{verbatim}

As illustrated using the made-up point data in the example above, you
can access the data frame associated with the polygons using
\texttt{@data}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(mu}\OperatorTok{@}\NormalTok{data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "data.frame"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{dim}\NormalTok{(mu}\OperatorTok{@}\NormalTok{data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 40  1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(mu}\OperatorTok{@}\NormalTok{data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  mu_id
0   C15
1   C17
2   C16
3   C27
4   U18
5   U31
\end{verbatim}

Above, a call to \texttt{class()} confirms we have accessed the data
frame, \texttt{dim()} shows there are 40 rows (one row for each polygon)
and one column, and \texttt{head()} shows the first six values of the
column named \texttt{mu\_id}. The \texttt{mu\_id} values are unique
identifiers for each management unit polygon across the PEF.

\section{Coordinate Reference
Systems}\label{coordinate-reference-systems}

One of the more challenging aspects of working with spatial data is
getting used to the idea of a coordinate reference system. A
\emph{coordinate reference system} (CRS) is a system that uses one or
more numbers, or coordinates, to uniquely determine the position of a
point or other geometric element (e.g., line, polygon, raster). For
spatial data, there are two common coordinate systems:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Spherical coordinate system, such as latitude-longitude, often
  referred to as a \emph{geographic coordinate system}.
\item
  Projected coordinate system based on a map projection, which is a
  systematic transformation of the latitudes and longitudes that aims to
  minimize distortion occurring from projecting maps of the earth's
  spherical surface onto a two-dimensional Cartesian coordinate plane.
  Projected coordinate systems are sometimes referred to as \emph{map
  projections}.
\end{enumerate}

There are numerous map projections\footnote{See partial list of map
  projections at
  \url{https://en.wikipedia.org/wiki/List/_of/_map/_projections}. See a
  humorous discussion of map projections at
  \url{http://brilliantmaps.com/xkcd/}.}. One of the more frustrating
parts of working with spatial data is that it seems like each data
source you find offers its data in a different map projection and hence
you spend a great deal of time \emph{reprojecting} (i.e., transforming
from one CRS to another) data into a common CRS such that they overlay
correctly. Reprojecting is accomplished using the \texttt{sp} package's
\texttt{spTransform} function as demonstrated in Section \ref{ggmap}.

In R, a spatial object's CRS is accessed via the \texttt{sp} package
\texttt{proj4string} function. The code below shows the current
projection of \texttt{mu}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{proj4string}\NormalTok{(mu)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "+proj=utm +zone=19 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
\end{verbatim}

The cryptic looking string returned by \texttt{proj4string()} is a set
of directives understood by the \href{http://proj4.org/}{proj.4} C
library, which is part of \texttt{sp}, and used to map geographic
longitude and latitude coordinates into the projected Cartesian
coordinates. This CRS tells us the \texttt{mu} object is in
\href{https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system}{Universal
Transverse Mercator (UTM)} zone 19 coordinate system.\footnote{If you
  start dealing with a lot of spatial data and reprojecting,
  \url{http://spatialreference.org} is an excellent resources for
  finding and specifying coordinate reference systems.}

\section{\texorpdfstring{Illustration using
\texttt{ggmap}}{Illustration using ggmap}}\label{ggmap}

Let's begin by making a map of PEF management unit boundaries over top
of a satellite image using the \texttt{ggmap} package. Given an address,
location, or bounding box, the \texttt{ggmap} package's
\texttt{get\_map} function will query Google Maps, OpenStreetMap, Stamen
Maps, or Naver Map servers for a user-specified map type. The
\texttt{get\_map} function requires the location or bounding box
coordinates be in a geographic coordinate system (i.e.,
latitude-longitude). This means we need to reproject \texttt{mu} from
UTM zone 19 to latitude-longitude geographic coordinates, which is
defined by the
\texttt{\textquotesingle{}"proj=longlat\ +datum=WGS84"\textquotesingle{}}
proj.4 string. As seen below, the first argument in \texttt{spTransform}
function is the spatial object to reproject and the second argument is a
CRS object created by passing a proj.4 string into the \texttt{CRS}
function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu <-}\StringTok{ }\KeywordTok{spTransform}\NormalTok{(mu, }\KeywordTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +datum=WGS84"}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{proj4string}\NormalTok{(mu)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
\end{verbatim}

Unfortunately, we cannot just feed the \texttt{SpatialPolygonsDataFrame}
\texttt{mu} into \texttt{ggplot} (perhaps some day soon this will
possible). Rather, we need to first convert the
\texttt{SpatialPolygonsDataFrame} into a specially formatted data frame
using the \texttt{fortify} function that is part of the \texttt{ggplot2}
package\footnote{\texttt{ggmap} depends on \texttt{ggplot2} so
  \texttt{ggplot2} will be automatically loaded when you call
  \texttt{library(ggmap)}.}. The \texttt{fortify} function will also
need a unique identifier for each polygon specified using the
\texttt{region} argument, which for \texttt{mu} is the \texttt{mu\_id}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(ggmap)}
\OperatorTok{>}\StringTok{ }\NormalTok{mu.f <-}\StringTok{ }\KeywordTok{fortify}\NormalTok{(mu, }\DataTypeTok{region=}\StringTok{"mu_id"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(mu.f)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    long   lat order  hole piece  id group
1 -68.62 44.86     1 FALSE     1 C12 C12.1
2 -68.62 44.86     2 FALSE     1 C12 C12.1
3 -68.62 44.86     3 FALSE     1 C12 C12.1
4 -68.62 44.86     4 FALSE     1 C12 C12.1
5 -68.62 44.86     5 FALSE     1 C12 C12.1
6 -68.62 44.86     6 FALSE     1 C12 C12.1
\end{verbatim}

Notice the \texttt{id} column in the fortified version of \texttt{mu}
holds each polygon's \texttt{mu\_id} value (this will be important later
when we link data to the polygons).

Next, we query the satellite imagery used to underlay the management
units (we'll generally refer to this underlying map as the basemap). As
of October 2018, Google requires you to set up a Google API account to
download imagery. This is free, but it does require a credit card to
obtain the API Key that is required to make the \texttt{ggmap} package
work. Here I provide you with an API key for a project I created for
this class that should allow you to run the following function if you
desire. If you are interested in obtaining your own API key, see the
page
\href{https://developers.google.com/maps/documentation/geocoding/get-api-key}{here}
for learning about how to use Google maps web services.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{register_google}\NormalTok{(}\DataTypeTok{key =} \StringTok{"AIzaSyBPAwSY5x8vQqlnG-QwiCAWQW12U3CTLZY"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{mu.bbox <-}\StringTok{ }\KeywordTok{bbox}\NormalTok{(mu)}
\OperatorTok{>}\StringTok{ }\NormalTok{mu.centroid <-}\StringTok{ }\KeywordTok{apply}\NormalTok{(mu.bbox, }\DecValTok{1}\NormalTok{, mean)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{basemap <-}\StringTok{ }\KeywordTok{get_map}\NormalTok{(}\DataTypeTok{location=}\NormalTok{mu.centroid, }\DataTypeTok{zoom=}\DecValTok{14}\NormalTok{, }\DataTypeTok{maptype =} \StringTok{"satellite"}\NormalTok{, }\DataTypeTok{source =} \StringTok{"google"}\NormalTok{)}
\OperatorTok{>}\StringTok{                                     }
\ErrorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_polygon}\NormalTok{(}\DataTypeTok{data=}\NormalTok{mu.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }\DataTypeTok{group=}\NormalTok{group), }
\OperatorTok{+}\StringTok{                  }\DataTypeTok{fill=}\OtherTok{NA}\NormalTok{, }\DataTypeTok{size=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{color=}\StringTok{"orange"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-200-1.pdf}
While the call to \texttt{get\_map} can use a bounding box
(\texttt{mu.bbox} in code above) to define the \texttt{basemap} extent,
I've found that it's easier to pass it a center point location
(\texttt{mu.centroid} note the use of the \texttt{apply} function to
find the mean in the easting and northing extents) and \texttt{zoom}
value to extract the desired extent. The resulting map looks pretty
good! Take a look at the \texttt{get\_map} function manual page and try
different options for \texttt{maptype} (e.g.,
\texttt{maptype="terrain"}).

Next we'll add the forest inventory plots to the map. Begin by reading
in the PEF forest inventory plot data held in ``plots.csv''. Recall,
foresters have measured forest variables at a set of locations (i.e.,
inventory plots) within each management unit. The following statement
reads these data and displays the resulting data frame structure.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{plots <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"PEF/plots.csv"}\NormalTok{, }\DataTypeTok{stringsAsFactors=}\OtherTok{FALSE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(plots)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   451 obs. of  8 variables:
 $ mu_id           : chr  "U10" "U10" "U10" "U10" ...
 $ plot            : int  11 13 21 22 23 24 31 32 33 34 ...
 $ easting         : num  529699 529777 529774 529814 529850 ...
 $ northing        : num  4966333 4966471 4966265 4966336 4966402 ...
 $ biomass_mg_ha   : num  96.3 115.7 121.6 72 122.3 ...
 $ stems_ha        : int  5453 2629 3385 7742 7980 10047 5039 5831 2505 7325 ...
 $ diameter_cm     : num  4.8 6.9 6.1 3.1 4.7 1.6 4.1 5.2 5.7 3.3 ...
 $ basal_area_m2_ha: num  22 23.2 23 16.1 29.2 19.1 14.1 27.4 21.6 15 ...
\end{verbatim}

In \texttt{plots} each row is a forest inventory plot and columns are:

\begin{itemize}
\tightlist
\item
  \texttt{mu\_id} identifies the management unit within which the plot
  is located
\item
  \texttt{plot} unique plot number within the management unit
\item
  \texttt{easting} longitude coordinate in UTM zone 19
\item
  \texttt{northing} latitude coordinate in UTM zone 19
\item
  \texttt{biomass\_mg\_ha} tree biomass in metric ton (per hectare
  basis)
\item
  \texttt{stocking\_stems\_ha} number of tree (per hectare basis)
\item
  \texttt{diameter\_cm} average tree diameter measured 130 cm up the
  tree trunk
\item
  \texttt{basal\_area\_m2\_ha} total cross-sectional area at 130 cm up
  the tree trunk (per hectare basis)
\end{itemize}

There is nothing inherently spatial about this data structure---it is
simply a data frame. We make \texttt{plots} into a spatial object by
identifying which columns hold the coordinates. This is done below using
the \texttt{coordinates} function, which promotes the \texttt{plots}
data frame to a \texttt{SpatialPointsDataFrame}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{coordinates}\NormalTok{(plots) <-}\StringTok{ }\ErrorTok{~}\NormalTok{easting}\OperatorTok{+}\NormalTok{northing}
\OperatorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(plots)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"
\end{verbatim}

Although \texttt{plots} is now a \texttt{SpatialPointsDataFrame}, it
does not know to which CRS the coordinates belong; hence, the
\texttt{NA} when \texttt{proj4string(plots)} is called below. As noted
in the \texttt{plots} file description above, \texttt{easting} and
\texttt{northing} are in UTM zone 19. This CRS is set using the second
call to \texttt{proj4string} below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{proj4string}\NormalTok{(plots)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{proj4string}\NormalTok{(plots) <-}\StringTok{ }\KeywordTok{CRS}\NormalTok{(}\StringTok{"+proj=utm +zone=19 +datum=NAD83 +units=m }
\StringTok{+                              +no_defs +ellps=GRS80 +towgs84=0,0,0"}\NormalTok{)                   }
\end{Highlighting}
\end{Shaded}

Now let's reproject \texttt{plots} to share a common CRS with
\texttt{mu}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{plots <-}\StringTok{ }\KeywordTok{spTransform}\NormalTok{(plots, }\KeywordTok{CRS}\NormalTok{(}\StringTok{"+proj=longlat +datum=WGS84"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Note, because \texttt{mu} is already in the projection we want for
\texttt{plots}, we could have replaced the second argument in the
\texttt{spTransform} call above with \texttt{proj4string(mu)} and saved
some typing.

We're now ready to add the forest inventory plots to the existing
basemap with management units. Specifically, let's map the
\texttt{biomass\_mg\_ha} variable to show changes in biomass across the
forest. No need to fortify \texttt{plots}, \texttt{ggplot} is happy to
take \texttt{geom\_point}'s \texttt{data} argument as a data frame
(although we do need to convert \texttt{plots} from a
\texttt{SpatialPointsDataFrame} to a data frame using the
\texttt{as.data.frame} function). Check out the
\texttt{scale\_color\_gradient} function in your favorite
\texttt{ggplot2} reference to understand how the color scale is set.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_polygon}\NormalTok{(}\DataTypeTok{data=}\NormalTok{mu.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }\DataTypeTok{group=}\NormalTok{group), }
\OperatorTok{+}\StringTok{                  }\DataTypeTok{fill=}\OtherTok{NA}\NormalTok{, }\DataTypeTok{size=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{color=}\StringTok{"orange"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{data=}\KeywordTok{as.data.frame}\NormalTok{(plots), }
\OperatorTok{+}\StringTok{                }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ easting, }\DataTypeTok{y =}\NormalTok{ northing, }\DataTypeTok{color=}\NormalTok{biomass_mg_ha)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{     }\KeywordTok{scale_color_gradient}\NormalTok{(}\DataTypeTok{low=}\StringTok{"white"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"darkblue"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{color =} \StringTok{"Biomass (mg/ha)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-205-1.pdf}

There is something subtle and easy to miss in the code above. Notice the
\texttt{aes} function arguments in \texttt{geom\_points} take geographic
longitude and latitude, \texttt{x} and \texttt{y} respectively, from the
\texttt{points} data frame (but recall \texttt{easting} and
\texttt{northing} were in UTM zone 19). This works because we applied
\texttt{spTransform} to reproject the \texttt{points}
\texttt{SpatialPointsDataFrame} to geographic coordinates. \texttt{sp}
then replaces the values in \texttt{easting} and \texttt{northing}
columns with the reprojected coordinate values when converting a
\texttt{SpatialPointsDataFrame} to a data frame via
\texttt{as.data.frame()}.

Foresters use the inventory plot measurements to estimate forest
variables within management units, e.g., the average or total management
unit biomass. Next we'll make a plot with management unit polygons
colored by average \texttt{biomass\_mg\_ha}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.bio <-}\StringTok{ }\NormalTok{plots}\OperatorTok{@}\NormalTok{data }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(mu_id) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{     }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{biomass_mu =} \KeywordTok{mean}\NormalTok{(biomass_mg_ha))}
\OperatorTok{>}\StringTok{ }\KeywordTok{print}\NormalTok{(mu.bio)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 33 x 2
   mu_id biomass_mu
   <chr>      <dbl>
 1 C12        124. 
 2 C15         49.9
 3 C16        128. 
 4 C17        112. 
 5 C20        121. 
 6 C21        134. 
 7 C22         65.2
 8 C23A       108. 
 9 C23B       153. 
10 C24        126. 
# ... with 23 more rows
\end{verbatim}

Recall from Section \ref{pipes} this one-liner can be read as ``get the
data frame from \texttt{plots}'s \texttt{SpatialPointsDataFrame}
\emph{then} group by management unit \emph{then} make a new variable
called \texttt{biomass\_mu} that is the average of
\texttt{biomass\_mg\_ha} and assign it to the \texttt{mu.bio} tibble.''

The management unit specific \texttt{biomass\_mu} can now be joined to
the \texttt{mu} polygons using the common \texttt{mu\_id} value.
Remember when we created the fortified version of \texttt{mu} called
\texttt{mu.f}? The \texttt{fortify} function \texttt{region} argument
was \texttt{mu\_id} which is the \texttt{id} variable in the resulting
\texttt{mu.f}. This \texttt{id} variable in \texttt{mu.f} can be linked
to the \texttt{mu\_id} variable in \texttt{mu.bio} using
\texttt{dplyr}'s \texttt{left\_join} function as illustrated below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(mu.f, }\DataTypeTok{n=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    long   lat order  hole piece  id group
1 -68.62 44.86     1 FALSE     1 C12 C12.1
2 -68.62 44.86     2 FALSE     1 C12 C12.1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.f <-}\StringTok{ }\KeywordTok{left_join}\NormalTok{(mu.f, mu.bio, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{'id'}\NormalTok{ =}\StringTok{ 'mu_id'}\NormalTok{))}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(mu.f, }\DataTypeTok{n=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    long   lat order  hole piece  id group biomass_mu
1 -68.62 44.86     1 FALSE     1 C12 C12.1      123.7
2 -68.62 44.86     2 FALSE     1 C12 C12.1      123.7
\end{verbatim}

The calls to \texttt{head()} show the first few rows of \texttt{mu.f}
pre- and post-join. After the join, \texttt{mu.f} includes
\texttt{biomass\_mu}, which is used used below for
\texttt{geom\_polygon}'s \texttt{fill} argument to color the polygons
accordingly.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_polygon}\NormalTok{(}\DataTypeTok{data=}\NormalTok{mu.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }
\OperatorTok{+}\StringTok{                                 }\DataTypeTok{group=}\NormalTok{group, }\DataTypeTok{fill=}\NormalTok{biomass_mu), }
\OperatorTok{+}\StringTok{                  }\DataTypeTok{size=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{color=}\StringTok{"orange"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{scale_fill_gradient}\NormalTok{(}\DataTypeTok{low=}\StringTok{"white"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"darkblue"}\NormalTok{, }
\OperatorTok{+}\StringTok{                         }\DataTypeTok{na.value=}\StringTok{"transparent"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{fill=}\StringTok{"Biomass (mg/ha)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-208-1.pdf}

Let's add the roads and some more descriptive labels as a finishing
touch. The roads data include a variable called \texttt{type} that
identifies the road type. To color roads by type in the map, we need to
join the \texttt{roads} data frame with the fortified roads
\texttt{roads.f} using the common variable \texttt{id} as a road segment
specific identifier. Then \texttt{geom\_path}'s \texttt{color} argument
gets this \texttt{type} variable as a factor to create road-specific
color. The default coloring of the roads blends in too much with the
polygon colors, so we manually set the road colors using the
\texttt{scale\_color\_brewer} function. The \texttt{palette} argument in
this function accepts a set of key words, e.g., \texttt{"Dark2"}, that
specify sets of diverging colors chosen to make map object difference
optimally distinct (see, the manual page for
\texttt{scale\_color\_brewer}, \url{http://colorbrewer2.org}, and blog
\href{https://www.r-bloggers.com/r-using-rcolorbrewer-to-colour-your-figures-in-r}{here}.)\footnote{Install
  the \texttt{RColorBrewer} package and run
  \texttt{library(RColorBrewer);\ display.brewer.all()} to get a
  graphical list of available palettes.}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{roads <-}\StringTok{ }\KeywordTok{readOGR}\NormalTok{(}\StringTok{"PEF"}\NormalTok{, }\StringTok{"roads"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
OGR data source with driver: ESRI Shapefile 
Source: "/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/PEF", layer: "roads"
with 33 features
It has 2 fields
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{roads <-}\StringTok{ }\KeywordTok{spTransform}\NormalTok{(roads, }\KeywordTok{proj4string}\NormalTok{(mu))}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{roads.f <-}\StringTok{ }\KeywordTok{fortify}\NormalTok{(roads, }\DataTypeTok{region=}\StringTok{"id"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{roads.f <-}\StringTok{ }\KeywordTok{left_join}\NormalTok{(roads.f, roads}\OperatorTok{@}\NormalTok{data, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{'id'}\NormalTok{ =}\StringTok{ 'id'}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: Column `id` joining character vector and
factor, coercing into character vector
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_polygon}\NormalTok{(}\DataTypeTok{data=}\NormalTok{mu.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }\DataTypeTok{group=}\NormalTok{group, }
\OperatorTok{+}\StringTok{                                 }\DataTypeTok{fill=}\NormalTok{biomass_mu), }
\OperatorTok{+}\StringTok{                  }\DataTypeTok{size=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{color=}\StringTok{"orange"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_path}\NormalTok{(}\DataTypeTok{data=}\NormalTok{roads.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }
\OperatorTok{+}\StringTok{                                 }\DataTypeTok{group=}\NormalTok{group, }\DataTypeTok{color=}\KeywordTok{factor}\NormalTok{(type))) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{scale_fill_gradient}\NormalTok{(}\DataTypeTok{low=}\StringTok{"white"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"darkblue"}\NormalTok{, }
\OperatorTok{+}\StringTok{                         }\DataTypeTok{na.value=}\StringTok{"transparent"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{scale_color_brewer}\NormalTok{(}\DataTypeTok{palette=}\StringTok{"Dark2"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{fill=}\StringTok{"Biomass (mg/ha)"}\NormalTok{, }\DataTypeTok{color=}\StringTok{"Road type"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"Longitude"}\NormalTok{, }
\OperatorTok{+}\StringTok{          }\DataTypeTok{ylab=}\StringTok{"Latitude"}\NormalTok{, }\DataTypeTok{title=}\StringTok{"PEF forest biomass"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: Removed 616 rows containing missing values
(geom_path).
\end{verbatim}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-209-1.pdf}

The second, and more cryptic, of the two warnings from this code occurs
because some of the roads extend beyond the range of the map axes and
are removed (nothing to worry about).

\section{\texorpdfstring{Illustration using
\texttt{leaflet}}{Illustration using leaflet}}\label{illustration-using-leaflet}

Leaflet is one of the most popular open-source JavaScript libraries for
interactive maps. As noted on the official
\href{https://rstudio.github.io/leaflet}{R leaflet website}, it's used
by websites ranging from \emph{The New York Times} and \emph{The
Washington Post} to GitHub and Flickr, as well as by GIS specialists
like OpenStreetMap, Mapbox, and CartoDB.

The \href{https://rstudio.github.io/leaflet}{R leaflet website} is an
excellent resource to learn leaflet basics, and should serve as a
reference to gain a better understanding of the topics we briefly
explore below.

You create a leaflet map using these basic steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a map by calling \texttt{leaflet()}
\item
  Add data layers to the map using layer functions such as,
  \texttt{addTiles()}, \texttt{addMarkers()}, \texttt{addPolygons()},
  \texttt{addCircleMarkers()}, \texttt{addPolylines()},
  \texttt{addRasterImage()} and other \texttt{add...} functions
\item
  Repeat step 2 to add more layers to the map
\item
  Print the map to display it
\end{enumerate}

Here's a brief example.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(leaflet)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{m <-}\StringTok{ }\KeywordTok{leaflet}\NormalTok{() }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{       }\KeywordTok{addTiles}\NormalTok{() }\OperatorTok{%>%}\StringTok{  }\CommentTok{# Add default OpenStreetMap map tiles}
\OperatorTok{+}\StringTok{       }\KeywordTok{addMarkers}\NormalTok{(}\DataTypeTok{lng=}\OperatorTok{-}\FloatTok{84.482004}\NormalTok{, }\DataTypeTok{lat=}\FloatTok{42.727516}\NormalTok{, }
\OperatorTok{+}\StringTok{                  }\DataTypeTok{popup=}\StringTok{"<b>Here I am!</b>"}\NormalTok{) }\CommentTok{# Add a clickable marker}
\OperatorTok{>}\StringTok{ }\NormalTok{m  }\CommentTok{# Print the map}
\end{Highlighting}
\end{Shaded}

\hypertarget{htmlwidget-4b2ba1852a569edfcbe7}{}

There are a couple things to note in the code. First, we use the pipe
operator \texttt{\%\textgreater{}\%} just like in \texttt{dplyr}
functions. Second, the \texttt{popup} argument in \texttt{addMarkers()}
takes standard HTML and clicking on the marker makes the text popup.
Third, the html version of this text provides the full interactive,
dynamic map, so we encourage you to read and interact with the html
version of this textbook for this section. The PDF document will simply
display a static version of this map and will not do justice to how
awesome \texttt{leaflet} truly is!

As seen in the \texttt{leaflet()} call above, the various
\texttt{add...} functions can take longitude (i.e., \texttt{lng}) and
latitude (i.e., \texttt{lat}). Alternatively, these functions can
extract the necessary spatial information from \texttt{sp} objects,
e.g., Table \ref{tab:spatialObjs}, when passed to the data argument
(which greatly simplifies life compared with map making using
\texttt{ggmap}).

\section{Subsetting Spatial Data}\label{subsetting-spatial-data}

You can imagine that we might want to subset spatial objects to map
specific points, lines, or polygons that meet some criteria, or perhaps
extract values from polygons or raster surfaces at a set of points or
geographic extent. These, and similar types, of operations are easy in R
(as long as all spatial objects are in a common CRS). Recall from
Chapter \ref{structures} how handy it is to subset data structures,
e.g., vectors and data frames, using the \texttt{{[}{]}} operator and
logical vectors? Well it's just as easy to subset spatial objects,
thanks to the authors of \texttt{sp}, \texttt{raster}, and other spatial
data packages.

\subsection{\texorpdfstring{Fetching and Cropping Data using
\texttt{raster}}{Fetching and Cropping Data using raster}}\label{fetching-and-cropping-data-using-raster}

In order to motivate our exploration of spatial data subsetting and to
illustrate some useful functionality of the \texttt{raster} package,
let's download some elevation data for the PEF. The \texttt{raster}
package has a rich set of functions for manipulating raster data as well
as functions for downloading data from open source repositories. We'll
focus on the package's \texttt{getData} function, which, given a
location in geographic longitude and latitude or location name, will
download data from
\href{http://www.gadm.org/\%7D\%7BGlobal\%20Administrative\%20Boundaries}{GADM},
\href{https://www2.jpl.nasa.gov/srtm/\%7D\%7BShuttle\%20Radar\%20Topography\%20Mission}{Shuttle
Radar Topography Mission}, \href{http://www.worldclim.org/}{Global
Climate Data}, and other sources commonly used in spatial data
applications.

Let's download SRTM surface elevation data for the PEF, check the
resulting object's class and CRS, and display it using the
\texttt{raster} package's \texttt{image} function along with the PEF
forest inventory plots.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(raster)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{pef.centroid <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(plots) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{     }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mu.x =} \KeywordTok{mean}\NormalTok{(easting), }\DataTypeTok{mu.y =} \KeywordTok{mean}\NormalTok{(northing))}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{srtm <-}\StringTok{ }\KeywordTok{getData}\NormalTok{(}\StringTok{"SRTM"}\NormalTok{, }\DataTypeTok{lon =}\NormalTok{ pef.centroid[, }\DecValTok{1}\NormalTok{], }\DataTypeTok{lat =}\NormalTok{ pef.centroid[, }\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{class}\NormalTok{(srtm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "RasterLayer"
attr(,"package")
[1] "raster"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{proj4string}\NormalTok{(srtm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{image}\NormalTok{(srtm)}
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(plots, }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-213-1.pdf}

A few things to notice in the code above. First the \texttt{getData}
function needs the longitude \texttt{lon} and latitude \texttt{lat} to
identify which SRTM raster tile to return (SRTM data come in large
raster tiles that cover the globe). As usual, look at the
\texttt{getData} function documentation for a description of the
arguments. To estimate the PEF's centroid coordinate, we averaged the
forest inventory plots' latitude and longitude then assigned the result
to \texttt{pef.centroid} (for fun, I used the \texttt{apply} function to
do the same task when creating \texttt{mu.centroid} earlier in the
chapter). Second, \texttt{srtm} is in a longitude latitude geographic
CRS (same as our other PEF data). Finally, the image shows SRTM
elevation along the coast of Maine, the PEF plots are those tiny specks
of black in the northwest quadrant, and the white region of the image is
the Atlantic Ocean.

Okay, this is a start, but it would be good to crop the SRTM image to
the PEF's extent. This is done using \texttt{raster}'s \texttt{crop}
function. This function can use many different kinds of spatial objects
in the second argument to calculate the extent at which to crop the
object in the first argument. Here, I set \texttt{mu} as the second
argument and save the resulting SRTM subset over the larger tile (the
\texttt{srtm} object).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{srtm <-}\StringTok{ }\KeywordTok{crop}\NormalTok{(srtm, mu)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{image}\NormalTok{(srtm)}
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(mu, }\DataTypeTok{add =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-214-1.pdf}

The \texttt{crop} is in effect doing a spatial subsetting of the raster
data. We'll return to the \texttt{srtm} data and explore different kinds
of subsetting in the subsequent sections.

\subsection{Logical, Index, and Name
Subsetting}\label{logical-index-and-name-subsetting}

As promised, we can subset spatial objects using the \texttt{{[}{]}}
operator and a logical, index, or name vector. The key is that
\texttt{sp} objects behave like data frames, see Section
\ref{dataFrames}. A logical or index vector to the left of the comma in
\texttt{{[},{]}} accesses points, lines, polygons, or pixels. Similarly,
a logical, index, or name vector to the right of the comma accesses
variables.

For example, say we want to map forest inventory plots with more than
10,000 stems per hectare, \texttt{stems\_ha} (the \texttt{min()} was
added below to double check that the subset worked correctly.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{min}\NormalTok{(plots}\OperatorTok{$}\NormalTok{stems_ha)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 119
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{plots.10k <-}\StringTok{ }\NormalTok{plots[plots}\OperatorTok{$}\NormalTok{stems_ha }\OperatorTok{>}\StringTok{ }\DecValTok{10000}\NormalTok{,]}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{min}\NormalTok{(plots.10k}\OperatorTok{$}\NormalTok{stems_ha)     }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 10008
\end{verbatim}

You can also add new variables to the spatial objects.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{plots}\OperatorTok{$}\NormalTok{diameter_in <-}\StringTok{ }\NormalTok{plots}\OperatorTok{$}\NormalTok{diameter_cm}\OperatorTok{/}\FloatTok{2.54}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(plots)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  mu_id plot biomass_mg_ha stems_ha diameter_cm
1   U10   11         96.35     5453         4.8
2   U10   13        115.70     2629         6.9
3   U10   21        121.58     3385         6.1
4   U10   22         71.97     7742         3.1
5   U10   23        122.26     7980         4.7
6   U10   24         85.85    10047         1.6
  basal_area_m2_ha diameter_in
1             22.0      1.8898
2             23.2      2.7165
3             23.0      2.4016
4             16.1      1.2205
5             29.2      1.8504
6             19.1      0.6299
\end{verbatim}

\subsection{Spatial Subsetting and
Overlay}\label{spatial-subsetting-and-overlay}

A spatial overlay retrieves the indexes or variables from object \(A\)
using the location of object \(B\). With some spatial objects this
operation can be done using the \texttt{{[}{]}} operator. For example,
say we want to select and map all management units in \texttt{mu}, i.e.,
\(A\), that contain plots with more than 10,000 stems per ha, i.e.,
\(B\).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.10k <-}\StringTok{ }\NormalTok{mu[plots.10k,]## A[B,]}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{mu.10k.f <-}\StringTok{ }\KeywordTok{fortify}\NormalTok{(mu.10k, }\DataTypeTok{region=}\StringTok{"mu_id"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_polygon}\NormalTok{(}\DataTypeTok{data=}\NormalTok{mu.10k.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }\DataTypeTok{group=}\NormalTok{group), }\DataTypeTok{fill=}\StringTok{"transparent"}\NormalTok{, }\DataTypeTok{size=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{color=}\StringTok{"orange"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{data=}\KeywordTok{as.data.frame}\NormalTok{(plots.10k), }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ easting, }\DataTypeTok{y =}\NormalTok{ northing), }\DataTypeTok{color=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-217-1.pdf}

More generally, however, the \texttt{over} function offers consistent
overlay operations for \texttt{sp} objects and can return either indexes
or variables from object \(A\) given locations from object \(B\), i.e.,
\texttt{over(B,\ A)} or, equivalently, \texttt{B\%over\%A}. The code
below duplicates the result from the preceding example using
\texttt{over}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.10k <-}\StringTok{ }\NormalTok{mu[mu}\OperatorTok{$}\NormalTok{mu_id }\OperatorTok{%in%}\StringTok{ }\KeywordTok{unique}\NormalTok{(}\KeywordTok{over}\NormalTok{(plots.10k, mu)}\OperatorTok{$}\NormalTok{mu_id),]}
\end{Highlighting}
\end{Shaded}

Yes, this requires more code but \texttt{over} provides a more flexible
and general purpose function for overlays on the variety of \texttt{sp}
objects. Let's unpack this one-liner into its five steps.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{i <-}\StringTok{ }\KeywordTok{over}\NormalTok{(plots.10k, mu)}
\OperatorTok{>}\StringTok{ }\NormalTok{ii <-}\StringTok{ }\NormalTok{i}\OperatorTok{$}\NormalTok{mu_id}
\OperatorTok{>}\StringTok{ }\NormalTok{iii <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(ii)}
\OperatorTok{>}\StringTok{ }\NormalTok{iv <-}\StringTok{ }\NormalTok{mu}\OperatorTok{$}\NormalTok{mu_id }\OperatorTok{%in%}\StringTok{ }\NormalTok{iii}
\OperatorTok{>}\StringTok{ }\NormalTok{v <-}\StringTok{ }\NormalTok{mu[iv,]}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  The \texttt{over} function returns variables for \texttt{mu}'s
  polygons that coincide with the \texttt{nrow(plots.10k@data)} points
  in \texttt{plots.10k}. No points fall outside the polygons and the
  polygons do not overlap, so i should be a data frame with
  \texttt{nrow(plots.10k@data)} rows. If polygons did overlap and a
  point fell within the overlap region, then variables for the
  coinciding polygons are returned.
\item
  Select the unique \texttt{mu} identifier \texttt{mu\_id} (this step is
  actually not necessary here because \texttt{mu} only has one
  variable).
\item
  Because some management units contain multiple plots there will be
  repeat values of \texttt{mu\_id} in ii, so apply the \texttt{unique}
  function to get rid of duplicates.
\item
  Use the \texttt{\%in\%} operator to create a logical vector that
  identifies which polygons should be in the final map.
\item
  Subset \texttt{mu} using the logical vector created in iv.
\end{enumerate}

Now let's do something similar using the \texttt{srtm} elevation raster.
Say we want to map elevation along trails, winter roads, and gravel
roads across the PEF. We could subset \texttt{srtm} using the
\texttt{roads} \texttt{SpatialLinesDataFrame}; however, mapping the
resulting pixel values along the road segments using \texttt{ggmap}
requires a bit more massaging. So, to simplify things for this example,
\texttt{roads} is first coerced into a \texttt{SpatialPointsDataFrame}
called \texttt{roads.pts} that is used to extract spatially coinciding
\texttt{srtm} pixel values which themselves are coerced from
\texttt{raster}'s \texttt{RasterLayer} to \texttt{sp}'s
\texttt{SpatialPixelsDataFrame} called \texttt{srtm.sp} so that we can
use the \texttt{over} function. We also choose a different basemap just
for fun.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{hikes <-}\StringTok{ }\NormalTok{roads[roads}\OperatorTok{$}\NormalTok{type }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Trail"}\NormalTok{, }\StringTok{"Winter"}\NormalTok{, }\StringTok{"Gravel"}\NormalTok{),]}
\OperatorTok{>}\StringTok{  }
\ErrorTok{>}\StringTok{ }\NormalTok{hikes.pts <-}\StringTok{ }\KeywordTok{as}\NormalTok{(hikes, }\StringTok{"SpatialPointsDataFrame"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{srtm.sp <-}\StringTok{ }\KeywordTok{as}\NormalTok{(srtm, }\StringTok{"SpatialPixelsDataFrame"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{hikes.pts}\OperatorTok{$}\NormalTok{srtm <-}\StringTok{ }\KeywordTok{over}\NormalTok{(hikes.pts, srtm.sp)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{basemap <-}\StringTok{ }\KeywordTok{get_map}\NormalTok{(}\DataTypeTok{location=}\NormalTok{mu.centroid, }\DataTypeTok{zoom=}\DecValTok{14}\NormalTok{, }\DataTypeTok{maptype =} \StringTok{"terrain"}\NormalTok{, }\DataTypeTok{source =} \StringTok{"google"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{color.vals <-}\StringTok{ }\NormalTok{srtm}\OperatorTok{@}\NormalTok{data}\OperatorTok{@}\NormalTok{values[}\DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(hikes.pts)]}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{data=}\KeywordTok{as.data.frame}\NormalTok{(hikes.pts),}
\OperatorTok{+}\StringTok{                }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ coords.x1, }\DataTypeTok{y =}\NormalTok{ coords.x2, }\DataTypeTok{color =}\NormalTok{ color.vals)) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{scale_color_gradient}\NormalTok{(}\DataTypeTok{low=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{color =} \StringTok{"Hiking trail elevation}\CharTok{\textbackslash{}n}\StringTok{(m above sea level)"}\NormalTok{,}
\OperatorTok{+}\StringTok{          }\DataTypeTok{xlab=}\StringTok{"Longitude"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Latitude"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: Removed 483 rows containing missing values
(geom_point).
\end{verbatim}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-220-1.pdf}

In the call to \texttt{geom\_point} above, \texttt{coords.x1}
\texttt{coords.x2} are the default names given to longitude and
latitude, respectively, when \texttt{sp} coerces \texttt{hikes} to
\texttt{hikes.pts}. These points represent the vertices along line
segments. I create the vector \texttt{color.vals} that contains the
values from \texttt{srtm} that I use in the map argument \texttt{color}.

Overlay operations involving lines and polygons over polygons require
the \texttt{rgeos} package which provides an interface to the
\href{https://trac.osgeo.org/geos/}{Geometry Engine - Open Source}
(GEOS) \texttt{C++} library for topology operations on geometries. We'll
leave it to you to explore these capabilities.

\subsection{Spatial Aggregation}\label{spatial-aggregation}

We have seen aggregation operations before when using \texttt{dplyr}'s
\texttt{summarize} function. The \texttt{summarize} function is
particularly powerful when combined with \texttt{group\_by()}, which can
apply a function specified in \texttt{summarize()} to a variable
partitioned using a grouping variable. The \texttt{aggregate} function
in \texttt{sp} works in a similar manner, except groups are delineated
by the spatial extent of a thematic variable. In fact, the work we did
to create \texttt{mu.bio} using \texttt{dplyr} functions can be
accomplished with \texttt{aggregate()}. Using \texttt{aggregate()} will,
however, require a slightly different approach for joining the derived
average \texttt{biomass\_mg\_ha} to the fortified \texttt{mu}. This is
because the \texttt{aggregate} function will apply the user specified
function to all variables in the input object, which, in our case,
results in an \texttt{NA} for the linking variable \texttt{mu\_id} as
demonstrated below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.ag <-}\StringTok{ }\KeywordTok{aggregate}\NormalTok{(plots[,}\KeywordTok{c}\NormalTok{(}\StringTok{"mu_id"}\NormalTok{,}\StringTok{"biomass_mg_ha"}\NormalTok{)], }\DataTypeTok{by=}\NormalTok{mu, }\DataTypeTok{FUN=}\NormalTok{mean)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(mu.ag}\OperatorTok{@}\NormalTok{data, }\DataTypeTok{n=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  mu_id biomass_mg_ha
0  <NA>         49.86
1  <NA>        112.17
\end{verbatim}

With \texttt{mu\_id} rendered useless, we do not have a variable that
uniquely identifies each polygon for use in \texttt{fortify}'s
\texttt{region} argument; hence no way to subsequently join the
unfortified and fortified versions of \texttt{mu.bio.ag}. Here's the
work around. If the \texttt{region} is not specified, \texttt{fortify()}
uses an internal unique polygon ID that is part of the \texttt{sp} data
object and accessed via \texttt{row.names()}\footnote{With other data,
  there is a chance the row names differ from the unique polygon IDs.
  Therefore a more reliable approach to getting a unique ID is to use
  \texttt{sapply(slot(mu.ag,\ \textquotesingle{}polygons\textquotesingle{}),\ function(x)\ slot(x,\ \textquotesingle{}ID\textquotesingle{}))},
  but replace \texttt{mu.ag} with your
  \texttt{SpatialPolygonsDataFrame}. Also, this approach will work with
  other \texttt{sp} objects in the right column of Table
  \ref{tab:spatialObjs}.} So, the trick is to add this unique polygon ID
to the \texttt{aggregate()} output prior to calling \texttt{fortify()}
as demonstrated below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.ag}\OperatorTok{$}\NormalTok{id <-}\StringTok{ }\KeywordTok{row.names}\NormalTok{(mu.ag)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{mu.ag.f <-}\StringTok{ }\KeywordTok{fortify}\NormalTok{(mu.ag)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Regions defined for each Polygons
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.ag.f <-}\StringTok{ }\KeywordTok{left_join}\NormalTok{(mu.ag.f, mu.ag}\OperatorTok{@}\NormalTok{data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Joining, by = "id"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_polygon}\NormalTok{(}\DataTypeTok{data=}\NormalTok{mu.ag.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }
\OperatorTok{+}\StringTok{                                 }\DataTypeTok{group=}\NormalTok{group, }\DataTypeTok{fill=}\NormalTok{biomass_mg_ha), }
\OperatorTok{+}\StringTok{                  }\DataTypeTok{size=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{color=}\StringTok{"orange"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{scale_fill_gradient}\NormalTok{(}\DataTypeTok{low=}\StringTok{"white"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"darkblue"}\NormalTok{, }
\OperatorTok{+}\StringTok{                         }\DataTypeTok{na.value=}\StringTok{"transparent"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{fill=}\StringTok{"Biomass (mg/ha)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-222-1.pdf}

The \texttt{aggregate()} function will work with all \texttt{sp}
objects. For example let's map the variance of pixel values in
\texttt{srtm.sp} by management unit. Notice that \texttt{aggregate()} is
happy to take a user-specified function for \texttt{FUN}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.srtm <-}\StringTok{ }\KeywordTok{aggregate}\NormalTok{(srtm.sp, }\DataTypeTok{by=}\NormalTok{mu,}
\OperatorTok{+}\StringTok{                      }\DataTypeTok{FUN=}\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{var}\NormalTok{(x))\})}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{mu.srtm}\OperatorTok{$}\NormalTok{id <-}\StringTok{ }\KeywordTok{row.names}\NormalTok{(mu.srtm)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{mu.srtm.f <-}\StringTok{ }\KeywordTok{fortify}\NormalTok{(mu.srtm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Regions defined for each Polygons
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{mu.srtm.f <-}\StringTok{ }\KeywordTok{left_join}\NormalTok{(mu.srtm.f, mu.srtm}\OperatorTok{@}\NormalTok{data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Joining, by = "id"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggmap}\NormalTok{(basemap) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{geom_polygon}\NormalTok{(}\DataTypeTok{data=}\NormalTok{mu.srtm.f, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ long, }\DataTypeTok{y =}\NormalTok{ lat, }\DataTypeTok{group=}\NormalTok{group, }
\OperatorTok{+}\StringTok{                                      }\DataTypeTok{fill=}\NormalTok{srtm_23_}\DecValTok{04}\NormalTok{), }
\OperatorTok{+}\StringTok{                  }\DataTypeTok{size=}\FloatTok{0.2}\NormalTok{, }\DataTypeTok{color=}\StringTok{"orange"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{     }\KeywordTok{scale_fill_gradient}\NormalTok{(}\DataTypeTok{low=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{high=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\OperatorTok{+}\StringTok{         }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{fill =} \StringTok{"Elevation standard deviation}\CharTok{\textbackslash{}n}\StringTok{(m above sea level)"}\NormalTok{, }
\OperatorTok{+}\StringTok{          }\DataTypeTok{xlab=}\StringTok{"Longitude"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Latitude"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-223-1.pdf}

\section{Where to go from here}\label{where-to-go-from-here}

This chapter just scratches the surface of R's spatial data manipulation
and visualization capabilities. The basic ideas we presented here should
allow you to take a deeper look into \texttt{sp}, \texttt{rgdal},
\texttt{rgeos}, \texttt{ggmap}, \texttt{leaflet}, and a myriad of other
excellent user-contributed R spatial data packages. A good place to
start is with Edzer Pebesma's excellent vignette on the use of the map
overlay and spatial aggregation, available
\href{https://cran.r-project.org/web/packages/sp/vignettes/over.pdf}{here},
as well as \emph{Applied Spatial Data Analysis with R} by
\cite{Bivand13}.

\section{Exercises}\label{exercises-5}

\textbf{Exercise Spatial Data} Learning objectives: practice loading and
reprojecting spatial data; analyze spatial data; create leaflet maps to
convey analysis results; interpret analysis results.

\chapter{Shiny: Interactive Web Apps in
R}\label{shiny-interactive-web-apps-in-r}

\href{https://shiny.rstudio.com/}{Shiny} is a framework that turns R
code and figures into interactive web applications. Let's start out by
looking at a built-in example Shiny app.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(shiny)}
\OperatorTok{>}\StringTok{ }\KeywordTok{runExample}\NormalTok{(}\StringTok{"01_hello"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In the bottom panel of the resulting Shiny app (Figure \ref{fig:hello}),
we can see the R script that is essential to running any Shiny app:
\texttt{app.R}. Take a minute to explore how the app works and how the
script code is structured. The first part of the script
(\texttt{ui\ \textless{}-}) defines the app's user interface (UI) using
directives that partition the resulting web page and placement of input
and output elements. The second part of the script defines a function
called \texttt{server} with arguments \texttt{input} and
\texttt{output}. This function provides the logic required to run the
app (in this case, to draw the histogram of the Old Faithful Geyser
Data). Third, \texttt{ui} and \texttt{server} are passed to a function
called \texttt{shinyApp} which creates the application.\footnote{Since
  2014, Shiny has supported single-file applications (one file called
  app.R that contains UI and server components), but in other resources,
  you may see two separate source files, \texttt{server.R} and
  \texttt{ui.R}, that correspond to those two components. We will use
  the updated one-file system here, but keep in mind that older
  resources you find on the internet using the Shiny package may employ
  the two-file approach. Ultimately, the code inside these files is
  almost identical to that within the single \texttt{app.R} file. See
  \url{https://shiny.rstudio.com/articles/app-formats.html} for more
  information.}

\begin{figure}
\includegraphics[width=1\linewidth]{../../for875-19/figures/hello_shiny} \caption{Hello Shiny example app}\label{fig:hello}
\end{figure}

All of the example code and data for the remainder of this chapter can
be accessed using the following code.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(downloader)}

\KeywordTok{download}\NormalTok{(}\StringTok{"http://blue.for.msu.edu/FOR875/data/shiny_chapter_code.zip"}\NormalTok{, }
         \DataTypeTok{destfile=}\StringTok{"./shiny_chapter_code.zip"}\NormalTok{, }\DataTypeTok{mode=}\StringTok{"wb"}\NormalTok{)}

\KeywordTok{unzip}\NormalTok{(}\StringTok{"shiny_chapter_code.zip"}\NormalTok{, }\DataTypeTok{exdir =} \StringTok{"."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Running a Simple Shiny App}\label{running-a-simple-shiny-app}

Shiny apps allow users to interact with a data set. Let's say we have
access to a dummy data set \texttt{name\_list.csv}. Begin by taking a
quick look at what this CSV file contains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{namesDF <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"http://blue.for.msu.edu/FOR875/data/name_list.csv"}\NormalTok{, }
                    \DataTypeTok{stringsAsFactors =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{str}\NormalTok{(namesDF)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   200 obs. of  4 variables:
 $ First: chr  "Sarah" "Boris" "Jessica" "Diane" ...
 $ Last : chr  "Poole" "Dowd" "Wilkins" "Murray" ...
 $ Age  : int  15 52 12 58 56 4 14 0 28 27 ...
 $ Sex  : chr  "F" "M" "F" "F" ...
\end{verbatim}

Given the \texttt{namesDF} data, our goal over the next few sections is
to develop a Shiny application that allows users to explore age
distributions for males and females. We begin by defining a very basic
Shiny application script upon which we can build the desired
functionality. The script file that defines this basic application is
called \texttt{app.R} and is provided in the code block below called
``version 1''. Follow the subsequent steps to create and run this Shiny
app (note these steps are already done for you in the ``ShinyPractice''
directory in ``shiny\_chapter\_code.zip'', but you might want to do it
yourself):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a new directory called ``ShinyPractice''.
\item
  In the ``ShinyPractice'' directory, create a blank R script called
  \texttt{app.R}.
\item
  Copy the code in ``app.R version 1'' into \texttt{app.R}.
\item
  Run the Shiny app from RStudio. There are two ways to do this: 1) use
  the RStudio button (See Figure \ref{fig:fig1}) or; 2) type the
  function \texttt{runApp()} in the RStudio console.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# app.R version 1}

\KeywordTok{library}\NormalTok{(shiny)}

\NormalTok{names.df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"http://blue.for.msu.edu/FOR875/data/name_list.csv"}\NormalTok{)}

\CommentTok{# Define UI}
\NormalTok{ui <-}\StringTok{ }\KeywordTok{fluidPage}\NormalTok{(}
  
  \KeywordTok{titlePanel}\NormalTok{(}\StringTok{"Random Names Analysis"}\NormalTok{),}
  
  \KeywordTok{sidebarLayout}\NormalTok{(}
    
    \KeywordTok{sidebarPanel}\NormalTok{(}\StringTok{"our inputs will be here"}\NormalTok{),}
    
    \KeywordTok{mainPanel}\NormalTok{(}\StringTok{"our output will appear here"}\NormalTok{)}
\NormalTok{  )}
\NormalTok{)}

\CommentTok{# Define server logic}
\NormalTok{server <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(input, output) \{\}}

\CommentTok{# Create Shiny app}
\KeywordTok{shinyApp}\NormalTok{(}\DataTypeTok{ui =}\NormalTok{ ui, }\DataTypeTok{server =}\NormalTok{ server)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{../figures/RStudio_runApp} \caption{Running a Shiny app locally}\label{fig:fig1}
\end{figure}

If everything compiles correctly, you should get a window that looks
like Figure \ref{fig:fig2}. There are a few things to notice. First, we
read in the CSV file at the beginning of the \texttt{app.R} script so
that these data can be accessed in subsquent development steps (although
we don't use it yet in this initial application). Second, our Shiny app
is not interactive yet because there is no way for a user to input any
data---the page is view-only. Third, the function
\texttt{function(input,output)\ \{\}} in \texttt{app.R} does not include
any code, reflecting that we are not yet using any user inputs or
creating any outputs.

\begin{figure}
\includegraphics[width=1\linewidth]{../figures/appSimple} \caption{Your first Shiny app}\label{fig:fig2}
\end{figure}

\section{Adding User Input}\label{adding-user-input}

Shiny package widgets are used to collect user provided inputs (visit
the \href{https://shiny.rstudio.com/gallery/widget-gallery.html}{Shiny
Widget Gallery} to get a sense of the different kinds of input
dialogues). In the subsequent development we'll use slider bars,
dropdown menus, and check boxes. All widget functions, at minimum,
include an \texttt{inputId} and \texttt{label} argument. The character
string assigned to the \texttt{inputId} argument will be the variable
name used to access the value(s) selected or provided by the user. This
variable name is used in the application development and not seen by the
user. The character string assigned to the \texttt{label} argument
appears in the UI above the given input widget and serves to provide a
user-friendly description of the desired input.

Building on the ``version 1'' code, we add a dropdown menu to the
script's UI portion using the \texttt{selectInput} function to the
``version 2'' code below. Update \texttt{app.R} and rerun the
application. What is our \texttt{inputId} for the dropdown menu? What is
our \texttt{label}? Can you see where the \texttt{label} is displayed in
the app when you rerun it?

Look at the structure of the \texttt{choices} argument in
\texttt{selectInput}. It's a vector of options in the form
\texttt{"name"\ =\ "value"} where the \texttt{name} is what the user
sees, and the \texttt{value} is what is returned to the server logic
function of the \texttt{app.R} file.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# app.R version 2}

\KeywordTok{library}\NormalTok{(shiny)}

\NormalTok{names.df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"http://blue.for.msu.edu/FOR875/data/name_list.csv"}\NormalTok{)}

\CommentTok{# Define UI}
\NormalTok{ui <-}\StringTok{ }\KeywordTok{fluidPage}\NormalTok{(}
  \KeywordTok{titlePanel}\NormalTok{(}\StringTok{"Random Names Age Analysis"}\NormalTok{),}
  \KeywordTok{sidebarLayout}\NormalTok{(}
    \KeywordTok{sidebarPanel}\NormalTok{(}
      \CommentTok{# Dropdown selection for Male/Female}
      \KeywordTok{selectInput}\NormalTok{(}\DataTypeTok{inputId =} \StringTok{"sexInput"}\NormalTok{, }\DataTypeTok{label =} \StringTok{"Sex:"}\NormalTok{,}
                  \DataTypeTok{choices =} \KeywordTok{c}\NormalTok{(}\StringTok{"Female"}\NormalTok{ =}\StringTok{ "F"}\NormalTok{, }
                              \StringTok{"Male"}\NormalTok{ =}\StringTok{ "M"}\NormalTok{, }
                              \StringTok{"Both"}\NormalTok{ =}\StringTok{ "B"}\NormalTok{))}
\NormalTok{    ),}
    \KeywordTok{mainPanel}\NormalTok{(}\StringTok{"our output will appear here"}\NormalTok{)}
\NormalTok{  )}
\NormalTok{)}

\CommentTok{# Define server logic}
\NormalTok{server <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(input, output) \{\}}

\CommentTok{# Create Shiny app}
\KeywordTok{shinyApp}\NormalTok{(}\DataTypeTok{ui =}\NormalTok{ ui, }\DataTypeTok{server =}\NormalTok{ server)}
\end{Highlighting}
\end{Shaded}

\section{Adding Output}\label{adding-output}

Now that we've included the user input dialog, let's make the
application truly interactive by changing the output depending on user
input. This is accomplished by modifying the server logic portion of the
script. Our goal is to plot an age distribution histogram in the main
panel given the sex selected by the user.

\subsection{Interactive Server Logic}\label{interactive-server-logic}

Server logic is defined by two arguments: \texttt{input} and
\texttt{output}. These objects are both list-like, so they can contain
multiple other objects. We already know from the user input part of the
\texttt{app.R} script that we have an input component called
\texttt{sexInput}, which can be accessed in the reactive portion of the
server logic by calling \texttt{input\$sexInput} (notice the use of the
\texttt{\$} to access the input value associated with
\texttt{sexInput}). In ``version 3'' of the application, we use the
information held in \texttt{input\$sexInput} to subset \texttt{names.df}
then create a histogram of \texttt{names.df\$Age}. This histogram
graphic is included as an element in the \texttt{output} object and
ultimately made available in the UI portion of the script by referencing
its name \texttt{histogram}.

Reactive portions of our \texttt{app.R} script's server logic are inside
the server function. We create reactive outputs using Shiny's functions
like \texttt{renderPlot}.\footnote{Every reactive output function's name
  in Shiny is of the form \texttt{render*}.} Obviously,
\texttt{renderPlot} renders the contents of the function into a plot
object; this is then stored in the \texttt{output} list wherever we
assign it (in this case, \texttt{output\$histogram}). Notice the
contents of the \texttt{renderPlot} function are contained not only by
regular parentheses, but also by curly brackets (just one more piece of
syntax to keep track of).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# app.R version 3}

\KeywordTok{library}\NormalTok{(shiny)}

\NormalTok{names.df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"http://blue.for.msu.edu/FOR875/data/name_list.csv"}\NormalTok{)}

\CommentTok{# Define UI}
\NormalTok{ui <-}\StringTok{ }\KeywordTok{fluidPage}\NormalTok{(}
  \KeywordTok{titlePanel}\NormalTok{(}\StringTok{"Random Names Age Analysis"}\NormalTok{),}
  \KeywordTok{sidebarLayout}\NormalTok{(}
    \KeywordTok{sidebarPanel}\NormalTok{(}
      \CommentTok{# Dropdown selection for Male/Female}
      \KeywordTok{selectInput}\NormalTok{(}\DataTypeTok{inputId =} \StringTok{"sexInput"}\NormalTok{, }\DataTypeTok{label =} \StringTok{"Sex:"}\NormalTok{,}
                  \DataTypeTok{choices =} \KeywordTok{c}\NormalTok{(}\StringTok{"Female"}\NormalTok{ =}\StringTok{ "F"}\NormalTok{, }
                              \StringTok{"Male"}\NormalTok{ =}\StringTok{ "M"}\NormalTok{, }
                              \StringTok{"Both"}\NormalTok{ =}\StringTok{ "B"}\NormalTok{))}
\NormalTok{    ),}
    \KeywordTok{mainPanel}\NormalTok{(}\StringTok{"our output will appear here"}\NormalTok{)}
\NormalTok{  )}
\NormalTok{)}

\CommentTok{# Define server logic}
\NormalTok{server <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(input, output) \{}

\NormalTok{  output}\OperatorTok{$}\NormalTok{histogram <-}\StringTok{ }\KeywordTok{renderPlot}\NormalTok{(\{}
    
    \ControlFlowTok{if}\NormalTok{(input}\OperatorTok{$}\NormalTok{sexInput }\OperatorTok{!=}\StringTok{ "B"}\NormalTok{)\{}
\NormalTok{      subset.names.df <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(names.df, Sex }\OperatorTok{==}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{sexInput)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      subset.names.df <-}\StringTok{ }\NormalTok{names.df}
\NormalTok{    \}}
    
\NormalTok{    ages <-}\StringTok{ }\NormalTok{subset.names.df}\OperatorTok{$}\NormalTok{Age}
    
    \CommentTok{# draw the histogram with the specified 20 bins}
    \KeywordTok{hist}\NormalTok{(ages, }\DataTypeTok{col =} \StringTok{'darkgray'}\NormalTok{, }\DataTypeTok{border =} \StringTok{'white'}\NormalTok{)}
\NormalTok{  \})}

\NormalTok{\}}

\CommentTok{# Create Shiny app}
\KeywordTok{shinyApp}\NormalTok{(}\DataTypeTok{ui =}\NormalTok{ ui, }\DataTypeTok{server =}\NormalTok{ server)}
\end{Highlighting}
\end{Shaded}

Update your \texttt{app.R} server logic function to match the code
above. Rerun the application. Note the appearance of the app doesn't
change because we have not updated the UI portion with the resulting
histogram.

\subsection{Interactive User
Interface}\label{interactive-user-interface}

Now we update the UI part of \texttt{app.R} to make the app interactive.
In the ``version 4'' code below, the \texttt{plotOutput("histogram")}
function in \texttt{ui} accesses the \texttt{histogram} component of the
\texttt{output} list and plots it in the main panel. Copy the code below
and rerun the application. You have now created your first Shiny app!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# app.R version 4}

\KeywordTok{library}\NormalTok{(shiny)}

\NormalTok{names.df <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"http://blue.for.msu.edu/FOR875/data/name_list.csv"}\NormalTok{)}

\CommentTok{# Define UI}
\NormalTok{ui <-}\StringTok{ }\KeywordTok{fluidPage}\NormalTok{(}
  \KeywordTok{titlePanel}\NormalTok{(}\StringTok{"Random Names Age Analysis"}\NormalTok{),}
  \KeywordTok{sidebarLayout}\NormalTok{(}
    \KeywordTok{sidebarPanel}\NormalTok{(}
      \CommentTok{# Dropdown selection for Male/Female}
      \KeywordTok{selectInput}\NormalTok{(}\DataTypeTok{inputId =} \StringTok{"sexInput"}\NormalTok{, }\DataTypeTok{label =} \StringTok{"Sex:"}\NormalTok{,}
                  \DataTypeTok{choices =} \KeywordTok{c}\NormalTok{(}\StringTok{"Female"}\NormalTok{ =}\StringTok{ "F"}\NormalTok{, }
                              \StringTok{"Male"}\NormalTok{ =}\StringTok{ "M"}\NormalTok{, }
                              \StringTok{"Both"}\NormalTok{ =}\StringTok{ "B"}\NormalTok{))}
\NormalTok{    ),}
    \KeywordTok{mainPanel}\NormalTok{(}\KeywordTok{plotOutput}\NormalTok{(}\StringTok{"histogram"}\NormalTok{))}
\NormalTok{  )}
\NormalTok{)}

\CommentTok{# Define server logic}
\NormalTok{server <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(input, output) \{}

\NormalTok{  output}\OperatorTok{$}\NormalTok{histogram <-}\StringTok{ }\KeywordTok{renderPlot}\NormalTok{(\{}

    \ControlFlowTok{if}\NormalTok{(input}\OperatorTok{$}\NormalTok{sexInput }\OperatorTok{!=}\StringTok{ "B"}\NormalTok{)\{}
\NormalTok{      subset.names.df <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(names.df, Sex }\OperatorTok{==}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{sexInput)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      subset.names.df <-}\StringTok{ }\NormalTok{names.df}
\NormalTok{    \}}
    
\NormalTok{    ages <-}\StringTok{ }\NormalTok{subset.names.df}\OperatorTok{$}\NormalTok{Age}
    
    \CommentTok{# draw the histogram with the specified 20 bins}
    \KeywordTok{hist}\NormalTok{(ages, }\DataTypeTok{col =} \StringTok{'darkgray'}\NormalTok{, }\DataTypeTok{border =} \StringTok{'white'}\NormalTok{)}
\NormalTok{  \})}

\NormalTok{\}}

\CommentTok{# Create Shiny app}
\KeywordTok{shinyApp}\NormalTok{(}\DataTypeTok{ui =}\NormalTok{ ui, }\DataTypeTok{server =}\NormalTok{ server)}
\end{Highlighting}
\end{Shaded}

\section{More Advanced Shiny App: Michigan
Campgrounds}\label{more-advanced-shiny-app-michigan-campgrounds}

The Michigan Department of Natural Resources (DNR) has made substantial
investments in open-sourcing its data via the
\href{http://gis-midnr.opendata.arcgis.com/datasets/}{Michigan DNR's
open data} initiative. We'll use some of these data to motivate our next
Shiny application. Specifically we'll work with the DNR State Park
Campgrounds data available
\href{http://blue.for.msu.edu/FOR875/data/Michigan_State_Park_Campgrounds.csv}{here}
as a CSV file.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/Michigan_State_Park_Campgrounds.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{sites <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u, }\DataTypeTok{stringsAsFactors =}\NormalTok{ F)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(sites)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   151 obs. of  19 variables:
 $ X          : num  -84.4 -84.4 -83.8 -83.8 -83.8 ...
 $ Y          : num  42.9 42.9 42.5 42.5 42.5 ...
 $ OBJECTID   : int  10330 10331 5986 5987 5988 5989 5990 5991 5992 5993 ...
 $ Type       : chr  "Campground" "Campground" "Campground" "Campground" ...
 $ Detail_Type: chr  "State Park" "State Park" "State Park" "State Park" ...
 $ DISTRICT   : chr  "Rose Lake" "Rose Lake" "Rose Lake" "Rose Lake" ...
 $ COUNTY     : chr  "Clinton" "Clinton" "Livingston" "Livingston" ...
 $ FACILITY   : chr  "Sleepy Hollow State Park" "Sleepy Hollow State Park" "Brighton Recreation Area" "Brighton Recreation Area" ...
 $ Camp_type  : chr  "Modern" "Organizational" "Modern" "Organizational" ...
 $ TOTAL_SITE : int  203 1 144 10 25 25 219 75 2 297 ...
 $ ADA_SITES  : int  0 0 0 0 0 0 0 3 0 13 ...
 $ name       : chr  "Sleepy Hollow State Park  " "Sleepy Hollow State Park  " "Brighton Recreation Area Bishop Lake" "Brighton Recreation Area  " ...
 $ Ownership  : chr  "State" "State" "State" "State" ...
 $ Management : chr  "DNR" "DNR" "DNR" "DNR" ...
 $ Surface    : chr  "Dirt" "Dirt" "Dirt" "Dirt" ...
 $ Use_       : chr  "Recreation" "Recreation" "Recreation" "Recreation" ...
 $ Condition  : chr  "Unknown" "Unknown" "Unknown" "Unknown" ...
 $ Lat        : num  42.9 42.9 42.5 42.5 42.5 ...
 $ Long       : num  -84.4 -84.4 -83.8 -83.8 -83.8 ...
\end{verbatim}

We see that Michigan has 151 state park campgrounds, and our data frame
contains 19 variables. Let's create a Shiny app UI in which the user
selects desired campground specifications, and the app displays the list
of resulting campgrounds and their location on a map. The complete Shiny
\texttt{app.R} is provided in the ``CampsitesMI'' directory in
``shiny\_chapter\_code.zip.'' Start out by running the application to
see how it works. Examine the example code and how it relates to the
application that you are running. The following sections detail each of
the app's components.

\subsection{Michigan Campgrounds UI}\label{michigan-campgrounds-ui}

First, let's look at the structure of the page. Similar to our first
application, we again use a \texttt{fluidPage} layout with title panel
and sidebar. The sidebar contains a sidebar panel and a main panel. Our
sidebar panel has three user input widgets:

\begin{itemize}
\tightlist
\item
  \texttt{sliderInput}: Allows user to specify a range of campsites
  desired in their campground. Since the maximum number of campsites in
  any Michigan state park campground is 411, 420 was chosen as the
  maximum.
\item
  \texttt{selectInput}: Allows user to select what type of campsites
  they want. To get the entire list of camp types, we used the data
  frame, \texttt{sites}, loaded at the beginning of the script.
\item
  \texttt{checkboxInput}: Allows the user to see only campgrounds with
  ADA sites available.
\end{itemize}

\begin{table}[t]

\caption{\label{tab:els}Interactive elements}
\centering
\begin{tabular}{lll}
\toprule
Element ID & Description & Function to Create\\
\midrule
input\$rangeNum & desired range of campsite quantity & sliderInput\\
input\$type & desired campsite type & selectInput\\
input\$ada & desired ADA site availability & checkboxInput\\
output\$plot1 & map with campground markers & renderPlot\\
output\$text1 & HTML-formatted list of campgrounds & renderText\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:els} provides a list of the various input and output
elements. Take your time and track how the app defines then uses each
input and output.

\subsection{Michigan Campgrounds Server
Logic}\label{michigan-campgrounds-server-logic}

In creating our \texttt{server} variable, we have two functions that
fill in our output elements:

\begin{itemize}
\tightlist
\item
  \texttt{renderText}: Creates a character string of HTML code to print
  the bulleted list of available sites.
\item
  \texttt{renderPlot}: Creates a \texttt{ggplot2} map of Michigan with
  campground markers.
\end{itemize}

Note that both of these functions contain identical subsetting of the
\texttt{sites} data frame into the smaller \texttt{sites1} data frame
(see below). As you can see from the code, we use the three inputs from
the application to subset the data: \texttt{rangeNum} from the slider
widget, \texttt{type} from the dropdown menu, and \texttt{ada} from the
checkbox.

This repeated code can be avoided using Shiny's reactive expressions.
These expressions will update in value whenever the widget input values
change. See
\href{https://shiny.rstudio.com/tutorial/written-tutorial/lesson6/}{here}
for more information. The use of reactive expressions is beyond the
scope of this chapter, but it is an important concept to be familiar
with if you plan to regularly create Shiny applications.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sites1 <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(sites, }
\NormalTok{                  TOTAL_SITE }\OperatorTok{>=}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{rangeNum[}\DecValTok{1}\NormalTok{] }\OperatorTok{&}\StringTok{  }
\StringTok{                  }\NormalTok{TOTAL_SITE }\OperatorTok{<=}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{rangeNum[}\DecValTok{2}\NormalTok{] }\OperatorTok{&}\StringTok{  }
\StringTok{                  }\NormalTok{Camp_type }\OperatorTok{==}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{type }\OperatorTok{&}\StringTok{   }
\StringTok{                  }\ControlFlowTok{if}\NormalTok{(input}\OperatorTok{$}\NormalTok{ada)\{ ADA_SITES }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{ \} }\ControlFlowTok{else}\NormalTok{ \{ADA_SITES }\OperatorTok{>=}\StringTok{ }\DecValTok{0}\NormalTok{\}}
\NormalTok{                )}
\end{Highlighting}
\end{Shaded}

\section{Adding Leaflet to Shiny}\label{adding-leaflet-to-shiny}

\href{https://rstudio.github.io/leaflet}{Leaflet} can be easily
incorporated in Shiny apps (See Chapter \ref{sp} of this text to learn
more about spatial data). In the Michigan Campgrounds example code, we
used \texttt{plotOutput} and \texttt{renderPlot} to put a plot widget in
our Shiny app. Similarly, in this code, we will use
\texttt{leafletOutput} and \texttt{renderLeaflet} to add Leaflet widgets
to our app. Run the Shiny app in the \texttt{CampsitesMI\_Leaflet}
directory. What are the differences between the plot widget in this app
and the plot widget in the previous app (using \texttt{ggplot2})?

Our code inside \texttt{renderLeaflet} is displayed below. As a reminder
from our previous use of Leaflet, we can use the \texttt{magrittr}
package's pipe operator, \texttt{\%\textgreater{}\%}, to add properties
to our Leaflet plot. In the \texttt{addCircleMarkers} function, you can
see that we used the \texttt{mapply} function to apply HTML code to each
of the markers. The HTML code simply prints the site name and number of
sites within each marker label. The \texttt{else} statement serves the
purpsose that if our subset, \texttt{sites1}, is empty, we render a map
centered on Lansing, MI.

\}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# renderLeaflet function from app.R}

\NormalTok{output}\OperatorTok{$}\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{renderLeaflet}\NormalTok{(\{}
    \CommentTok{# create a subset of campsites based on inputs}
\NormalTok{    sites1 <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(sites, }
\NormalTok{                    TOTAL_SITE }\OperatorTok{>=}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{rangeNum[}\DecValTok{1}\NormalTok{] }\OperatorTok{&}\StringTok{ }
\StringTok{                      }\NormalTok{TOTAL_SITE }\OperatorTok{<=}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{rangeNum[}\DecValTok{2}\NormalTok{] }\OperatorTok{&}\StringTok{ }
\StringTok{                      }\NormalTok{Camp_type }\OperatorTok{==}\StringTok{ }\NormalTok{input}\OperatorTok{$}\NormalTok{type }\OperatorTok{&}\StringTok{ }
\StringTok{                      }\ControlFlowTok{if}\NormalTok{(input}\OperatorTok{$}\NormalTok{ada)\{ ADA_SITES }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{ \} }\ControlFlowTok{else}\NormalTok{ \{ADA_SITES }\OperatorTok{>=}\StringTok{ }\DecValTok{0}\NormalTok{\})}
    
    \ControlFlowTok{if}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(sites1) }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{)\{}
      \KeywordTok{leaflet}\NormalTok{(sites1) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{addTiles}\NormalTok{()  }\OperatorTok{%>%}\StringTok{ }
\StringTok{        }\KeywordTok{addCircleMarkers}\NormalTok{(}\DataTypeTok{lng =} \OperatorTok{~}\NormalTok{Long, }\DataTypeTok{lat =} \OperatorTok{~}\NormalTok{Lat, }
                         \DataTypeTok{radius =} \DecValTok{5}\NormalTok{,}
                         \DataTypeTok{color =} \StringTok{"red"}\NormalTok{,}
                         \DataTypeTok{label =} \KeywordTok{mapply}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x,y) \{}
                           \KeywordTok{HTML}\NormalTok{(}\KeywordTok{sprintf}\NormalTok{(}\StringTok{'<em>%s</em><br>%s site(s)'}\NormalTok{, }
                                        \KeywordTok{htmlEscape}\NormalTok{(x), }
                                        \KeywordTok{htmlEscape}\NormalTok{(y)))\}, }
\NormalTok{                           sites1}\OperatorTok{$}\NormalTok{FACILITY, sites1}\OperatorTok{$}\NormalTok{TOTAL_SITE}
\NormalTok{                           )}
\NormalTok{                         )}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
        \KeywordTok{leaflet}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\KeywordTok{addTiles}\NormalTok{() }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{setView}\NormalTok{( }\OperatorTok{-}\FloatTok{84.5555}\NormalTok{, }\FloatTok{42.7325}\NormalTok{,   }\DataTypeTok{zoom =} \DecValTok{7}\NormalTok{)}
\NormalTok{    \}}
    
\NormalTok{  \})}
\end{Highlighting}
\end{Shaded}

\section{Why use Shiny?}\label{why-use-shiny}

In this chapter, we learned what a Shiny app is, what it's components
are, how to run the app, and how to incorporate Leaflet plots. We can
also host these apps online on our own server or the
\href{https://www.shinyapps.io/}{shinyapps.io} server, which can be
accessed directly from RStudio. Hosting our apps on a server allows
anyone with internet access to interact with our widgets.

The shinyapps.io server allows free hosting of apps within the monthly
limits of 5 applications and 25 active hours. Paid plans are also
available. A user guide to deploying your application on shinyapps.io is
available \href{http://docs.rstudio.com/shinyapps.io/index.html}{here}.
Set up a free account and impress your friends by sending them links to
your Shiny apps! In addition to hosting your applications, here are a
few more things to discover with Shiny:

\begin{itemize}
\tightlist
\item
  \href{https://shiny.rstudio.com/tutorial/\%7D}{Dive deeper} into
  development by working through the RStudio Shiny tutorial series.
\item
  \href{https://shiny.rstudio.com/articles/css.html}{Incorporate} CSS
  stylesheets to make your apps fancier.
\item
  \href{https://shiny.rstudio.com/articles/single-file.html}{Explore}
  the single-file Shiny app structure.
\end{itemize}

\section{Exercises}\label{exercises-6}

\textbf{Exercise Shiny} Learning objectives: practice updating
\texttt{ggplot2} plot aesthetics; modify Shiny HTML output; add an
interactive Shiny element.

\chapter{Classification}\label{classification}

Classification problems are quite common. For example a spam filter is
asked to classify incoming messages into spam or non-spam, based on
factors such as the sender's address, the subject of the message, the
contents of the message, and so on. As another example, a doctor
diagnosing a patient into one of four possible diagnoses based on
symptoms, blood tests, and medical history is another form of
classification. Or a bank may want to determine (prior to giving a loan)
whether an applicant for a loan will default on the loan, again based on
several variables such as income, financial history, etc.

Classification methods are both extremely useful and an active area of
research in statistics. In this chapter we will learn about two common,
and somewhat different, classification methods, logistic regression and
\(k\) nearest neighbors. A very good introduction to classification and
many other ``Statistical Learning'' methods is \citet{JamesEtAl}. The
abbreviated treatment in this chapter draws from \citet{JamesEtAl}.

\section{Logistic Regression}\label{logistic-regression}

Logistic regression is widely used to relate a categorical response
variable to one or more (continuous or categorical) predictors.
Initially we will consider the simplest case where the response \(Y\)
has only two possible values (we'll assume the values are \(0\) and
\(1\)) and where there is only one continuous predictor \(X\). We would
like to predict the value of \(Y\) based on the value of the predictor
\(X\). Let \(p(X) = P(Y = 1 | X)\).\footnote{For those not familiar with
  probability notation, the right side of this equation reads as ``The
  probability that Y = 1 given we know the value of X'')}. We will model
\(p(X)\) with the \emph{logistic function}, which takes values between
\(0\) and \(1\), which is of course appropriate for modeling a
probability:

\[
p(X) = \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}}.
\]

A graph of this function when \(\beta_0=0\) and \(\beta_1 = 1\) shows
the characteristic shape.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(ggplot2)}
\OperatorTok{>}\StringTok{ }\NormalTok{logistic <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{exp}\NormalTok{(x)}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(x))\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{)), }\KeywordTok{aes}\NormalTok{(x)) }\OperatorTok{+}
\OperatorTok{+}\StringTok{   }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ logistic)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-234-1.pdf}

To make this more concrete, we will consider a data set on a population
of women who were over 21 years of age, lived near Phoenix, Arizona, and
were of Pima Indian heritage. The data included diabetes status (yes or
no) and seven possible predictor variables such as age, number of
pregnancies, body mass index, etc. The original data are from the
National Institute of Diabetes and Digestive and Kidney Diseases. These
data were cleaned and are available in the \texttt{MASS} package in R.
In the package the data frame \texttt{Pima.tr} contains 200 randomly
selected cases from the full data set, which we will use to find a
classifier. The data frame \texttt{Pima.te} contains the remaining 332
cases, which we will use to test the classifier on new data.\footnote{This
  practice of randomly separating data into training data and testing
  data is a common practice for many classification methods.}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(MASS)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(Pima.tr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  npreg glu bp skin  bmi   ped age type
1     5  86 68   28 30.2 0.364  24   No
2     7 195 70   33 25.1 0.163  55  Yes
3     5  77 82   41 35.8 0.156  35   No
4     0 165 76   43 47.9 0.259  26   No
5     0 107 60   25 26.4 0.133  23   No
6     5  97 76   27 35.6 0.378  52  Yes
\end{verbatim}

It will be more convenient to code the presence or absence of diabetes
by 1 and 0, so we first create another column in the data frame with
this coding:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{Pima.tr}\OperatorTok{$}\NormalTok{diabetes <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{dim}\NormalTok{(Pima.tr)[}\DecValTok{1}\NormalTok{])}
\OperatorTok{>}\StringTok{ }\NormalTok{Pima.tr}\OperatorTok{$}\NormalTok{diabetes[Pima.tr}\OperatorTok{$}\NormalTok{type }\OperatorTok{==}\StringTok{ "Yes"}\NormalTok{] <-}\StringTok{ }\DecValTok{1}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(Pima.tr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  npreg glu bp skin  bmi   ped age type diabetes
1     5  86 68   28 30.2 0.364  24   No        0
2     7 195 70   33 25.1 0.163  55  Yes        1
3     5  77 82   41 35.8 0.156  35   No        0
4     0 165 76   43 47.9 0.259  26   No        0
5     0 107 60   25 26.4 0.133  23   No        0
6     5  97 76   27 35.6 0.378  52  Yes        1
\end{verbatim}

We will begin with \texttt{glu} as a predictor, and of course
\texttt{type} as the response. So we want to find the values \(\beta_0\)
and \(\beta_1\) which provide the best fit for the model

\[
P(\text{yes} | \text{glu}) = \frac{e^{\beta_0 + \beta_1 (\text{glu})}}{1 + e^{\beta_0 + \beta_1 (\text{glu})}}
\]

Usually maximum likelihood methods are used to fit the model.

In R we will use the function \texttt{glm} to fit logistic regression
models. The \texttt{glm} function fits a wide variety of models. To
specify the logistic regression model we specify
\texttt{family\ =\ binomial} as an argument to \texttt{glm}. We also
must specify the predictor and response variables via the model formula,
which in our case will be \texttt{diabetes\ \textasciitilde{}\ glu} to
indicate that \texttt{diabetes} (i.e., \texttt{type} recoded) is the
response and \texttt{glu} is the predictor; also we specify the data
frame, which in our case is \texttt{Pima.tr}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.lr1 <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(diabetes }\OperatorTok{~}\StringTok{ }\NormalTok{glu, }\DataTypeTok{data =}\NormalTok{ Pima.tr, }\DataTypeTok{family =}\NormalTok{ binomial)}
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.lr1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:  glm(formula = diabetes ~ glu, family = binomial, data = Pima.tr)

Coefficients:
(Intercept)          glu  
    -5.5036       0.0378  

Degrees of Freedom: 199 Total (i.e. Null);  198 Residual
Null Deviance:      256 
Residual Deviance: 207  AIC: 211
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{summary}\NormalTok{(diabetes.lr1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = diabetes ~ glu, family = binomial, data = Pima.tr)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.971  -0.779  -0.529   0.849   2.263  

Coefficients:
            Estimate Std. Error z value       Pr(>|z|)
(Intercept) -5.50364    0.83608   -6.58 0.000000000046
glu          0.03778    0.00628    6.02 0.000000001756
               
(Intercept) ***
glu         ***
---
Signif. codes:  
0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 256.41  on 199  degrees of freedom
Residual deviance: 207.37  on 198  degrees of freedom
AIC: 211.4

Number of Fisher Scoring iterations: 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{beta0.lr.}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{coef}\NormalTok{(diabetes.lr1)[}\DecValTok{1}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{beta1.lr.}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{coef}\NormalTok{(diabetes.lr1)[}\DecValTok{2}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{beta0.lr.}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(Intercept) 
     -5.504 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{beta1.lr.}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    glu 
0.03778 
\end{verbatim}

The coefficients \(\beta_0\) and \(\beta_1\) are approximately -5.504
and 0.038, respectively. So for example we can estimate the probability
that a woman in this population whose glucose level is 150 would be
diabetic as

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\FloatTok{5.504} \OperatorTok{+}\StringTok{ }\FloatTok{0.038}\OperatorTok{*}\DecValTok{150}\NormalTok{)}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\FloatTok{5.504} \OperatorTok{+}\StringTok{ }\FloatTok{0.038}\OperatorTok{*}\DecValTok{150}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5488
\end{verbatim}

We can plot the fitted probabilities along with the data ``by hand''.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.logistic.}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
\OperatorTok{+}\StringTok{   }\KeywordTok{exp}\NormalTok{(beta0.lr.}\DecValTok{1}\OperatorTok{+}\StringTok{ }\NormalTok{beta1.lr.}\DecValTok{1}\OperatorTok{*}\NormalTok{x)}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(beta0.lr.}\DecValTok{1}\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{                                            }\NormalTok{beta1.lr.}\DecValTok{1}\OperatorTok{*}\NormalTok{x))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(Pima.tr, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ glu, }\DataTypeTok{y =}\NormalTok{ diabetes)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ diabetes.logistic.}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-239-1.pdf}

The \texttt{ggplot2} package also provides a way to do this more
directly, using \texttt{stat\_smooth}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(Pima.tr, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ glu, }\DataTypeTok{y =}\NormalTok{ diabetes)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{stat_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"glm"}\NormalTok{, }
\OperatorTok{+}\StringTok{               }\DataTypeTok{method.args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{family =} \StringTok{"binomial"}\NormalTok{), }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-240-1.pdf}

From these graphics we can see that although glucose level and diabetes
are related, there are many women with high glucose levels who are not
diabetic, and many with low glucose levels who are diabetic, so likely
adding other predictors to the model will help.

Next let's see how the model does in predicting diabetes status in the
data we did not use for fitting the model. We will predict diabetes for
anyone whose glucose level leads to a model-based probability greater
than \(1/2\). First we use the \texttt{predict} function to compute the
probabilities, and then use these to make predictions.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(Pima.te)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  npreg glu bp skin  bmi   ped age type
1     6 148 72   35 33.6 0.627  50  Yes
2     1  85 66   29 26.6 0.351  31   No
3     1  89 66   23 28.1 0.167  21   No
4     3  78 50   32 31.0 0.248  26  Yes
5     2 197 70   45 30.5 0.158  53  Yes
6     5 166 72   19 25.8 0.587  51  Yes
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.probs.}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(diabetes.lr1, Pima.te, }\DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(diabetes.probs.}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      1       2       3       4       5       6 
0.52207 0.09179 0.10519 0.07199 0.87433 0.68319 
\end{verbatim}

The \texttt{predict} function (with \texttt{type\ =\ "response"}
specified) provides \(p(x) = P(Y = 1 | X = x)\) for all the \(x\) values
in a data frame. In this case we specified the data frame
\texttt{Pima.te} since we want to know how the model does in predicting
diabetes in a new population, i.e., in a population that wasn't used to
``train'' the model.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.predict.}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\StringTok{"No"}\NormalTok{, }\KeywordTok{dim}\NormalTok{(Pima.te)[}\DecValTok{1}\NormalTok{])}
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.predict.}\DecValTok{1}\NormalTok{[diabetes.probs.}\DecValTok{1} \OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{] <-}\StringTok{ "Yes"}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(diabetes.predict.}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Yes" "No"  "No"  "No"  "Yes" "Yes"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(diabetes.predict.}\DecValTok{1}\NormalTok{, Pima.te}\OperatorTok{$}\NormalTok{type)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                  
diabetes.predict.1  No Yes
               No  206  58
               Yes  17  51
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(diabetes.predict.}\DecValTok{1}\NormalTok{[diabetes.predict.}\DecValTok{1} \OperatorTok{==}\StringTok{ }\NormalTok{Pima.te}\OperatorTok{$}\NormalTok{type])}\OperatorTok{/}
\OperatorTok{+}\StringTok{   }\KeywordTok{dim}\NormalTok{(Pima.te)[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7741
\end{verbatim}

The table (sometimes called a \emph{confusion matrix}) has the
predictions of the model in the rows, so for example we see that the
model predicts that \(206 + 58 = 264\) of the women will not be
diabetic, and that \(17+51 = 68\) of the women will be diabetic. More
interesting of course are the cells themselves. For example, of the
\(206 + 17 = 223\) women who are not diabetic in \texttt{Pima.te}, the
model correctly classifies 206, and misclassifies 17. A classifier that
predicted perfectly for the test data would have zeros off the diagonal.

\subsection{Adding Predictors}\label{adding-predictors}

If we have \(p\) predictors \(X = (X_1, \dots, X_p)\), the logistic
model becomes

\[
p(X) = p(X) = \frac{e^{\beta_0 + \beta_1 X + \dots + \beta_p X_p}}{1 + e^{\beta_0 + \beta_1 X + \dots + \beta_p X_p}}.
\]

Although there is a lot more notation to keep track of, the basic ideas
are the same as they were for the one predictor model. We will next see
how adding \texttt{bmi}, the body mass index, affects predictions of
diabetes.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.lr2 <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(diabetes }\OperatorTok{~}\StringTok{ }\NormalTok{glu }\OperatorTok{+}\StringTok{ }\NormalTok{bmi, }
\OperatorTok{+}\StringTok{                     }\DataTypeTok{data =}\NormalTok{ Pima.tr, }\DataTypeTok{family =}\NormalTok{ binomial)}
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.lr2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:  glm(formula = diabetes ~ glu + bmi, family = binomial, data = Pima.tr)

Coefficients:
(Intercept)          glu          bmi  
    -8.2161       0.0357       0.0900  

Degrees of Freedom: 199 Total (i.e. Null);  197 Residual
Null Deviance:      256 
Residual Deviance: 198  AIC: 204
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{summary}\NormalTok{(diabetes.lr2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = diabetes ~ glu + bmi, family = binomial, data = Pima.tr)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-2.058  -0.757  -0.431   0.801   2.249  

Coefficients:
            Estimate Std. Error z value     Pr(>|z|)
(Intercept) -8.21611    1.34697   -6.10 0.0000000011
glu          0.03572    0.00631    5.66 0.0000000152
bmi          0.09002    0.03127    2.88        0.004
               
(Intercept) ***
glu         ***
bmi         ** 
---
Signif. codes:  
0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 256.41  on 199  degrees of freedom
Residual deviance: 198.47  on 197  degrees of freedom
AIC: 204.5

Number of Fisher Scoring iterations: 4
\end{verbatim}

Now we look at predictions from this model.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.probs.}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(diabetes.lr2, Pima.te, }\DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(diabetes.probs.}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      1       2       3       4       5       6 
0.52359 0.05810 0.07530 0.06662 0.82713 0.50879 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.predict.}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\StringTok{"No"}\NormalTok{, }\KeywordTok{dim}\NormalTok{(Pima.te)[}\DecValTok{1}\NormalTok{])}
\OperatorTok{>}\StringTok{ }\NormalTok{diabetes.predict.}\DecValTok{2}\NormalTok{[diabetes.probs.}\DecValTok{2} \OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{] <-}\StringTok{ "Yes"}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(diabetes.predict.}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Yes" "No"  "No"  "No"  "Yes" "Yes"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(diabetes.predict.}\DecValTok{2}\NormalTok{, Pima.te}\OperatorTok{$}\NormalTok{type)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                  
diabetes.predict.2  No Yes
               No  204  54
               Yes  19  55
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(diabetes.predict.}\DecValTok{2}\NormalTok{[diabetes.predict.}\DecValTok{2} \OperatorTok{==}\StringTok{ }\NormalTok{Pima.te}\OperatorTok{$}\NormalTok{type])}\OperatorTok{/}
\OperatorTok{+}\StringTok{   }\KeywordTok{dim}\NormalTok{(Pima.te)[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7801
\end{verbatim}

Adding \texttt{bmi} as a predictor did not improve the predictions by
very much!

Let \(x_1\) and \(x_2\) represent glucose and bmi levels. We classify a
subject as ``diabetic'' if the fitted \(p(X)\) is greater than \(0.5\),
i.e., if the fitted probability of diabetes is greater than the fitted
probability of not diabetes. The boundary for our decision is where
these two fitted probabilities are equal, i.e., where

\[
\frac{P(Y = 1 | (x_1, x_2))}{P(Y = 0 | (x_1, x_2))} = \frac{P(Y = 1 | (x_1, x_2))}{1 - P(Y = 1 | (x_1, x_2))}  = 1.
\]

Writing these out in terms of the logistic regression model, taking
logarithms, and performing some algebra leads to the following (linear!)
decision boundary:

\[
x_2 = -\frac{\beta_0}{\beta_2} - \frac{\beta_1}{\beta_2} x_1.
\]

The diabetes training data along with the decision boundary are plotted
below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{lr.int <-}\StringTok{ }\OperatorTok{-}\KeywordTok{coef}\NormalTok{(diabetes.lr2)[}\DecValTok{1}\NormalTok{]}\OperatorTok{/}\KeywordTok{coef}\NormalTok{(diabetes.lr2)[}\DecValTok{3}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{lr.slope <-}\StringTok{ }\OperatorTok{-}\KeywordTok{coef}\NormalTok{(diabetes.lr2)[}\DecValTok{2}\NormalTok{]}\OperatorTok{/}\KeywordTok{coef}\NormalTok{(diabetes.lr2)[}\DecValTok{3}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(Pima.tr, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ glu, }\DataTypeTok{y =}\NormalTok{ bmi)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ type)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_abline}\NormalTok{(}\DataTypeTok{intercept =}\NormalTok{ lr.int, }\DataTypeTok{slope =}\NormalTok{ lr.slope)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-245-1.pdf}

\subsection{More than Two Classes}\label{more-than-two-classes}

Logistic regression methods also are applicable to classification
contexts where there are more than two classes. Consider for example
Fisher's iris data.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{data}\NormalTok{(iris)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1          5.1         3.5          1.4         0.2
2          4.9         3.0          1.4         0.2
3          4.7         3.2          1.3         0.2
4          4.6         3.1          1.5         0.2
5          5.0         3.6          1.4         0.2
6          5.4         3.9          1.7         0.4
  Species
1  setosa
2  setosa
3  setosa
4  setosa
5  setosa
6  setosa
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Sepal.Length, }\DataTypeTok{y =}\NormalTok{ Sepal.Width)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-246-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ iris, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Petal.Length, }\DataTypeTok{y =}\NormalTok{ Petal.Width)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Species))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-246-2.pdf}

Here the potential predictors are sepal width, sepal length, petal
width, and petal length. The goal is to find a classifier that will
yield the correct species. From the scatter plots it should be pretty
clear that a model with petal length and petal width as predictors would
classify the data well. Although in a sense this is too easy, these data
do a good job of illustrating logistic regression with more than two
classes.

Before doing that we randomly choose 75 of the 150 rows of the data
frame to be the training sample, with the other 75 being the test
sample.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{set.seed}\NormalTok{(}\DecValTok{321}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{selected <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{150}\NormalTok{, }\DataTypeTok{replace =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{size =} \DecValTok{75}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{iris.train <-}\StringTok{ }\NormalTok{iris[selected,]}
\OperatorTok{>}\StringTok{ }\NormalTok{iris.test <-}\StringTok{ }\NormalTok{iris[}\OperatorTok{-}\NormalTok{selected,]}
\end{Highlighting}
\end{Shaded}

There are several packages which implement logistic regression for data
with more than two classes. We will use the \texttt{VGAM} package. The
function \texttt{vglm} within \texttt{VGAM} implements logistic
regression (and much more).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(VGAM)}
\OperatorTok{>}\StringTok{ }\NormalTok{iris.lr <-}\StringTok{ }\KeywordTok{vglm}\NormalTok{(Species }\OperatorTok{~}\StringTok{ }\NormalTok{Petal.Width }\OperatorTok{+}\StringTok{ }\NormalTok{Petal.Length, }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{data =}\NormalTok{ iris.train, }\DataTypeTok{family =}\NormalTok{ multinomial)}
\OperatorTok{>}\StringTok{ }\KeywordTok{summary}\NormalTok{(iris.lr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
vglm(formula = Species ~ Petal.Width + Petal.Length, family = multinomial, 
    data = iris.train)

Pearson residuals:
                          Min            1Q
log(mu[,1]/mu[,3]) -0.0000397  0.0000000175
log(mu[,2]/mu[,3]) -1.5279112 -0.0020907887
                         Median           3Q       Max
log(mu[,1]/mu[,3]) 0.0000000257 0.0000000395 0.0000796
log(mu[,2]/mu[,3]) 0.0000000972 0.0101234167 1.6385058

Coefficients: 
               Estimate Std. Error z value Pr(>|z|)  
(Intercept):1    104.97    8735.20      NA       NA  
(Intercept):2     52.71      27.05      NA       NA  
Petal.Width:1    -41.55   21914.63      NA       NA  
Petal.Width:2     -9.18       4.49   -2.04    0.041 *
Petal.Length:1   -18.93    8993.53      NA       NA  
Petal.Length:2    -7.62       4.90   -1.55    0.120  
---
Signif. codes:  
0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Names of linear predictors: log(mu[,1]/mu[,3]), 
log(mu[,2]/mu[,3])

Residual deviance: 14.65 on 144 degrees of freedom

Log-likelihood: -7.324 on 144 degrees of freedom

Number of Fisher scoring iterations: 21 

Warning: Hauck-Donner effect detected in the following estimate(s):
'(Intercept):1', '(Intercept):2', 'Petal.Width:1', 'Petal.Length:1'


Reference group is level  3  of the response
\end{verbatim}

Notice that the family is specified as \texttt{multinomial} rather than
\texttt{binomial} since we have more than two classes. When run with
these data, the \texttt{vglm} function returns several (about 20)
warnings. These occur mainly because the classes are so easily
separated, and are suppressed above.

Next we compute the probabilities for the test data.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{iris.probs <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(iris.lr, iris.test[,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)], }\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(iris.probs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   setosa          versicolor
2       1 0.00000000000009874
5       1 0.00000000000009874
6       1 0.00000000190561922
7       1 0.00000000000251434
10      1 0.00000000000001202
11      1 0.00000000000030599
                               virginica
2  0.00000000000000000000000000000034016
5  0.00000000000000000000000000000034016
6  0.00000000000000000000000040468850399
7  0.00000000000000000000000000002168557
10 0.00000000000000000000000000000003543
11 0.00000000000000000000000000000225863
\end{verbatim}

At least for the first six cases, one probability is close to one and
the other two are close to zero, reflecting the fact that this is an
easy classification problem. Next we extract the actual predictions. For
these, we want to choose the highest probability in each row. The
\texttt{which.max} function makes this easy. Before applying this to the
fitted probabilities, we illustrate its use. Take notice that
\texttt{which.max()} returns the position of the highest probability,
and not the actualy highest probability itself.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{which.max}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{which.max}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{class.predictions <-}\StringTok{ }\KeywordTok{apply}\NormalTok{(iris.probs, }\DecValTok{1}\NormalTok{, which.max)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(class.predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 2  5  6  7 10 11 
 1  1  1  1  1  1 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{class.predictions[class.predictions }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{] <-}\StringTok{ }\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)[}\DecValTok{1}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{class.predictions[class.predictions }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{] <-}\StringTok{ }\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)[}\DecValTok{2}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\NormalTok{class.predictions[class.predictions }\OperatorTok{==}\StringTok{ }\DecValTok{3}\NormalTok{] <-}\StringTok{ }\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)[}\DecValTok{3}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(class.predictions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       2        5        6        7       10       11 
"setosa" "setosa" "setosa" "setosa" "setosa" "setosa" 
\end{verbatim}

Next we create the confusion matrix.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(class.predictions, iris.test}\OperatorTok{$}\NormalTok{Species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                 
class.predictions setosa versicolor virginica
       setosa         25          0         0
       versicolor      0         22         1
       virginica       0          0        27
\end{verbatim}

\section{Nearest Neighbor Methods}\label{nearest-neighbor-methods}

Nearest neighbor methods provide a rather different way to construct
classifiers, and have strengths (minimal assumptions, flexible decision
boundaries) and weaknesses (computational burden, lack of
interpretability) compared to logistic regression models.

In principle the idea is simple. Recall that the training set will have
both \(x\) and \(y\) values known, while the test set will have only
\(x\) values known. Begin by choosing a positive integer \(k\) which
will specify the number of neighbors to use in classification. To
classify a point \(x\) in the training set, find the \(k\) closest \(x\)
values in the training set, and choose the class which has the highest
representation among the \(k\) points. The algorithm is called kNN for
``k Nearest Neighbors''.

For example, suppose that \(k=10\) and the 10 nearest neighbors to a
training \(x\) have classes \(1, 1, 3, 2, 3, 3, 3, 2, 3, 2\). Since
there are five 3s, three 2s, and two 1s, the training point is assigned
to class 3. Suppose that for another \(x\) the 10 nearest neighbors have
classes \(1,1,1,2,3,1,3,3,3,2\). In this case there are four 1s and four
3s, so there is a tie for the lead. The nearest neighbor algorithm then
will choose between 1 and 3 at random.

Although in principle kNN is simple, some issues arise. First, how
should \(k\) be chosen? There is not an easy answer, but it can help to
think of the extreme values for \(k\).

The largest possible \(k\) is the number of observations in the training
set. For example suppose that the training set has \(10\) observations,
with classes \(1, 1, 1, 2, 2, 2, 3, 3, 3, 3\). Then for any point in the
test set, the \(k=10\) nearest neighbors will include ALL of the points
in the training set, and hence every point in the test set will be
classified in class 3. This classifier has low (zero) variance, but
probably has high bias.

The smallest possible \(k\) is 1. In this case, each point in the test
set is put in the same class as its nearest neighbor in the training
set. This may lead to a very non-smooth and high variance classifier,
but the bias will tend to be small.

A second issue that is relatively easy to deal with concerns the scales
on which the \(x\) values are measured. If for example one \(x\)
variable has a range from 2 to 4, while another has a range from 2000 to
4000, the distance between the test and training data will be dominated
by the second variable. The solution that is typically used is to
standardize all the variables (rescale them so that their mean is 0 and
their standard deviation is 1).

These and other issues are discussed in the literature on kNN, but we
won't pursue them further.

There are at least three R packages which implement kNN, including
\texttt{class}, \texttt{kknn}, and \texttt{RWeka}. We will use
\texttt{class} below.

An example from \citet{hastieESL} will be used to give a better sense of
the role of \(k\) in the kNN algorithm. The example uses simulated data
and shows the decision boundaries for kNN with \(k=15\) and
\(k=1\).\footnote{The graphs below use code adapted from
  \url{http://stackoverflow.com/questions/31234621/variation-on-how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-f}}.
Although the R code used to draw the displays is given below, focus
mainly on the graphics produced, and what they tell us about kNN.

First the data are read into R and graphed. The predictors \texttt{x1}
and \texttt{x2}, while not standardized, have very similar standard
deviations, so we will not standardize these data before applying kNN.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.knn <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/knnExample.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{knnExample <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.knn, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(knnExample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   200 obs. of  3 variables:
 $ x1   : num  2.5261 0.367 0.7682 0.6934 -0.0198 ...
 $ x2   : num  0.3211 0.0315 0.7175 0.7772 0.8673 ...
 $ class: int  0 0 0 0 0 0 0 0 0 0 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ knnExample, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =} \KeywordTok{as.factor}\NormalTok{(class))) }\OperatorTok{+}
\OperatorTok{+}\StringTok{    }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-252-1.pdf}

Next a large set of test data is created using the \texttt{expand.grid}
function, which creates a data frame with all possible combinations of
the arguments. First a simple example to illustrate the function, then
the actual creation of the training set. The test set covers the range
of the \texttt{x1} and \texttt{x2} values in the training set.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{expand.grid}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\FloatTok{3.4}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  x   y
1 1 5.0
2 2 5.0
3 1 3.4
4 2 3.4
5 1 2.0
6 2 2.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{min}\NormalTok{(knnExample}\OperatorTok{$}\NormalTok{x1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -2.521
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{max}\NormalTok{(knnExample}\OperatorTok{$}\NormalTok{x1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.171
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{min}\NormalTok{(knnExample}\OperatorTok{$}\NormalTok{x2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{max}\NormalTok{(knnExample}\OperatorTok{$}\NormalTok{x2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.856
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x.test <-}\StringTok{ }\KeywordTok{expand.grid}\NormalTok{(}\DataTypeTok{x1 =} \KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\FloatTok{2.6}\NormalTok{, }\FloatTok{4.2}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{), }\DataTypeTok{x2 =} \KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\DecValTok{2}\NormalTok{, }\FloatTok{2.9}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Next the kNN with \(k=15\) is fit. Notice that the first argument gives
the \(x\) values in the training set, the next argument gives the \(x\)
values in the test set, the third argument gives the \(y\) values
(labels) from the training set. The fourth argument gives \(k\), and the
fifth argument asks for the function to return the probabilities of
membership (that is, the proportion of the nearest neighbors which were
in the majority class) as well as the class assignments.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(class)}
\OperatorTok{>}\StringTok{ }\NormalTok{Example_knn <-}\StringTok{ }\KeywordTok{knn}\NormalTok{(knnExample[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)], x.test, knnExample[,}\DecValTok{3}\NormalTok{], }\DataTypeTok{k =} \DecValTok{15}\NormalTok{, }\DataTypeTok{prob =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{prob <-}\StringTok{ }\KeywordTok{attr}\NormalTok{(Example_knn, }\StringTok{"prob"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(prob)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6667 0.6667 0.6667 0.7333 0.7333 0.7333
\end{verbatim}

Next the graphs are created. This is somewhat complex, since we want to
plot the test data colored by the class they were assigned to by the kNN
classifier as background, the training data (using a different symbol),
and the decision boundary.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dplyr)}
\OperatorTok{>}\StringTok{ }\NormalTok{df1 <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(x.test, }\DataTypeTok{prob =}\NormalTok{ prob, }\DataTypeTok{class =} \DecValTok{0}\NormalTok{,  }\DataTypeTok{prob_cls =} \KeywordTok{ifelse}\NormalTok{(Example_knn }\OperatorTok{==}\StringTok{ }\NormalTok{class, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(df1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   3450 obs. of  5 variables:
 $ x1      : num  -2.6 -2.5 -2.4 -2.3 -2.2 -2.1 -2 -1.9 -1.8 -1.7 ...
 $ x2      : num  -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 ...
 $ prob    : num  0.667 0.667 0.667 0.733 0.733 ...
 $ class   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ prob_cls: num  1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{df2 <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(x.test, }\DataTypeTok{prob =}\NormalTok{ prob, }\DataTypeTok{class =} \DecValTok{1}\NormalTok{,  }\DataTypeTok{prob_cls =} \KeywordTok{ifelse}\NormalTok{(Example_knn }\OperatorTok{==}\StringTok{ }\NormalTok{class, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\NormalTok{bigdf <-}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{(df1, df2)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(knnExample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "x1"    "x2"    "class"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(bigdf) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x1, }\DataTypeTok{y =}\NormalTok{x2, }\DataTypeTok{col=}\NormalTok{class), }\DataTypeTok{data =} \KeywordTok{mutate}\NormalTok{(x.test, }\DataTypeTok{class =}\NormalTok{ Example_knn), }\DataTypeTok{size =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{    }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2, }\DataTypeTok{col =} \KeywordTok{as.factor}\NormalTok{(class)), }\DataTypeTok{size =} \DecValTok{4}\NormalTok{, }\DataTypeTok{shape =} \DecValTok{1}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ knnExample) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{    }\KeywordTok{geom_contour}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2, }\DataTypeTok{z =}\NormalTok{ prob_cls, }\DataTypeTok{group =} \KeywordTok{as.factor}\NormalTok{(class), }\DataTypeTok{color =} \KeywordTok{as.factor}\NormalTok{(class)), }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{bins =} \DecValTok{1}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ bigdf) }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-255-1.pdf}

Next we graph the decision boundary of kNN with \(k=1\).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{Example_knn <-}\StringTok{ }\KeywordTok{knn}\NormalTok{(knnExample[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)], x.test, knnExample[,}\DecValTok{3}\NormalTok{], }\DataTypeTok{k =} \DecValTok{1}\NormalTok{, }\DataTypeTok{prob =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{prob <-}\StringTok{ }\KeywordTok{attr}\NormalTok{(Example_knn, }\StringTok{"prob"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(prob)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 1 1 1 1 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{df1 <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(x.test, }\DataTypeTok{prob =}\NormalTok{ prob, }\DataTypeTok{class =} \DecValTok{0}\NormalTok{,  }\DataTypeTok{prob_cls =} \KeywordTok{ifelse}\NormalTok{(Example_knn }\OperatorTok{==}\StringTok{ }\NormalTok{class, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(df1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   3450 obs. of  5 variables:
 $ x1      : num  -2.6 -2.5 -2.4 -2.3 -2.2 -2.1 -2 -1.9 -1.8 -1.7 ...
 $ x2      : num  -2 -2 -2 -2 -2 -2 -2 -2 -2 -2 ...
 $ prob    : num  1 1 1 1 1 1 1 1 1 1 ...
 $ class   : num  0 0 0 0 0 0 0 0 0 0 ...
 $ prob_cls: num  1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{df2 <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(x.test, }\DataTypeTok{prob =}\NormalTok{ prob, }\DataTypeTok{class =} \DecValTok{1}\NormalTok{,  }\DataTypeTok{prob_cls =} \KeywordTok{ifelse}\NormalTok{(Example_knn }\OperatorTok{==}\StringTok{ }\NormalTok{class, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\NormalTok{bigdf <-}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{(df1, df2)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(bigdf) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2, }\DataTypeTok{col =}\NormalTok{ class), }\DataTypeTok{data =} \KeywordTok{mutate}\NormalTok{(x.test, }\DataTypeTok{class =}\NormalTok{ Example_knn), }\DataTypeTok{size =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2, }\DataTypeTok{col =} \KeywordTok{as.factor}\NormalTok{(class)), }\DataTypeTok{size =} \DecValTok{4}\NormalTok{, }\DataTypeTok{shape =} \DecValTok{1}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ knnExample) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_contour}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2, }\DataTypeTok{z =}\NormalTok{ prob_cls, }\DataTypeTok{group =} \KeywordTok{as.factor}\NormalTok{(class), }\DataTypeTok{color =} \KeywordTok{as.factor}\NormalTok{(class)), }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{bins =} \DecValTok{1}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ bigdf) }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-256-1.pdf}

\subsection{kNN and the Diabetes Data}\label{knn-and-the-diabetes-data}

Next kNN is applied to the diabetes data. We will use the same
predictors, \texttt{glu} and \texttt{bmi} that were used in the logistic
regression example. Since the scales of the predictor variables are
substantially different, they are standardized first. The value \(k=15\)
is chosen for kNN.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{Pima.tr[,}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{] <-}\StringTok{ }\KeywordTok{scale}\NormalTok{(Pima.tr[,}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{], }\DataTypeTok{center =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{Pima.te[,}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{] <-}\StringTok{ }\KeywordTok{scale}\NormalTok{(Pima.te[,}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{], }\DataTypeTok{center =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{knn_Pima <-}\StringTok{ }\KeywordTok{knn}\NormalTok{(Pima.tr[,}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{)], Pima.te[,}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{)], Pima.tr[,}\DecValTok{8}\NormalTok{], }\DataTypeTok{k =} \DecValTok{15}\NormalTok{, }\DataTypeTok{prob=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(knn_Pima, Pima.te[,}\DecValTok{8}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        
knn_Pima  No Yes
     No  206  55
     Yes  17  54
\end{verbatim}

At least in terms of the confusion matrix, kNN with \(k=15\) performed
about as well as logistic regression for these data.

\subsection{Practice Problem}\label{practice-problem-13}

Produce a figure that displays how the number of false positives
produced from the kNN classifier for the diabetes data set changes for
all integer values of \(k\) from 1 to 40. Use this graph to justify
whether or not \(k = 15\) was a valid choice for the number of
neighbors.

\subsection{kNN and the iris Data}\label{knn-and-the-iris-data}

Now kNN is used to classify the iris data. As before we use petal length
and width as predictors. The scales of the two predictors are not
particularly different, so we won't standardize the predictors.
Unsurprisingly kNN does well in classifying the test set for a wide
variety of \(k\) values.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sd}\NormalTok{(iris.train}\OperatorTok{$}\NormalTok{Petal.Width)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7316
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sd}\NormalTok{(iris.train}\OperatorTok{$}\NormalTok{Petal.Length) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.705
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(iris.train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    Sepal.Length Sepal.Width Petal.Length Petal.Width
77           6.8         2.8          4.8         1.4
88           6.3         2.3          4.4         1.3
58           4.9         2.4          3.3         1.0
96           5.7         3.0          4.2         1.2
126          7.2         3.2          6.0         1.8
17           5.4         3.9          1.3         0.4
       Species
77  versicolor
88  versicolor
58  versicolor
96  versicolor
126  virginica
17      setosa
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{knn_iris <-}\StringTok{ }\KeywordTok{knn}\NormalTok{(iris.train[,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)], iris.test[,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)], iris.train[,}\DecValTok{5}\NormalTok{], }\DataTypeTok{k=}\DecValTok{1}\NormalTok{, }\DataTypeTok{prob=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(knn_iris, iris.test[,}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            
knn_iris     setosa versicolor virginica
  setosa         25          0         0
  versicolor      0         22         1
  virginica       0          0        27
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{knn_iris <-}\StringTok{ }\KeywordTok{knn}\NormalTok{(iris.train[,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)], iris.test[,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)], iris.train[,}\DecValTok{5}\NormalTok{], }\DataTypeTok{k=}\DecValTok{3}\NormalTok{, }\DataTypeTok{prob=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(knn_iris, iris.test[,}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            
knn_iris     setosa versicolor virginica
  setosa         25          0         0
  versicolor      0         22         1
  virginica       0          0        27
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{knn_iris <-}\StringTok{ }\KeywordTok{knn}\NormalTok{(iris.train[,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)], iris.test[,}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)], iris.train[,}\DecValTok{5}\NormalTok{], }\DataTypeTok{k=}\DecValTok{15}\NormalTok{, }\DataTypeTok{prob=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(knn_iris, iris.test[,}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            
knn_iris     setosa versicolor virginica
  setosa         25          0         0
  versicolor      0         22         1
  virginica       0          0        27
\end{verbatim}

\section{Exercises}\label{exercises-7}

\textbf{Exercise Classification} Learning objectives: explore the
logistic regression classification method; apply the kNN classification
method; create confusion matrices to compare classification methods;
plot classified data.

\chapter{Text Data}\label{xml}

Many applications require the ability to manipulate and process text
data. For example, an email spam filter takes as its input various
features of email such as the sender, words in the subject, words in the
body, the number and types of attachments, and so on. The filter then
tries to build a classifier which can correctly classify a message as
spam or not spam (aka ham). As another example, some works of
literature, such as some of Shakespeare's plays or some of the
Federalist papers, have disputed authorship. By analyzing word use
across many documents, researchers try to determine the author of the
disputed work.

Working with text data requires functions that will, for example,
concatenate and split text strings, modify strings (e.g., converting to
lower-case or removing vowels), count the number of characters in a
string, and so on. In addition to being useful in such contexts, string
manipulation is helpful more generally in R---for example, to
effectively construct titles for graphics.

As with most tasks, there are a variety of ways to accomplish these text
processing tasks in R. The \texttt{base} R package has functions which
work with and modify text strings. Another useful package which
approaches these tasks in a slightly different way is \texttt{stringr}.
As with graphics, we will focus mainly on one package to avoid
confusion. In this case we will focus on the base R string processing
functions, but will emphasize that \texttt{stringr} is also worth
knowing.

The application to analyzing \emph{Moby Dick} below comes from the book
\emph{\{Text Analysis with R for Students of Literature} by Matthew L.
Jockers.

\section{Reading Text Data into R}\label{reading-text-data-into-r}

Often text data will not be in a rectangular format that is suitable for
reading into a data frame. For example, an email used to help train a
spam filter, or literary texts used to help determine authorship of a
novel are certainly not of this form. Often when working with text data
we want to read the whole text object into a single R vector. In this
case either the \texttt{scan} function or the \texttt{readLines}
function are useful. The \texttt{readLines} function is typically more
efficient, but \texttt{scan} is much more flexible.

As an example, consider the following email message and a plain text
version of the novel \emph{Moby Dick} by Herman Melville, the beginning
of which is displayed subsequently.

\begin{verbatim}
From safety33o@l11.newnamedns.com  Fri Aug 23 11:03:37 2002
Return-Path: <safety33o@l11.newnamedns.com>
Delivered-To: zzzz@localhost.example.com
Received: from localhost (localhost [127.0.0.1])
    by phobos.labs.example.com (Postfix) with ESMTP id 5AC994415F
    for <zzzz@localhost>; Fri, 23 Aug 2002 06:02:59 -0400 (EDT)
Received: from mail.webnote.net [193.120.211.219]
    by localhost with POP3 (fetchmail-5.9.0)
    for zzzz@localhost (single-drop); Fri, 23 Aug 2002 11:02:59 +0100 (IST)
Received: from l11.newnamedns.com ([64.25.38.81])
    by webnote.net (8.9.3/8.9.3) with ESMTP id KAA09379
    for <zzzz@example.com>; Fri, 23 Aug 2002 10:18:03 +0100
From: safety33o@l11.newnamedns.com
Date: Fri, 23 Aug 2002 02:16:25 -0400
Message-Id: <200208230616.g7N6GOR28438@l11.newnamedns.com>
To: kxzzzzgxlrah@l11.newnamedns.com
Reply-To: safety33o@l11.newnamedns.com
Subject: ADV: Lowest life insurance rates available!                                                   
moode

Lowest rates available for term life insurance! Take a moment 
and fill out our online form 
to see the low rate you qualify for. 
Save up to 70% from regular rates! Smokers accepted! 
http://www.newnamedns.com/termlife/ 
          
Representing quality nationwide carriers. Act now!
\end{verbatim}

\begin{verbatim}
The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville

This eBook is for the use of anyone anywhere at no cost and with
almost no restrictions whatsoever.  You may copy it, give it away or
re-use it under the terms of the Project Gutenberg License included
with this eBook or online at www.gutenberg.org


Title: Moby Dick; or The Whale

Author: Herman Melville

Last Updated: January 3, 2009
Posting Date: December 25, 2008 [EBook #2701]
Release Date: June, 2001

Language: English


*** START OF THIS PROJECT GUTENBERG EBOOK MOBY DICK; OR THE WHALE ***




Produced by Daniel Lazarus and Jonesey





MOBY DICK; OR THE WHALE

By Herman Melville
\end{verbatim}

The email message is available at
\url{http://blue.for.msu.edu/FOR875/data/email1.txt} while the novel is
available at \url{http://blue.for.msu.edu/FOR875/data/mobydick.txt}. We
will read these into R using \texttt{scan}.

First, we read in the email message. The \texttt{scan} function has
several possible arguments. For now the important arguments are the file
to be read (the argument is named \texttt{file}), the type of data in
the file (the argument is named \texttt{what}), and how the fields in
the file are separated (the argument is named \texttt{sep}). To
illustrate the \texttt{sep} argument, the file will be read into R once
with \texttt{sep\ =\ ""} indicating that the separator is whitespace,
and once with \texttt{sep\ =\ "\textbackslash{}n"} indicating that the
separator is the newline character, i.e., each field in the file is a
line.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.email <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/email1.txt"}
\OperatorTok{>}\StringTok{ }\NormalTok{email1 <-}\StringTok{ }\KeywordTok{scan}\NormalTok{(u.email, }\DataTypeTok{what =} \StringTok{"character"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(email1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 133
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{email1[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "From"                          
 [2] "safety33o@l11.newnamedns.com"  
 [3] "Fri"                           
 [4] "Aug"                           
 [5] "23"                            
 [6] "11:03:37"                      
 [7] "2002"                          
 [8] "Return-Path:"                  
 [9] "<safety33o@l11.newnamedns.com>"
[10] "Delivered-To:"                 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{email1 <-}\StringTok{ }\KeywordTok{scan}\NormalTok{(u.email, }\DataTypeTok{what =} \StringTok{"character"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(email1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 26
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{email1[}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "From safety33o@l11.newnamedns.com  Fri Aug 23 11:03:37 2002"              
 [2] "Return-Path: <safety33o@l11.newnamedns.com>"                              
 [3] "Delivered-To: zzzz@localhost.example.com"                                 
 [4] "Received: from localhost (localhost [127.0.0.1])"                         
 [5] "\tby phobos.labs.example.com (Postfix) with ESMTP id 5AC994415F"          
 [6] "\tfor <zzzz@localhost>; Fri, 23 Aug 2002 06:02:59 -0400 (EDT)"            
 [7] "Received: from mail.webnote.net [193.120.211.219]"                        
 [8] "\tby localhost with POP3 (fetchmail-5.9.0)"                               
 [9] "\tfor zzzz@localhost (single-drop); Fri, 23 Aug 2002 11:02:59 +0100 (IST)"
[10] "Received: from l11.newnamedns.com ([64.25.38.81])"                        
\end{verbatim}

Note that when \texttt{sep\ =\ ""} was specified, every time whitespace
was encountered R moved to a new element of the vector \texttt{email1},
and this vector ultimately contained 133 elements. When
\texttt{sep\ =\ "\textbackslash{}n"} was specified, all the text before
a newline was put into one element of the vector, which ended up with 26
elements.

The \texttt{scan} function is quite flexible. In fact,
\texttt{read.table} uses \texttt{scan} to actually read in the data.
Read the help file for \texttt{scan} if more information is desired.

Next \emph{Moby Dick} is read in line by line.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.moby <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/mobydick.txt"}
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick <-}\StringTok{ }\KeywordTok{scan}\NormalTok{(u.moby, }\DataTypeTok{what =} \StringTok{"character"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick[}\DecValTok{1}\OperatorTok{:}\DecValTok{25}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville"
 [2] "This eBook is for the use of anyone anywhere at no cost and with"          
 [3] "almost no restrictions whatsoever.  You may copy it, give it away or"      
 [4] "re-use it under the terms of the Project Gutenberg License included"       
 [5] "with this eBook or online at www.gutenberg.org"                            
 [6] "Title: Moby Dick; or The Whale"                                            
 [7] "Author: Herman Melville"                                                   
 [8] "Last Updated: January 3, 2009"                                             
 [9] "Posting Date: December 25, 2008 [EBook #2701]"                             
[10] "Release Date: June, 2001"                                                  
[11] "Language: English"                                                         
[12] "*** START OF THIS PROJECT GUTENBERG EBOOK MOBY DICK; OR THE WHALE ***"     
[13] "Produced by Daniel Lazarus and Jonesey"                                    
[14] "MOBY DICK; OR THE WHALE"                                                   
[15] "By Herman Melville"                                                        
[16] "Original Transcriber's Notes:"                                             
[17] "This text is a combination of etexts, one from the now-defunct ERIS"       
[18] "project at Virginia Tech and one from Project Gutenberg's archives. The"   
[19] "proofreaders of this version are indebted to The University of Adelaide"   
[20] "Library for preserving the Virginia Tech version. The resulting etext"     
[21] "was compared with a public domain hard copy version of the text."          
[22] "In chapters 24, 89, and 90, we substituted a capital L for the symbol"     
[23] "for the British pound, a unit of currency."                                
[24] "ETYMOLOGY."                                                                
[25] "(Supplied by a Late Consumptive Usher to a Grammar School)"                
\end{verbatim}

You will notice that the \texttt{scan} function ignored blank lines in
the file. If it is important to preserve blank lines, the argument
\texttt{blank.lines.skip\ =\ FALSE} can be supplied to \texttt{scan}.

The file containing the novel contains some introductory and closing
text that is not part of the original novel. If we are interested in
Melville's writing, we should remove this text. By inspection we can
discover that the novel's text begins at position 408 and ends at
position 18576.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick <-}\StringTok{ }\NormalTok{moby_dick[}\DecValTok{408}\OperatorTok{:}\DecValTok{18576}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(moby_dick)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 18169
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick[}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "CHAPTER 1. Loomings."                                                    
[2] "Call me Ishmael. Some years ago--never mind how long precisely--having"  
[3] "little or no money in my purse, and nothing particular to interest me on"
[4] "shore, I thought I would sail about a little and see the watery part of" 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick[}\DecValTok{18165}\OperatorTok{:}\DecValTok{18169}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "they glided by as if with padlocks on their mouths; the savage sea-hawks"
[2] "sailed with sheathed beaks. On the second day, a sail drew near, nearer,"
[3] "and picked me up at last. It was the devious-cruising Rachel, that in"   
[4] "her retracing search after her missing children, only found another"     
[5] "orphan."                                                                 
\end{verbatim}

\section{\texorpdfstring{The \texttt{paste}
Function}{The paste Function}}\label{the-paste-function}

The \texttt{paste} function concatenates vectors after (if necessary)
converting the vectors to character.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\StringTok{"Homer Simpson"}\NormalTok{, }\StringTok{"is"}\NormalTok{, }\StringTok{"Bart Simpson's"}\NormalTok{, }\StringTok{"father"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Homer Simpson is Bart Simpson's father"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{n <-}\StringTok{ }\DecValTok{10}
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\StringTok{"The value of n is"}\NormalTok{, n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "The value of n is 10"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"pig"}\NormalTok{, }\StringTok{"dog"}\NormalTok{), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "pig 3" "dog 3"
\end{verbatim}

By default the \texttt{paste} function separates the input vectors with
a space. But other separators can be specified.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\StringTok{"mail"}\NormalTok{, }\StringTok{"google"}\NormalTok{, }\StringTok{"com"}\NormalTok{, }\DataTypeTok{sep=}\StringTok{"."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "mail.google.com"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\StringTok{"and"}\NormalTok{, }\StringTok{"or"}\NormalTok{, }\DataTypeTok{sep =} \StringTok{"/"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "and/or"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"horse"}\NormalTok{, }\StringTok{"human"}\NormalTok{, }\StringTok{"elephant"}\NormalTok{), }\StringTok{"food"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dog food"      "cat food"      "horse food"   
[4] "human food"    "elephant food"
\end{verbatim}

Sometimes we want to take a character vector with \(n\) elements and
create a character vector with only one element, which contains all
\(n\) character strings. Setting the \texttt{collapse} argument to
something other than the default \texttt{NULL} tells R we want to do
this, and allows specification of the separator in the collapsed vector.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"one"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"four"}\NormalTok{, }\StringTok{"five"}\NormalTok{), }
\OperatorTok{+}\StringTok{       }\KeywordTok{c}\NormalTok{(}\StringTok{"six"}\NormalTok{, }\StringTok{"seven"}\NormalTok{, }\StringTok{"eight"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"ten"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "one six"     "two seven"   "three eight"
[4] "four nine"   "five ten"   
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"one"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"four"}\NormalTok{, }\StringTok{"five"}\NormalTok{), }
\OperatorTok{+}\StringTok{       }\KeywordTok{c}\NormalTok{(}\StringTok{"six"}\NormalTok{, }\StringTok{"seven"}\NormalTok{, }\StringTok{"eight"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"ten"}\NormalTok{), }\DataTypeTok{collapse =} \StringTok{"."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "one six.two seven.three eight.four nine.five ten"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"one"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"four"}\NormalTok{, }\StringTok{"five"}\NormalTok{),  }
\OperatorTok{+}\StringTok{       }\KeywordTok{c}\NormalTok{(}\StringTok{"six"}\NormalTok{, }\StringTok{"seven"}\NormalTok{, }\StringTok{"eight"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"ten"}\NormalTok{), }\DataTypeTok{collapse =} \StringTok{"&&"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "one six&&two seven&&three eight&&four nine&&five ten"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"one"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"four"}\NormalTok{, }\StringTok{"five"}\NormalTok{),}
\OperatorTok{+}\StringTok{       }\KeywordTok{c}\NormalTok{(}\StringTok{"six"}\NormalTok{, }\StringTok{"seven"}\NormalTok{, }\StringTok{"eight"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"ten"}\NormalTok{), }\DataTypeTok{collapse =} \StringTok{" "}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "one six two seven three eight four nine five ten"
\end{verbatim}

In the example above by default \texttt{paste} created a vector with
five elements, each containing one input string from the first input
vector and one from the second vector, pasted together. When a non
\texttt{NULL} argument was specified for \texttt{collapse}, the vector
created had one element, with the pasted strings separated by that
argument.\footnote{There is a somewhat subtle difference among the
  examples. If all the arguments are length one vectors, then
  \texttt{paste} by default returns a length one vector. But if one or
  more of the arguments have length greater than one, the default
  behavior of paste is to return a vector of length greater than one.
  The \texttt{collapse} argument changes this behavior.}

Also don't forget that R ``recycles'' values from vectors if two or more
different length vectors are provided as input.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{), }\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "a1"  "b2"  "a3"  "b4"  "a5"  "b6"  "a7"  "b8" 
 [9] "a9"  "b10"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{), }\DecValTok{1}\OperatorTok{:}\DecValTok{9}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "a1" "b2" "a3" "b4" "a5" "b6" "a7" "b8" "a9"
\end{verbatim}

Next, consider writing a function which simulates repeatedly tossing a
coin \(n\) times, counting the number of HEADS out of the \(n\) tosses.
For the first five repetitions of \(n\) tosses, the function will print
out the number of HEADS (for example if there are 7 HEADS in the
\(n=10\) tosses the function prints ``The number of HEADS out of 10
tosses is 7.'' The function returns a histogram of the number of HEADS,
with a title stating ``Number of HEADS in ?? tosses'' where ?? is
replaced by the number of tosses. The \texttt{paste} function will help
greatly.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{coin_toss <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(}\DataTypeTok{n=}\DecValTok{10}\NormalTok{, }\DataTypeTok{iter =} \DecValTok{500}\NormalTok{)\{}
\OperatorTok{+}\StringTok{   }\KeywordTok{require}\NormalTok{(ggplot2)}
\OperatorTok{+}\StringTok{   }\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{numheads =} \KeywordTok{numeric}\NormalTok{(iter))}
\OperatorTok{+}\StringTok{   }\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{iter) \{}
\OperatorTok{+}\StringTok{     }\NormalTok{df}\OperatorTok{$}\NormalTok{numheads[i] <-}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, n, }\FloatTok{0.5}\NormalTok{)}
\OperatorTok{+}\StringTok{     }\ControlFlowTok{if}\NormalTok{(i }\OperatorTok{<=}\StringTok{ }\DecValTok{5}\NormalTok{) \{}
\OperatorTok{+}\StringTok{       }\KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The number of HEADS out of"}\NormalTok{, n, }\StringTok{"tosses is"}\NormalTok{, df}\OperatorTok{$}\NormalTok{numheads[i]))\}}
\OperatorTok{+}\StringTok{   }\NormalTok{\}}
\OperatorTok{+}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ numheads)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{ggtitle}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"Number of HEADS in"}\NormalTok{, n, }\StringTok{"tosses"}\NormalTok{))}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\OperatorTok{>}\StringTok{ }\KeywordTok{coin_toss}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "The number of HEADS out of 10 tosses is 5"
[1] "The number of HEADS out of 10 tosses is 7"
[1] "The number of HEADS out of 10 tosses is 8"
[1] "The number of HEADS out of 10 tosses is 4"
[1] "The number of HEADS out of 10 tosses is 4"
\end{verbatim}

\includegraphics{bookdown_files/figure-latex/cointoss-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{coin_toss}\NormalTok{(}\DataTypeTok{n =} \DecValTok{25}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "The number of HEADS out of 25 tosses is 13"
[1] "The number of HEADS out of 25 tosses is 10"
[1] "The number of HEADS out of 25 tosses is 16"
[1] "The number of HEADS out of 25 tosses is 13"
[1] "The number of HEADS out of 25 tosses is 13"
\end{verbatim}

\includegraphics{bookdown_files/figure-latex/cointoss-2.pdf}

Let's now return to the object \texttt{moby\_dick} that contains the
text of the novel. If we want to analyze word choice, word frequency,
etc., it would be helpful to form a vector in which each element is a
word from the novel. One way to do this is to first paste the current
version of the \texttt{moby\_dick} variable into a new version which is
one long vector with the lines pasted together. To illustrate, we will
first do this with a much smaller object that shares the structure of
\texttt{moby\_dick}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{small_novel <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"First line"}\NormalTok{, }\StringTok{"Second somewhat longer line"}\NormalTok{, }
\OperatorTok{+}\StringTok{                  "third line."}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{small_novel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "First line"                 
[2] "Second somewhat longer line"
[3] "third line."                
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{small_novel <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(small_novel, }\DataTypeTok{collapse=}\StringTok{" "}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(small_novel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{small_novel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "First line Second somewhat longer line third line."
\end{verbatim}

Now we do the same with the actual novel.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(moby_dick, }\DataTypeTok{collapse =} \StringTok{" "}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(moby_dick)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

At this point \texttt{moby\_dick} contains a single very long character
string. Next we will separate this string into separate words and clean
up the resulting vector a bit.

\section{More String Processing
Functions}\label{more-string-processing-functions}

Common string processing tasks include changing case between upper and
lower, extracting and/or replacing substrings of a string, trimming a
string to a specified width, counting the number of characters in a
string, etc.

\subsection{\texorpdfstring{\texttt{tolower} and
\texttt{toupper}}{tolower and toupper}}\label{tolower-and-toupper}

R contains functions \texttt{tolower} and \texttt{toupper} which very
simply change the case of all characters in a string.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ "aBCdefG12#"}
\OperatorTok{>}\StringTok{ }\NormalTok{y <-}\StringTok{ }\NormalTok{x}
\OperatorTok{>}\StringTok{ }\KeywordTok{tolower}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "abcdefg12#"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{toupper}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "ABCDEFG12#"
\end{verbatim}

If we are interested in frequencies of words in \emph{Moby Dick},
converting all the text to the same case makes sense, so for example the
word ``the'' at the beginning of a sentence is not counted differently
than the same word in the middle of a sentence.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick <-}\StringTok{ }\KeywordTok{tolower}\NormalTok{(moby_dick)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{\texttt{nchar} and
\texttt{strsplit}}{nchar and strsplit}}\label{nchar-and-strsplit}

The function \texttt{nchar} counts the number of characters in a string
or strings.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{nchar}\NormalTok{(}\StringTok{"dog"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{nchar}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"horse"}\NormalTok{, }\StringTok{"elephant"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3 3 5 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{nchar}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"horse"}\NormalTok{, }\StringTok{"elephant"}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\StringTok{"goat"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  3  3  5  8 NA  4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{nchar}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"horse"}\NormalTok{, }\StringTok{"elephant"}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\StringTok{"goat"}\NormalTok{), }\DataTypeTok{keepNA =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3 3 5 8 2 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{nchar}\NormalTok{(moby_dick)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1190309
\end{verbatim}

By default \texttt{nchar} returns NA for a missing value. If you want
\texttt{nchar} to return 2 for a \texttt{NA} value, you can set
\texttt{keepNA\ =\ TRUE}.\footnote{It may be reasonable if the purpose
  of counting characters is to find out how much space to allocate for
  printing a vector of strings where the \texttt{NA} string will be
  printed.}

The function \texttt{strsplit} splits the elements of a character
vector. The function returns a list, and often the \texttt{unlist}
function is useful to convert the list into an atomic vector.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"mail.msu.edu"}\NormalTok{, }\StringTok{"mail.google.com"}\NormalTok{, }\StringTok{"www.amazon.com"}\NormalTok{),}
\OperatorTok{+}\StringTok{          }\DataTypeTok{split =} \StringTok{"."}\NormalTok{, }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[[1]]
[1] "mail" "msu"  "edu" 

[[2]]
[1] "mail"   "google" "com"   

[[3]]
[1] "www"    "amazon" "com"   
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"mail.msu.edu"}\NormalTok{, }\StringTok{"mail.google.com"}\NormalTok{, }\StringTok{"www.amazon.com"}\NormalTok{),}
\OperatorTok{+}\StringTok{                 }\DataTypeTok{split =} \StringTok{"."}\NormalTok{, }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "mail"   "msu"    "edu"    "mail"   "google"
[6] "com"    "www"    "amazon" "com"   
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"pig"}\NormalTok{, }\StringTok{"horse"}\NormalTok{), }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{split =} \StringTok{"o"}\NormalTok{, }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "d"   "g"   "cat" "pig" "h"   "rse"
\end{verbatim}

Setting the argument \texttt{fixed} to \texttt{TRUE} tells R to match
the value of \texttt{split} exactly when performing the split. The
function can be much more powerful if the value of \texttt{split} is a
\emph{regular expression}, which can for example ask for splits at any
vowels, etc. We will not go in depth on Regular Expressions here, but we
will make some use of regular expressions on a case-by-case basis prior
to that. Regular expressions are very powerful, so if this chapter
interests you, we suggest researching regular expressions on your own
(as always there are plenty of free resources online).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"pig"}\NormalTok{, }\StringTok{"horse"}\NormalTok{, }\StringTok{"rabbit"}\NormalTok{), }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{split =} \StringTok{"[aeiou]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "d"  "g"  "c"  "t"  "p"  "g"  "h"  "rs" "r"  "bb"
[11] "t" 
\end{verbatim}

The regular expression \texttt{{[}aeiou{]}} represents any of the
letters a, e, i, o, u. In general a string of characters enclosed in
square brackets indicates any one character in the string.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"dog"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"pig"}\NormalTok{, }\StringTok{"horse"}\NormalTok{, }\StringTok{"rabbit"}\NormalTok{), }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{split =} \StringTok{"[aorb]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "d"   "g"   "c"   "t"   "pig" "h"   ""    "se" 
 [9] ""    ""    ""    ""    "it" 
\end{verbatim}

The regular expression \texttt{{[}aorb{]}} represents any of the letters
a, o, r, b.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"a1c2b"}\NormalTok{, }\StringTok{"bbb2bc3f"}\NormalTok{), }\DataTypeTok{split =} \StringTok{"[1-9]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "a"   "c"   "b"   "bbb" "bc"  "f"  
\end{verbatim}

The regular expression \texttt{{[}1-9{]}} represents any of the numbers
1, 2, 3, 4, 5, 6, 7, 8, 9.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"aBc1fGh"}\NormalTok{, }\StringTok{"1TyzaaG"}\NormalTok{), }\DataTypeTok{split =} \StringTok{"[^a-z]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "a"    "c"    "f"    "h"    ""     ""     "yzaa"
\end{verbatim}

The regular expression \texttt{{[}a-z{]}} represents any lower case
letter. The caret \texttt{\^{}} in front of \texttt{a-z} indicates
``match any character \emph{except} those in the following string''
which in this case indicates ``match any character that is NOT a lower
case letter''.

Recall that the \texttt{moby\_dick} vector now contains one long
character string which includes the entire text of the novel, and that
we would like to split it into separate words. We now know how to do
this using \texttt{strsplit} and a regular expression. First a smaller
example.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }\StringTok{"the plain"}\NormalTok{), }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{split =} \StringTok{"[^0-9A-Za-z]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the"    "rain"   "in"     "Spain"  "stays" 
[6] "mainly" "in"     "the"    "plain" 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }\StringTok{"the plain"}\NormalTok{), }
\OperatorTok{+}\StringTok{                 }\DataTypeTok{split =}\StringTok{" "}\NormalTok{, }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the"    "rain"   "in"     "Spain"  "stays" 
[6] "mainly" "in"     "the"    "plain" 
\end{verbatim}

Look at the regular expression. The caret says ``match anything but''
and then \texttt{0=9A-Za-z} says ``any digit, any lower-case letter, and
any upper-case letter.'' So the whole expression (including the fact
that it is the value of the argument \texttt{split}) says ``match
anything but any digit, any lower-case letter, or any upper-case
letter''.

Now we apply this to \texttt{moby\_dick}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick <-}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(moby_dick, }\DataTypeTok{split =} \StringTok{"[^0-9A-Za-z]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Let's see a bit of what we have.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick[}\DecValTok{1}\OperatorTok{:}\DecValTok{50}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "chapter"    "1"          ""          
 [4] "loomings"   ""           "call"      
 [7] "me"         "ishmael"    ""          
[10] "some"       "years"      "ago"       
[13] ""           "never"      "mind"      
[16] "how"        "long"       "precisely" 
[19] ""           "having"     "little"    
[22] "or"         "no"         "money"     
[25] "in"         "my"         "purse"     
[28] ""           "and"        "nothing"   
[31] "particular" "to"         "interest"  
[34] "me"         "on"         "shore"     
[37] ""           "i"          "thought"   
[40] "i"          "would"      "sail"      
[43] "about"      "a"          "little"    
[46] "and"        "see"        "the"       
[49] "watery"     "part"      
\end{verbatim}

There is a small problem: Some of the ``words'' are blank. The following
small example indicates why this happened.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }\StringTok{"the plain"}\NormalTok{), }\DataTypeTok{split =} \StringTok{"[^0-9A-Za-z]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "the"    "rain"   "in"     "Spain"  ""      
 [6] ""       ""       "stays"  "mainly" "in"    
[11] "the"    "plain" 
\end{verbatim}

It is not too hard to remove the blank words.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(moby_dick)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 253993
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{not.blanks <-}\StringTok{ }\KeywordTok{which}\NormalTok{(moby_dick }\OperatorTok{!=}\StringTok{ ""}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick <-}\StringTok{ }\NormalTok{moby_dick[not.blanks]}
\OperatorTok{>}\StringTok{ }\KeywordTok{length}\NormalTok{(moby_dick)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 214889
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick[}\DecValTok{1}\OperatorTok{:}\DecValTok{50}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "chapter"    "1"          "loomings"  
 [4] "call"       "me"         "ishmael"   
 [7] "some"       "years"      "ago"       
[10] "never"      "mind"       "how"       
[13] "long"       "precisely"  "having"    
[16] "little"     "or"         "no"        
[19] "money"      "in"         "my"        
[22] "purse"      "and"        "nothing"   
[25] "particular" "to"         "interest"  
[28] "me"         "on"         "shore"     
[31] "i"          "thought"    "i"         
[34] "would"      "sail"       "about"     
[37] "a"          "little"     "and"       
[40] "see"        "the"        "watery"    
[43] "part"       "of"         "the"       
[46] "world"      "it"         "is"        
[49] "a"          "way"       
\end{verbatim}

(In this example it would have been more efficient to replace

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick <-}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(moby_dick, }\DataTypeTok{split =} \StringTok{"[^0-9A-Za-z]"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick2 <-}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(moby_dick, }\DataTypeTok{split =} \StringTok{" "}\NormalTok{, }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Then the second step of selecting the non-blank words would not have
been necessary. But regular expressions will be essential going forward,
so it was worthwhile using regular expressions even if they do not
provide the most efficient method.)

\subsection{Practice Problem}\label{practice-problem-14}

Use \texttt{strsplit()} and regular expressions to split the following
strings into their respective words (i.e.~write a regular expression
that will match the \texttt{-} and \texttt{.} character). Your output
should be a vector (not a list).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{strings <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Once-upon"}\NormalTok{, }\StringTok{"a.time"}\NormalTok{, }\StringTok{"there"}\NormalTok{, }\StringTok{"was-a"}\NormalTok{, }\StringTok{"man.named"}\NormalTok{, }\StringTok{"Bob"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{\texttt{nchar}
Again}{nchar Again}}\label{nchar-again}

Now that the vector \texttt{moby\_dick} contains each word in the novel
as a separate element, it is relatively easy to do some basic analyses.
For example the \texttt{nchar} function can give us a count of the
number of characters in each element of the vector, i.e., can give us
the number of letters in each word in the novel.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick_nchar <-}\StringTok{ }\KeywordTok{nchar}\NormalTok{(moby_dick)}
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick_nchar[}\DecValTok{1}\OperatorTok{:}\DecValTok{50}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  7  1  8  4  2  7  4  5  3  5  4  3  4  9  6  6  2
[18]  2  5  2  2  5  3  7 10  2  8  2  2  5  1  7  1  5
[35]  4  5  1  6  3  3  3  6  4  2  3  5  2  2  1  3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{max}\NormalTok{(moby_dick_nchar)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{nwords =}\NormalTok{ moby_dick_nchar), }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ nwords)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{1}\NormalTok{, }\DataTypeTok{color =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"white"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Number of letters in words in Moby Dick"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-285-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick_word_table <-}\StringTok{ }\KeywordTok{table}\NormalTok{(moby_dick)}
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick_word_table <-}\StringTok{ }\KeywordTok{sort}\NormalTok{(moby_dick_word_table, }\DataTypeTok{decreasing =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{moby_dick_word_table[}\DecValTok{1}\OperatorTok{:}\DecValTok{50}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
moby_dick
  the    of   and     a    to    in  that    it   his 
14175  6469  6325  4636  4539  4077  3045  2497  2495 
    i    he   but     s    as  with    is   was   for 
 2114  1876  1805  1737  1720  1692  1690  1627  1593 
  all  this    at    by whale   not  from   him    so 
 1515  1382  1304  1175  1150  1142  1072  1058  1053 
   on    be   one   you there   now   had  have    or 
 1040  1032   907   884   854   779   767   754   689 
 were  they  like    me  then which  what  some their 
  677   649   639   630   628   625   611   608   604 
 when    an   are    my    no 
  601   590   587   587   581 
\end{verbatim}

\subsection{Practice Problem}\label{practice-problem-15}

The goal of this exercise is to generate a wordcloud image of the 50
most frqeuent words in \emph{Moby Dick} that we identifid above. To do
this, we need the \texttt{wordcloud} package (you may also need to
install the package \texttt{tm}). Look at the R documentation for the
\texttt{wordcloud} function included in the \texttt{wordcloud} package
and create a wordcloud image of the most popular 500 words in the novel.
Here is what mine looks like

\begin{verbatim}
Warning in wordcloud(md.data.frame$moby_dick,
md.data.frame$Freq, max.words = 500, : the could not be
fit on page. It will not be plotted.
\end{verbatim}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-287-1.pdf}

\subsection{\texorpdfstring{\texttt{substr} and
\texttt{strtrim}}{substr and strtrim}}\label{substr-and-strtrim}

The \texttt{substr} function can be used to extract or replace
substrings. The first argument is the string to be manipulated, and the
second and third arguments specify the first and last elements of the
string to be extracted or to be replaced.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ "Michigan"}
\OperatorTok{>}\StringTok{ }\KeywordTok{substr}\NormalTok{(x, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "ch"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{substr}\NormalTok{(x, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{) <-}\StringTok{ "CH"}
\OperatorTok{>}\StringTok{ }\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "MiCHigan"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Ohio"}\NormalTok{, }\StringTok{"Michigan"}\NormalTok{, }\StringTok{"Illinois"}\NormalTok{, }\StringTok{"Wisconsin"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{substr}\NormalTok{(x, }\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "hio" "ich" "lli" "isc"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{substr}\NormalTok{(x, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{) <-}\StringTok{ "$#&"}
\OperatorTok{>}\StringTok{ }\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "O$#&"      "M$#&igan"  "I$#&nois"  "W$#&onsin"
\end{verbatim}

The \texttt{strtrim} function trims a character string to a specified
length.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{strtrim}\NormalTok{(}\StringTok{"Michigan"}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "M"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{strtrim}\NormalTok{(}\StringTok{"Michigan"}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Mich"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{strtrim}\NormalTok{(}\StringTok{"Michigan"}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Michigan"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{strtrim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Ohio"}\NormalTok{, }\StringTok{"Michigan"}\NormalTok{, }\StringTok{"Illinois"}\NormalTok{, }\StringTok{"Wisconsin"}\NormalTok{), }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Ohi" "Mic" "Ill" "Wis"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{strtrim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Ohio"}\NormalTok{, }\StringTok{"Michigan"}\NormalTok{, }\StringTok{"Illinois"}\NormalTok{, }\StringTok{"Wisconsin"}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Ohi"    "Mich"   "Illin"  "Wiscon"
\end{verbatim}

\subsection{\texorpdfstring{\texttt{grep} and Related
Functions}{grep and Related Functions}}\label{grep-and-related-functions}

The \texttt{grep} function searches for a specified pattern and returns
either the locations where this pattern is found or the selected
elements. The \texttt{grepl} function returns a logical vector rather
than locations of elements.

Here are some examples. All use \texttt{fixed\ =\ TRUE} since at this
point we are using fixed character strings rather than regular
expressions.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{grep}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }\StringTok{"the plain"}\NormalTok{), }
\OperatorTok{+}\StringTok{      }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{grep}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }\StringTok{"the plain"}\NormalTok{), }
\OperatorTok{+}\StringTok{      }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{value =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the rain"                
[2] "in Spain    stays mainly"
[3] "the plain"               
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{grepl}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }\StringTok{"the plain"}\NormalTok{), }
\OperatorTok{+}\StringTok{       }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  TRUE  TRUE FALSE  TRUE
\end{verbatim}

The \texttt{sub} and \texttt{gsub} functions replace a specified
character string. The \texttt{sub} function only replaces the first
occurrence, while \texttt{gsub} replaces all occurrences.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"?"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }
\OperatorTok{+}\StringTok{                  "the plain"}\NormalTok{), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the r?in"                
[2] "in Sp?in    st?ys m?inly"
[3] "in"                      
[4] "the pl?in"               
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sub}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"?"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }
\OperatorTok{+}\StringTok{                 "the plain"}\NormalTok{), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the r?in"                
[2] "in Sp?in    stays mainly"
[3] "in"                      
[4] "the pl?in"               
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"???"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }
\OperatorTok{+}\StringTok{                    "the plain"}\NormalTok{), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the r???in"                    
[2] "in Sp???in    st???ys m???inly"
[3] "in"                            
[4] "the pl???in"                   
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{sub}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"???"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"the rain"}\NormalTok{, }\StringTok{"in Spain    stays mainly"}\NormalTok{, }\StringTok{"in"}\NormalTok{, }
\OperatorTok{+}\StringTok{                   "the plain"}\NormalTok{), }\DataTypeTok{fixed =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "the r???in"                
[2] "in Sp???in    stays mainly"
[3] "in"                        
[4] "the pl???in"               
\end{verbatim}

\section{Exercises}\label{exercises-8}

\textbf{Exercise Text Data} Learning objectives: read and write text
data; concatenate text with the \texttt{paste} function, analyze text
with \texttt{nchar}; practice with functions; manipulate strings with
\texttt{substr} and \texttt{strtrim}.

\chapter{Rcpp}\label{rcpp}

R is an interpreted language. The code interpretor runs each line of a
script individually instead of compiling the entire file at once as in a
compiled language like C++. This means R can be slower than compiled
languages when completing some tasks. In this chapter, we show how to
improve the performance of our R scripts by rewriting functions in
C++\footnote{You do not need prior C++ experience to complete this
  chapter and corresponding exercises, but we are hoping you learn a
  little C++ syntax along the way!}. Although R has an API for
developers to move between R data structures and data structures in
lower-level languages (C++, C, FORTRAN, etc.), an alternative is to use
\texttt{Rcpp}. According to the \href{http://www.rcpp.org/}{official
Rcpp website}, ``Rcpp provides a powerful API on top of R, permitting
direct interchange of rich R objects between R and C++.'' It is a
higher-level approach than using the aforementioned API directly. C++
functions can address gaps in R's abilities including

\begin{itemize}
\tightlist
\item
  Vectorizing loops whose subsequent iterations depend on previous
  iterations.
\item
  Writing recursive functions with lower overhead. (Recursive functions
  are functions that call themselves, leading to millions of function
  calls.)
\item
  Using data structures and algorithms that R does not provide but that
  are in the C++ standard template library (STL) such as ordered maps
  and double-ended queues.
\end{itemize}

In this chapter, we will cover an abbreviated/modified version of Hadley
Wickham's tutorial
\href{http://adv-r.had.co.nz/Rcpp.html\%7D\%7BHigh\%20performance\%20functions\%20with\%20Rcpp}{High
performance functions with Rcpp}

\section{Getting Started with Rcpp}\label{getting-started-with-rcpp}

\subsection{Installation}\label{installation}

Before we install the \texttt{Rcpp} package, we need a working C++
compiler. To get the compiler:

\begin{itemize}
\tightlist
\item
  Windows: install Rtools from
  \href{https://cran.r-project.org/bin/windows/Rtools/}{here}.
\item
  Mac: install Xcode from the Mac App Store.
\item
  Linux: in the terminal (for Debian-based systems or similar) enter
  \texttt{sudo\ apt-get\ install\ r-base\ dev}.
\end{itemize}

Now we can install \texttt{Rcpp}. (Note that the \texttt{microbenchmark}
package is needed for the examples in this chapter, so we'll install
that, too.)

\subsection{The Simplest C++ Example}\label{the-simplest-c-example}

It is common for textbooks to introduce a new programming language
through the ``Hello World'' program.\footnote{For a collection of
  ``Hello World'' programs in 400+ programming languages, see
  \href{https://helloworldcollection.github.io/}{here}.} If we wanted to
write this simple program in C++, the code would look like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{> }\ErrorTok{#}\NormalTok{include <iostream>}
\NormalTok{+ }
\NormalTok{+ }\DataTypeTok{int}\NormalTok{ main()}
\NormalTok{+ \{}
\NormalTok{+     }\BuiltInTok{std::}\NormalTok{cout << }\StringTok{"Hello World!"}\NormalTok{ << }\BuiltInTok{std::}\NormalTok{endl;}
\NormalTok{+ \}}
\end{Highlighting}
\end{Shaded}

Think about the C++ code above. How would you accomplish the same task
in R? How are the programs similar in syntax and structure? How are they
different? In the following section, we will rewrite this program in a
format that can interface with R through \texttt{Rcpp}. Note that C++ is
a compiled language, which means we cannot run the program line-by-line
like we can with an R script.

\section{Using Rcpp}\label{using-rcpp}

\subsection{Exporting C++ Functions}\label{exporting-c-functions}

Let's start out with that simple, obligatory ``Hello World!'' program in
C++ that we will export to R. C++ files use the extension
\texttt{*.cpp}. Through the RStudio menu, create a new C++ File (File
\(>\) New File \(>\) C++ File). Note that the default C++ file contains
the line \texttt{\#include\ \textless{}Rcpp.h\textgreater{}}. In C++,
these \texttt{include} files are header files that provide us with
objects and functions that we can use within our C++ file. Although the
program building process is different, there are some parallels between
these header files and the packages we use in our R code. Note that
unlike R, every line of code in a C++ file must end with a semicolon.

To verify that Rcpp is working correctly, let's run the following code.
Save the document as \texttt{hello.cpp}, and enter the following code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{> }\ErrorTok{#}\NormalTok{include <Rcpp.h>}
\NormalTok{+ }\KeywordTok{using} \KeywordTok{namespace}\NormalTok{ Rcpp;}
\NormalTok{+ }
\NormalTok{+ }\CommentTok{// [[Rcpp::export]]}
\NormalTok{+ }
\NormalTok{+ }\DataTypeTok{void}\NormalTok{ hello()\{}
\NormalTok{+   Rprintf(}\StringTok{"Hello World!}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{);}
\NormalTok{+ \}}
\end{Highlighting}
\end{Shaded}

Let's do a quick line-by line explanation:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{\#include\ \textless{}Rcpp.h\textgreater{}}: contains the
  definitions used by the Rcpp package. \textbackslash{}item
  \texttt{using\ namespace\ Rcpp;}: allows us to call functions from the
  Rcpp header file by writing \texttt{functionname} instead of
  \texttt{Rcpp::functionname}. \textbackslash{}item
  \texttt{//\ {[}{[}Rcpp::export{]}{]}}: an Rcpp attribute. Attributes
  are annotations that are added to C++ source files to indicate that
  C++ functions should be made available as R functions.
  \textbackslash{}item \texttt{void\ hello()\{}: the declaration of the
  \texttt{hello} function, which has a return type \texttt{void} and no
  arguments, hence the empty parentheses. Note that the function content
  (definition) is all contained within the squiggly brackets.
  \textbackslash{}item
  \texttt{Rprintf("Hello\ World!\textbackslash{}n");}: prints to the R
  console.
\end{enumerate}

Now, we can go to the RStudio Console and test our code with the
following three lines and the expected output.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(Rcpp)}
\OperatorTok{>}\StringTok{ }\KeywordTok{sourceCpp}\NormalTok{(}\StringTok{"hello.cpp"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{hello}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Hello"
\end{verbatim}

The \texttt{sourceCpp} function parsed our C++ file (``hello.cpp'') and
looked for functions marked with the \texttt{Rcpp::export} attribute. A
shared library was then built and the exported function
(\texttt{hello()}) was made available as an R function in the current
environment. The function simply printed ``Hello World!'' to our RStudio
Console. Great! You have now written a C++ function using built-in C++
types and Rcpp wrapper types and then sourced them like an R script.

\subsection{Inline C++ Code}\label{inline-c-code}

Maintaining C++ code in it's own source file provides several benefits
including the ability to use C++ aware text-editing tools and
straightforward mapping of compilation errors to lines in the source
file. However, it's also possible to do inline declaration and execution
of C++ code.

There are several ways to accomplish this, including passing a code
string to \texttt{sourceCpp()} or using the shorter-form
\texttt{cppFunction()} or \texttt{evalCpp()} functions. Run the
following code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(Rcpp)}

\KeywordTok{cppFunction}\NormalTok{(}\StringTok{"}
\StringTok{  int add(int x, int y, int z) \{}
\StringTok{    int sum = x + y + z;}
\StringTok{    return sum;}
\StringTok{  \}"}
\NormalTok{)}

\KeywordTok{add}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a <-}\StringTok{ }\KeywordTok{add}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6
\end{verbatim}

When you run this code, Rcpp will compile the C++ code and construct an
R function that connects to the compiled C++ function. We're going to
use this simple interface to learn how to write C++. C++ is a large
language, and there's no way to cover it all in the limited time we
have. Instead, you'll get the basics so that you can start writing
useful functions to address bottlenecks in your R code.

\section{The Rcpp Interface}\label{the-rcpp-interface}

The following subsections will teach you the basics by translating
simple R functions to their C++ equivalents. We'll start simple with a
function that has no inputs and a scalar output, and then get
progressively more complicated:

\begin{itemize}
\tightlist
\item
  No input and scalar output
\item
  Scalar input and scalar output
\item
  Vector input and scalar output
\item
  Vector input and vector output
\item
  Matrix input and vector output
\item
  Matrix input and matrix output
\end{itemize}

\section{No input and scalar output}\label{no-input-and-scalar-output}

Let's start with a very simple function. It has no arguments and always
returns the integer 1:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{one <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{() 1L}
\end{Highlighting}
\end{Shaded}

The equivalent C++ function is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{> }\DataTypeTok{int}\NormalTok{ one() \{}
\NormalTok{+   }\ControlFlowTok{return} \DecValTok{1}\NormalTok{;}
\NormalTok{+ \}}
\end{Highlighting}
\end{Shaded}

We can compile and use this from R with \texttt{cppFunction}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cppFunction}\NormalTok{(}\StringTok{"}
\StringTok{  int one() \{}
\StringTok{    return 1;}
\StringTok{  \}"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This small function illustrates a number of important differences
between R and C++:

\begin{itemize}
\tightlist
\item
  The syntax to create a function looks like the syntax to call a
  function; you don't use assignment to create functions as you do in R.
\item
  You must declare the type of output the function returns. This
  function returns an int (a scalar integer). The classes for the most
  common types of R vectors are: NumericVector, IntegerVector,
  CharacterVector, and LogicalVector.
\item
  Scalars and vectors are different. The scalar equivalents of numeric,
  integer, character, and logical vectors are: double, int, String, and
  bool.
\item
  You must use an explicit return statement to return a value from a
  function.
\item
  Every statement is terminated by a semicolon.
\end{itemize}

\subsection{Scalar input and scalar
output}\label{scalar-input-and-scalar-output}

The next example function implements a scalar version of the
\texttt{sign()} function which returns 1 if the input is positive, and
-1 if it's negative:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{signR <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
    \ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{) \{}
        \DecValTok{1}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{) \{}
        \DecValTok{0}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
        \OperatorTok{-}\DecValTok{1}
\NormalTok{    \}}
\NormalTok{\}}

\KeywordTok{cppFunction}\NormalTok{(}\StringTok{"}
\StringTok{  int signC(int x) \{}
\StringTok{    if (x > 0) \{}
\StringTok{      return 1;}
\StringTok{    \} else if (x == 0) \{}
\StringTok{      return 0;}
\StringTok{    \} else \{}
\StringTok{      return -1;}
\StringTok{    \}}
\StringTok{  \}"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In the C++ version:

\begin{itemize}
\item
  We declare the type of each input in the same way we declare the type
  of the output. While this makes the code a little more verbose, it
  also makes it very obvious what type of input the function needs.
\item
  The \texttt{if} syntax is identical. While there are some big
  differences between R and C++, there are also lots of similarities!
  C++ also has a \texttt{while} statement that works the same way as
  R's, e.g., as in R you can use \texttt{break} to exit the loop.
\end{itemize}

\subsection{Vector input and scalar
output}\label{vector-input-and-scalar-output}

One big difference between R and C++ is that the cost of loops is much
lower in C++. For example, we could implement the \texttt{sum()}
function in R using a loop. If you've been programming in R a while,
you'll probably have a visceral reaction to this function!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sumR <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    total <-}\StringTok{ }\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(x)) \{}
\NormalTok{        total <-}\StringTok{ }\NormalTok{total }\OperatorTok{+}\StringTok{ }\NormalTok{x[i]}
\NormalTok{    \}}
\NormalTok{    total}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

In C++, loops have very little overhead, so it's fine to use them.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cppFunction}\NormalTok{(}\StringTok{"}
\StringTok{  double sumC(NumericVector x) \{}
\StringTok{    int n = x.size();}
\StringTok{    double total = 0;}
\StringTok{    for(int i = 0; i < n; i++) \{}
\StringTok{      total += x[i];}
\StringTok{    \}}
\StringTok{    return total;}
\StringTok{  \}"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The C++ version is similar, but

\begin{itemize}
\item
  To find the length of the vector, we use the \texttt{.size()} method,
  which returns an integer. C++ methods are called with \texttt{.}
  (i.e., a period).
\item
  The \texttt{for} statement has a different syntax:
  \texttt{for(init;\ check;\ increment)}. This loop is initialized by
  creating a new variable called \texttt{i} with value 0. Before each
  iteration, we check that \texttt{i\ \textless{}\ n}, and terminate the
  loop if it's not. After each iteration, we increment the value of
  \texttt{i} by one, using the special prefix operator \texttt{++} which
  increases the value of \texttt{i} by 1.
\item
  In C++, vector indices start at 0. I'll say this again because it's so
  important: IN C++, VECTOR INDICES START AT 0! This is a very common
  source of bugs when converting R functions to C++.
\item
  Use \texttt{=} for assignment, not \texttt{\textless{}-}.
\item
  C++ provides operators that modify in-place:
  \texttt{total\ +=\ x{[}i{]}} is equivalent to
  \texttt{total\ =\ total\ +\ x{[}i{]}}. Similar in-place operators are
  \texttt{-=}, \texttt{*=;}, and \texttt{/=}.
\end{itemize}

This is a good example of where C++ is much more efficient than R. As
shown by the following microbenchmark, \texttt{sumC()} is competitive
with the built-in (and highly optimized) \texttt{sum()}, while
\texttt{sumR()} is several orders of magnitude slower. Note, you'll need
to install the microbenchmark package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(microbenchmark)}

\NormalTok{x <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{1000}\NormalTok{)}
\KeywordTok{microbenchmark}\NormalTok{(}\KeywordTok{sum}\NormalTok{(x), }\KeywordTok{sumC}\NormalTok{(x), }\KeywordTok{sumR}\NormalTok{(x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Unit: microseconds
    expr    min     lq   mean median     uq      max
  sum(x)  1.006  1.069  1.204  1.097  1.136    8.756
 sumC(x)  2.345  2.457 12.837  2.531  2.689  990.538
 sumR(x) 38.699 38.910 65.486 39.031 39.273 2660.493
 neval
   100
   100
   100
\end{verbatim}

The \texttt{microbenchmark()} function runs each function it's passed
100 times and provides summary statistics for the multiple execution
times. This is a very handy tool for testing various function
implementations (as illustrated above).

\subsection{Vector input and vector
output}\label{vector-input-and-vector-output}

Next we'll create a function that computes the Euclidean distance
between a value and a vector of values:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdistR <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, ys) \{}
    \KeywordTok{sqrt}\NormalTok{((x }\OperatorTok{-}\StringTok{ }\NormalTok{ys)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

It's not obvious that we want \texttt{x} to be a scalar from the
function definition. We'd need to make that clear in the documentation.
That's not a problem in the C++ version because we have to be explicit
about types:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cppFunction}\NormalTok{(}\StringTok{"}
\StringTok{  NumericVector pdistC(double x, NumericVector ys) \{}
\StringTok{    int n = ys.size();}
\StringTok{    NumericVector out(n);}

\StringTok{    for(int i = 0; i < n; i++) \{}
\StringTok{      out[i] = sqrt(pow(ys[i] - x, 2.0));}
\StringTok{    \}}
\StringTok{    return out;}
\StringTok{  \}"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This function introduces only a few new concepts:

\begin{itemize}
\tightlist
\item
  We create a new numeric vector of length n with a constructor:
  \texttt{NumericVector\ out(n)}. This and similar vector and matrix
  constrictors initialize the elements with zeros. Another useful way of
  making a vector is to copy an existing one:
  \texttt{NumericVector\ zs\ =\ clone(ys)}.
\item
  C++ uses \texttt{pow()}, not \texttt{\^{}}, for exponentiation.
\end{itemize}

Note that because the R version is fully vectorized, it's already going
to be fast. On my computer, it takes around 8 ms with a 1 million
element y vector. The C++ function is twice as fast, \(\sim\) 4 ms, but
assuming it took you 10 minutes to write the C++ function, you'd need to
run it \(\sim\) 150,000 times to make rewriting worthwhile :-) The
reason why the C++ function is faster is subtle, and relates to memory
management. The R version needs to create an intermediate vector the
same length as \texttt{y(x\ -\ ys)}, and allocating memory is an
expensive operation. The C++ function avoids this overhead because it
uses an intermediate scalar.

\subsection{Matrix input and vector
output}\label{matrix-input-and-vector-output}

Each vector type has a matrix equivalent: \texttt{NumericMatrix},
\texttt{IntegerMatrix}, \texttt{CharacterMatrix}, and
\texttt{LogicalMatrix}. Using them is straightforward. For example, we
could create a function that reproduces \texttt{rowSums()}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cppFunction}\NormalTok{(}\StringTok{"}
\StringTok{  NumericVector rowSumsC(NumericMatrix x) \{}
\StringTok{    int nrow = x.nrow(), ncol = x.ncol();}
\StringTok{    NumericVector out(nrow);}

\StringTok{    for (int i = 0; i < nrow; i++) \{}
\StringTok{      double total = 0;}
\StringTok{      for (int j = 0; j < ncol; j++) \{}
\StringTok{        total += x(i, j);}
\StringTok{      \}}
\StringTok{      out[i] = total;}
\StringTok{    \}}
\StringTok{    return out;}
\StringTok{  \}"}
\NormalTok{)}

\NormalTok{x <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{100}\NormalTok{), }\DecValTok{10}\NormalTok{)}

\KeywordTok{rowSums}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 487 421 508 527 643 568 519 488 462 427
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rowSumsC}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 487 421 508 527 643 568 519 488 462 427
\end{verbatim}

Let's look at the main differences:

\begin{itemize}
\tightlist
\item
  In C++, you subset a matrix with \texttt{()}, not \texttt{{[}{]}}.
\item
  In C++, use \texttt{.nrow()} and \texttt{.ncol()} methods to get the
  dimensions of a matrix.
\end{itemize}

\subsection{Matrix input and matrix
output}\label{matrix-input-and-matrix-output}

See the Rcpp exercise.

\section{Exercises}\label{exercises-9}

\textbf{Exercise Rcpp} Learning objectives: practice using \texttt{Rcpp}
to run a C++ function through R; use \texttt{microbenchmark()} to
compare function performance.

\chapter{Databases and R}\label{databases-and-r}

As we previously saw in Chapter \ref{data2}, \texttt{dplyr} is a
fantastic tool for manipulating data inside the R environment. Up to
this point, we have worked with data sets that easily fit within your
computer's memory. Is R capable of working with data sets that are too
large to store on your computer? Fortunately R is more than capable of
dealing with large data sets (or not so large data sets that are stored
remotely in a database). Recently, developers at \texttt{RStudio} have
been working on building tools for data scientists to use inside of R to
work with databases. Currently there are numerous different ways to work
with data from databases in R. In this chapter we will explore some of
the many different packages used to query external databases from within
R, and we will focus on using \texttt{dplyr} to perform our queries
solely in R.

\section{SQL and Database Structure}\label{sql-and-database-structure}

In today's world, there is an extremely large amount of electronic data.
The actual amount of existing data is not quite known, as it is pretty
much impossible to determine an exact amount. One estimate by IBM stated
that 2.5 exabytes (2.5 billion gigabytes) of data were generated every
day in 2012. Clearly, we need to have efficient ways to store such
incredibly large amounts of data inside computers. In many cases, these
data are stored in \emph{relational databases}.

In simple terms, a database is a collection of similar files. In a
relational database, there are numerous data-containing tables that are
related to each other by some common field, known as a \emph{key}. Each
table consists of numerous rows and columns, very similar to the way a
\texttt{tibble} or any other type of data frame is stored inside of R.
One can imagine a database consisting of student records with two
tables, one containing the address information of students (called
\texttt{address}), and one containing email information of the students
(called \texttt{email}). These two tables could perhaps be linked (or
\emph{joined}) together by a common field such as a student
identification number. Thus one could join together the two tables to
obtain email information and address information for any given student
at the same time.

Data analysts and data scientists require a method to do tasks like that
described above in databases. Fortunately, almost every relational
database is manipulated and stored using \texttt{SQL}, which makes such
queries possible.

\subsection{SQL}\label{sql}

SQL\footnote{The pronunciation of SQL is highly debated. I prefer to
  pronounce it like the word ``sequel'', but many others prefer to say
  it as ``ess-que-ell''. See
  \url{https://softwareengineering.stackexchange.com/questions/8588/whats-the-history-of-the-non-official-pronunciation-of-sql}
  for a good debate}, or Structured Query Language, is an incredibly
useful tool for querying and managing relational databases. SQL is
common to all major database management systems, such as Oracle,
MariaDB, PostgreSQL, MySQL, SQLite, and SQL Server. Each system has
slight differences in syntax for certain commands, but the overall basic
structure is the same across all database management systems. In order
to work with databases, at least a basic understanding of the SQL
language is desirable. Here we will give a \emph{brief} overview of the
main structure of a SQL query. If you have minimal SQL background and
desire to learn more about databases, we encourage you to use numerous
free online resources to help gain experience in using SQL. Some of my
favorites include tutorials from
\href{https://www.w3schools.com/sql/}{W3Schools},
\href{https://www.tutorialspoint.com/sql/index.htm}{tutorialspoint}, and
\href{http://www.sqltutorial.org/}{SQL Tutorial}. There are also
numerous free online courses available (i.e.~this
\href{https://lagunita.stanford.edu/courses/Engineering/db/2014_1/about}{Stanford}
course) that you can enroll in and gain experience in querying on sample
databases.

\subsubsection{A Basic Query}\label{a-basic-query}

Let's first explore a little bit of SQL syntax. A basic SQL query
consists of three different parts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{SELECT}: used to select data from a database
\item
  \texttt{FROM}: tells SQL what table to look at to get the data
\item
  \texttt{WHERE}: used to filter out different records
\end{enumerate}

Using these three statements you are able to perform queries on the
database to extract data from different tables. For example, consider
the database mentioned previously consisting of student records. To
obtain all the email addresses from the \texttt{email} table, our query
would look like this

\begin{verbatim}
SELECT email_address
FROM email
\end{verbatim}

If we only desired the email addresses of the student with
\texttt{id\ =\ 001}, then we would add a condition using the
\texttt{WHERE} clause:

\begin{verbatim}
SELECT email_address
FROM email
WHERE student_id = '001'
\end{verbatim}

Queries of this basic form are used by database programmers numerous
times a day in order to obtain needed information from large databases.
There are \emph{many} more features that can be added to this basic
query form, including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{AND}: added to the \texttt{WHERE} clause, allows for multiple
  conditions at once
\item
  \texttt{JOIN}: connect two tables based on a common feature
\item
  \texttt{GROUP\ BY}: group data together according to a certain field
  to obtain statistics, counts, etc.
\end{enumerate}

Does this remind you of anything we previously studied? Maybe something
in Chapter \ref{data2}? If so, you are correct! The manipulation of data
sets in R using \texttt{dplyr} provides many of the same sort of
manipulation tools used by SQL, and we will soon see how we can use
\texttt{dplyr} directly to query external databases.

\texttt{SQL} also has the ability to update the database, insert new
records, and delete records from the database. This is done using the
\texttt{UPDATE}, \texttt{INSERT}, and \texttt{DELETE} statements. Here
are some simple examples for each of these statements:

\begin{verbatim}
UPDATE email
SET email_address = 'doserjef@msu.edu'
WHERE student_id = '001'

DELETE FROM email
WHERE email_address = 'doserjef@msu.edu'

INSERT INTO email
VALUES ('001', 'doserjef@msu.edu')
\end{verbatim}

Again, this is nowhere near a full introduction to the SQL language, but
it will provide you with enough understanding to work with databases
within the R framework. If you are interested in databases, we encourage
you to seek out some of the additional resources mentioned at the
beginning of this section.

\section{Difficulties of Working with Large
Datasets}\label{difficulties-of-working-with-large-datasets}

The first step in using R with databases is to connect R to the
database. This leads to many difficulties. As described by Edgar Ruiz, a
solutions engineer at RStudio, when connecting to a database in R there
is only a ``small conduit'' between R and the database that often
prevents us from being able to work with the data as fast as we can work
with local data frames. In order to work around this there have
historically been two different options. The first option is to take
data from the database in small chunks, save it in R memory, and then
analyze it later. This is not desirable because you aren't dealing with
the data directly, so if the data in the database changes this will not
be reflected in the data previously loaded into your R memory. A
different option is to load \emph{all} of the data into R. This allows
you to see all of the data, but it takes forever to download and it
essentially takes over the R session (and it has the same problems as
option one regarding changes in the database).

The main problem with these methods is that they are trying to perform
the computations locally in R as opposed to performing computations
directly on the data in the database using the SQL Engine. Ideally, we
want to be able to analyze the data in place. In other words, we want R
to somehow send a SQL query over to the database, perform the query
using the powerful SQL engine, and then have the database send back an R
data frame that we can manipulate in R. This would allow us to avoid
performing computations directly in R, which would improve program speed
and reduce the amount of storage needed. In addition, we do not want to
go back and forth between using R and SQL, as this can cause a lot of
unnecessary confusion. As R programmers, we of course want to write
solely R code. Fortunately, researchers at RStudio have increased the
capabilities of the \texttt{dplyr} package to allow just that.

\section{\texorpdfstring{Using \texttt{dplyr} to Query the
Database}{Using dplyr to Query the Database}}\label{using-dplyr-to-query-the-database}

The \texttt{dplyr} package has recently been updated to allow for better
communications with external databases. Specifically, you, as the R
programmer, can write code in \texttt{dplyr} acting on a database in the
same manner in which you use \texttt{dplyr} to work with a data frame in
the R environment. \texttt{dplyr} will then behind the scenes convert
this R code into a SQL query, will send this query to the database, use
the SQL engine to run the query on the data, and will return these data
as a data frame in R.

This is the most efficient method for querying databases in R for three
reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We are pushing the computation to the database, allowing us to avoid
  bringing large amounts of data in the database into the R environment
  unless we specifically ask R to do it.
\item
  We can use piped code, which greatly enhances the readability of the
  code.
\item
  All the code is in R. This reduces the cognitive costs that are often
  associated when using two or more programming languages at the same
  time.
\end{enumerate}

Next we will go through an example using \texttt{SQLite} to detail
exactly how queries on a sample database are performed.

\subsection{Example with RSQLite}\label{example-with-rsqlite}

SQLite is arguably the most widely used relational database management
system throughout the world. We will first provide a demonstration using
a SQLite database as it is relatively easy to install on your system
compared to other database management systems. SQLite is different from
most database management systems because you don't have to set up a
separate database server. This makes SQLite great for a demo, and
surprisingly it can also be very powerful when working with many
gigabytes of data. We will use a sample database provided by SQLite
called \texttt{chinook} that contains data on store employees,
customers, and the music they purchased.

First, go to \url{http://www.sqlitetutorial.net/sqlite-sample-database/}
and download the \texttt{chinook} database into your R working directory
so you can follow along with this example yourself.

Upon successful download, the first step we need to do is install/load
the necessary packages for connecting to the external database. To help
\texttt{dplyr} communicate with the SQL engine, install the
\texttt{dbplyr} package using \texttt{install.packages("dbplyr")}. Next
we need the \texttt{RSQLite} package for interfacing with the SQLite
database. Install this by running \texttt{install.packages("RSQLite")}
in the R console. Then load the packages, along with \texttt{dplyr}:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dplyr)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dbplyr)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(RSQLite)}
\end{Highlighting}
\end{Shaded}

We next use the \texttt{DBI} package to connect directly to the
database. \texttt{DBI} is a backend package that provides a common
interface for R to work with many different database management systems
using the same code. This package does much of the communication from R
to the database that occurs behind the scenes, and is an essential part
of using \texttt{dplyr} to work with databases.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(DBI)}
\OperatorTok{>}\StringTok{ }\NormalTok{chinook <-}\StringTok{ }\KeywordTok{dbConnect}\NormalTok{(}\KeywordTok{SQLite}\NormalTok{(), }\StringTok{"chinook.db"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This command creates a reference to the database, and tells R to connect
to this database in a specific location (your location could change
depending on where you save the \texttt{chinook.db} file). A similar
approach could be used to connect to databases of other database
management systems like Oracle, MySQL, PostgreSQL, and others. Most
databases do not live in a file, but instead live on another server.
This causes the above connection to be much more complex, but for now we
will focus on this simple case.

Now lets look closer at the chinook database.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{src_dbi}\NormalTok{(chinook)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
src:  sqlite 3.22.0 [/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/chinook.db]
tbls: albums, artists, customers, employees, genres,
  invoice_items, invoices, media_types,
  playlist_track, playlists, sqlite_sequence,
  sqlite_stat1, tracks
\end{verbatim}

The above function displays the location of the database, as well as the
tables contained in the database. You can see in the \texttt{chinook}
database there are numerous tables regarding customers, employees, and
the music that customers purchased. In total, there are 13 tables
contained in this database.

Now that we know the structure of the database, we can perform some
simple queries on the data using \texttt{dplyr} syntax. For now, let's
focus on the \texttt{employees} table.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{employees <-}\StringTok{ }\KeywordTok{tbl}\NormalTok{(chinook, }\StringTok{"employees"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{employees}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:   table<employees> [?? x 15]
# Database: sqlite 3.22.0
#   [/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/chinook.db]
  EmployeeId LastName FirstName Title ReportsTo
       <int> <chr>    <chr>     <chr>     <int>
1          1 Adams    Andrew    Gene~        NA
2          2 Edwards  Nancy     Sale~         1
3          3 Peacock  Jane      Sale~         2
4          4 Park     Margaret  Sale~         2
5          5 Johnson  Steve     Sale~         2
6          6 Mitchell Michael   IT M~         1
7          7 King     Robert    IT S~         6
8          8 Callahan Laura     IT S~         6
# ... with 10 more variables: BirthDate <chr>,
#   HireDate <chr>, Address <chr>, City <chr>,
#   State <chr>, Country <chr>, PostalCode <chr>,
#   Phone <chr>, Fax <chr>, Email <chr>
\end{verbatim}

Notice how the \texttt{employees} table looks mostly like a regular
tibble, but has a couple added lines detailing its location as a remote
table in a SQLite database.

Now lets use familiar \texttt{dplyr} commands to perform queries on the
database

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{employees }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(LastName, FirstName, Phone, Email) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(LastName)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:     lazy query [?? x 4]
# Database:   sqlite 3.22.0
#   [/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/chinook.db]
# Ordered by: LastName
  LastName FirstName Phone          Email              
  <chr>    <chr>     <chr>          <chr>              
1 Adams    Andrew    +1 (780) 428-~ andrew@chinookcorp~
2 Callahan Laura     +1 (403) 467-~ laura@chinookcorp.~
3 Edwards  Nancy     +1 (403) 262-~ nancy@chinookcorp.~
4 Johnson  Steve     1 (780) 836-9~ steve@chinookcorp.~
5 King     Robert    +1 (403) 456-~ robert@chinookcorp~
6 Mitchell Michael   +1 (403) 246-~ michael@chinookcor~
7 Park     Margaret  +1 (403) 263-~ margaret@chinookco~
8 Peacock  Jane      +1 (403) 262-~ jane@chinookcorp.c~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{employees }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(Title }\OperatorTok{==}\StringTok{ "Sales Support Agent"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(LastName, FirstName, Address) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(LastName)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:     lazy query [?? x 3]
# Database:   sqlite 3.22.0
#   [/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/chinook.db]
# Ordered by: LastName
  LastName FirstName Address         
  <chr>    <chr>     <chr>           
1 Johnson  Steve     7727B 41 Ave    
2 Park     Margaret  683 10 Street SW
3 Peacock  Jane      1111 6 Ave SW   
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{employees }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(ReportsTo) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{numberAtLocation =} \KeywordTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:   lazy query [?? x 2]
# Database: sqlite 3.22.0
#   [/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/chinook.db]
  ReportsTo numberAtLocation
      <int>            <int>
1        NA                1
2         1                2
3         2                3
4         6                2
\end{verbatim}

You can see by using \texttt{dplyr} you are able to use the same syntax
to query the database as you used to analyze data frames in Chapter
\ref{data2}. The most important difference to again note is that when
working with remote databases the R code is translated into SQL and
executed in the database using the SQL engine, not in R. When doing
this, \texttt{dplyr} is as ``lazy'' as possible as it never pulls data
in R unless explicity asked. It collects everything you ask it to do and
then sends it to the database all in one step. This is often a very
useful feature when desiring to look at a certain group of records in a
database. To understand this further, take a look at the following code,
which at first you might think will output a \texttt{tibble} or
\texttt{data\ frame}:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{salesSupportAgents <-}\StringTok{ }\NormalTok{employees }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(Title }\OperatorTok{==}\StringTok{ "Sales Support Agent"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(LastName, FirstName, Address) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(LastName) }
\OperatorTok{>}\StringTok{ }\NormalTok{salesSupportAgents}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:     lazy query [?? x 3]
# Database:   sqlite 3.22.0
#   [/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/chinook.db]
# Ordered by: LastName
  LastName FirstName Address         
  <chr>    <chr>     <chr>           
1 Johnson  Steve     7727B 41 Ave    
2 Park     Margaret  683 10 Street SW
3 Peacock  Jane      1111 6 Ave SW   
\end{verbatim}

Notice the first two lines in the output. The source is described as a
\texttt{lazy\ query} and the \texttt{salesSupportAgents} is still a
database connection and not a local data frame. Because you did not
specifically tell R that you wanted to bring the data directly into R,
it did not do so. In order to bring the data directly into R in a local
tibble you need to use the \texttt{collect()} function. Note that if you
are asking the database to send back a lot of data, this could take a
while.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{salesSupportAgents <-}\StringTok{ }\NormalTok{employees }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(Title }\OperatorTok{==}\StringTok{ "Sales Support Agent"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(LastName, FirstName, Address) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(LastName) }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{collect}\NormalTok{()}
\OperatorTok{>}\StringTok{ }\NormalTok{salesSupportAgents}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 3
  LastName FirstName Address         
  <chr>    <chr>     <chr>           
1 Johnson  Steve     7727B 41 Ave    
2 Park     Margaret  683 10 Street SW
3 Peacock  Jane      1111 6 Ave SW   
\end{verbatim}

As we've seen, for simple tasks, and even many complex tasks,
\texttt{dplyr} syntax can be used to query external databases.

\subsection{\texorpdfstring{\texttt{dbplot}}{dbplot}}\label{dbplot}

If we can use \texttt{dplyr} to analyze the data in a database, you may
be wondering whether or not we can use \texttt{ggplot2} to graph the
data in the database. Of course we can! In fact, the package
\texttt{dbplot} is designed to process the calculations of a plot inside
a database and output a \texttt{ggplot2} object. If not already
installed on your system, make sure to install the \texttt{dbplot}
package before continuing.

We can use the same \texttt{chinook} database from SQLite we were using
above. Suppose we desire to see how many types of each employee there
are in the database. We can produce a barplot to show this.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dbplot)}
\OperatorTok{>}\StringTok{ }\NormalTok{employees }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{dbplot_bar}\NormalTok{(Title)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-316-1.pdf}

We first load the \texttt{dbplot} package. Next we produce the bar plot.
Notice that we can continue to use the convenient
\texttt{\%\textgreater{}\%} character while producing graphs using
\texttt{dbplot}, making the code easy to read. Since \texttt{dbplot}
outputs a \texttt{ggplot2} object, we can further customize the graph
using familiar functions from \texttt{ggplot2} (so long as the package
is loaded).

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(ggplot2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Attaching package: 'ggplot2'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:dplyr':

    vars
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{employees }\OperatorTok{%>%}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{dbplot_bar}\NormalTok{(Title) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Employee Types"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Count"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{theme_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-317-1.pdf}

\subsection{Using Google BigQuery}\label{using-google-bigquery}

For a second example, we will utilize a database from Google BigQuery,
Google's fully managed low cost analytics data warehouse. The package
\texttt{bigrquery} provides an R interface to Google BigQuery. If not
already installed, install the package with our usual method.

We will use data from a great set of sample tables that BigQuery
provides to its users. First we will look at the \texttt{shakespeare}
table that contains a word index of the different works of Shakespeare.
Thus, given the data in the table, let's use \texttt{bigrquery},
\texttt{DBI}, and \texttt{dplyr} to determine the ten words that appear
most often in Shakespeare's works.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(bigrquery)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(DBI)}
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dplyr)}
\OperatorTok{>}\StringTok{ }\NormalTok{billing <-}\StringTok{ "for875-databases"}
\OperatorTok{>}\StringTok{ }\NormalTok{con <-}\StringTok{ }\KeywordTok{dbConnect}\NormalTok{(}
\OperatorTok{+}\StringTok{   }\KeywordTok{bigquery}\NormalTok{(),}
\OperatorTok{+}\StringTok{   }\DataTypeTok{project =} \StringTok{"publicdata"}\NormalTok{,}
\OperatorTok{+}\StringTok{   }\DataTypeTok{dataset =} \StringTok{"samples"}\NormalTok{,}
\OperatorTok{+}\StringTok{   }\DataTypeTok{billing =}\NormalTok{ billing}
\OperatorTok{+}\StringTok{ }\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{shakespeare <-}\StringTok{ }\NormalTok{con }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{tbl}\NormalTok{(}\StringTok{"shakespeare"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Auto-refreshing stale OAuth token.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{shakespeare }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(word) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{sum}\NormalTok{(word_count, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(n)) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:     lazy query [?? x 2]
# Database:   BigQueryConnection
# Ordered by: desc(n)
   word      n
   <chr> <int>
 1 the   25568
 2 I     21028
 3 and   19649
 4 to    17361
 5 of    16438
 6 a     13409
 7 you   12527
 8 my    11291
 9 in    10589
10 is     8735
\end{verbatim}

First we load the neceessary packages. We then provide the name of our
project to the \texttt{billing} variable. In this case, I created a
project called \texttt{for875-databases} for this course. The
\texttt{con} variable establishes the connection to the database and the
data that we want to look at. Notice the difference in connecting to the
Google BigQuery database, which is stored remotely on Google's servers,
as compared to the previous example when connecting to a SQLite database
stored on your computer's hard drive. This example is much more
realistic of the connections you would make when accessing external
databases. The \texttt{bigquery()} statement tells DBI we will be
working with a database from Google BigQuery. The project and dataset
options tell DBI what database to look for inside of the Google BigQuery
framework. We then supply the name of our project to the
\texttt{billing} option to tell BigQuery what account to ``bill'' (this
only costs money if you surpass the monthly limit given by Google).

If you run this code by yourself, you'll notice that R will ask you to
sign in to a google account (your MSU account), and then after you allow
the \texttt{bigrquery} package to connect to your account, you will be
able to run all the code without a problem.

From here we can establish a connection to a specific table by using the
\texttt{tbl()} function as shown above. We can then use \texttt{dplyr}
like we did previously to group the data by words, determine the count
of each word, and then order it in decreasing order to obtain the top
ten words in Shakespeare's works. Notice that when you run this code you
may obtain a message in red describing the total amount of bytes billed.
This is how Google manages how much its users are querying and using its
data. We're just tinkering around here, so we won't surpass the monthly
limit on free queries.

This code again displays the benefits of the ``lazy evaluation'' that R
employs. The \texttt{con} variable and \texttt{shakespeare} variable do
not store the database or the specific table in R itself, instead they
serve as references to the database where the specific data they are
referencing is contained. Only when the \texttt{dplyr} query is written
and called using the \texttt{collect()} function is any data from the
database actually brought into R. R waits till the last possible second
(i.e.~is lazy) to perform any computations.

A second table in the \texttt{publicdata} project on Google BigQuery
contains weather data from NOAA ranging from the years 1929 to 2010.
Let's first make a connection to this table and explore its structure.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weather <-}\StringTok{ }\NormalTok{con }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{tbl}\NormalTok{(}\StringTok{"gsod"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{dbListFields}\NormalTok{(con, }\StringTok{"gsod"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "station_number"                    
 [2] "wban_number"                       
 [3] "year"                              
 [4] "month"                             
 [5] "day"                               
 [6] "mean_temp"                         
 [7] "num_mean_temp_samples"             
 [8] "mean_dew_point"                    
 [9] "num_mean_dew_point_samples"        
[10] "mean_sealevel_pressure"            
[11] "num_mean_sealevel_pressure_samples"
[12] "mean_station_pressure"             
[13] "num_mean_station_pressure_samples" 
[14] "mean_visibility"                   
[15] "num_mean_visibility_samples"       
[16] "mean_wind_speed"                   
[17] "num_mean_wind_speed_samples"       
[18] "max_sustained_wind_speed"          
[19] "max_gust_wind_speed"               
[20] "max_temperature"                   
[21] "max_temperature_explicit"          
[22] "min_temperature"                   
[23] "min_temperature_explicit"          
[24] "total_precipitation"               
[25] "snow_depth"                        
[26] "fog"                               
[27] "rain"                              
[28] "snow"                              
[29] "hail"                              
[30] "thunder"                           
[31] "tornado"                           
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weather }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{select}\NormalTok{(thunder, mean_wind_speed) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:   lazy query [?? x 2]
# Database: BigQueryConnection
   thunder mean_wind_speed
   <lgl>             <dbl>
 1 FALSE              7   
 2 FALSE             14.5 
 3 FALSE             28.7 
 4 FALSE             15.5 
 5 FALSE              0   
 6 FALSE             15   
 7 FALSE             15   
 8 FALSE             21   
 9 FALSE              8.90
10 TRUE              13   
\end{verbatim}

First we establish a connection to the weather table. We then use the
\texttt{dbListFields()} function from the \texttt{DBI} package to
display the fields in the table. We then view the first 10 records in
the table. We see that there are 31 different variables on information
for the weather on a given day from 1929 to 2010. Let's say we are
interested in determining the total number of days where the
\texttt{mean\_temp\ \textgreater{}\ 60} and
\texttt{mean\_wind\_speed\ \textgreater{}\ 10}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weather }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(mean_temp }\OperatorTok{>}\StringTok{ }\DecValTok{60} \OperatorTok{&}\StringTok{ }\NormalTok{mean_wind_speed }\OperatorTok{>}\StringTok{ }\DecValTok{10}\NormalTok{) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{count =} \KeywordTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:   lazy query [?? x 1]
# Database: BigQueryConnection
    count
    <int>
1 6581146
\end{verbatim}

Further, suppose we are interested in determining how the average wind
speed has changed from 1929 to 2010. We can use \texttt{dbplot} to plot
the data.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weather }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{dbplot_line}\NormalTok{(year, }\DataTypeTok{average_wind_speed =} \KeywordTok{mean}\NormalTok{(mean_wind_speed, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-322-1.pdf}

Upon first glance at this plot, a naive student might think ``Wow! Wind
speeds have decreased dramatically since the 1930s'', and just accept
this as true since that is what the graph shows. But since we are all
data analysts at heart (otherwise you wouldn't be taking this course!),
we want to explore this further. We might ask why the wind was so high
in the late 1920s and early 1930s? An average wind speed of above 12
miles per hour seems pretty high. Let's explore the entries for all
years in the 1930s and 1920s by looking at how many records there are
with a mean wind speed for each year before 1940.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{weather }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{<}\StringTok{ }\DecValTok{1940} \OperatorTok{&}\StringTok{ }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(mean_wind_speed)) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}
\OperatorTok{+}\StringTok{   }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{count =} \KeywordTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Source:   lazy query [?? x 2]
# Database: BigQueryConnection
    year count
   <int> <int>
 1  1929  2037
 2  1930  7101
 3  1933 17708
 4  1938 51770
 5  1936 50514
 6  1937 83310
 7  1932 10751
 8  1931  9726
 9  1934 20334
10  1935 26829
# ... with more rows
\end{verbatim}

Interesting! We see that there are only 2037 records from 1929, while
there are 65623 records from 1939. This suggests we could be
experiencing a phenomenon known as \emph{sampling bias} in which the
2037 records from 1929 are not a valid random representation of all the
wind speeds occurring in 1929. Or potentially the wind was just much
higher during that time due to other factors we aren't exploring here.
Determining the true cause of this pattern requires further
investigation, which we leave to you if you so desire.

\section{Changing Records in the
Database}\label{changing-records-in-the-database}

\texttt{dplyr} is fantastic for retrieving data from databases and
analyzing it using familiar functions. As detailed in this
\href{https://www.rstudio.com/resources/videos/best-practices-for-working-with-databases-webinar/}{video},
using \texttt{dplyr} is considered a ``best practice'' when using
databases in R because you only have to use one language, you don't need
to know any SQL, and you can use the lazy evaluation of R, among many
other reasons. As a data analyst, a majority of work can be accomplished
by using \texttt{dplyr} and other forms of queries against a database.
But what if you need to do more than query the data in the database and
you have to change some of the records? \texttt{dplyr} is not capable of
inserting or deleting records in a database, and although updating
recordings is possible with \texttt{dplyr}, Hadley Wickham strongly
recommends against it, as \texttt{dplyr} is designed specifically for
retrieving data. Thus, we need to use other options for
updating/inserting/deleting records in a database. Unlike using
\texttt{dplyr} this requires a more in depth knowledge of SQL. We will
not discuss updating/inserting/deleting records in a database here, but
you will briefly learn about methods to do this in this chapter's
exercise.

\section{R Studio Connections Pane}\label{r-studio-connections-pane}

If by this point in the book you haven't already been convinced that
RStudio is a fantastic IDE for running R then perhaps this will convince
you. R Studio has a Connections Pane by default in the top right corner
of your screen that makes it easy to connect to a variety of data
sources, and better yet, explore the objects and data inside the
connection. You can use it with a variety of different packages for
working with databases in R, and it will also work with a variety of
databases and other datasources (i.e.~Spark). This Connections Pane is a
great way of exploring the data in a data source once you are connected.
If interested, the page
\href{https://db.rstudio.com/rstudio/connections/}{here} which provides
an overview of the connections pane and some other useful links of
potential interest.

\section{Further Resources}\label{further-resources}

There are numerous other methods besides \texttt{dplyr} to work with
databases in R that involve using more standard SQL queries. If you come
from a SQL background and want to use these other methods, then explore
the \href{http://db.rstudio.com/}{RStudio Databases using R page}. This
website will be an essential resource for you if you get more involved
with using databases within the R environment.

\section{Exercises}\label{exercises-10}

\textbf{Exercise Databases} Learning objectives: connect to an external
database; perform simple queries using \texttt{dplyr}; use data from a
database in a Shiny app; learn how to perform changes
(update/delete/insert) on a database

\chapter{Digital Signal Processing}\label{digital-signal-processing}

Signals are everywhere. And no, that is not an exaggeration. In today's
technology age, signals really are pervasive throughout most of the
world. Humans and animals use audio signals to convey important
information to conspecifics. Airplanes use signals in the air to obtain
important information to ensure your safety on a flight. Cell phones are
pretty much just one small digital signal processing device. They
process our speech when we talk into the phone by removing background
noise and echos that would distort the clearness of our sound. They
obtain wifi signals to allow for us to search the web. They send text
messages using signals. They use digital image processing to take really
good pictures. They take a video of your dog when he's doing something
completely hilarious that you want to show your friend. The applications
of digital signal processing (DSP) span numerous different fields, such
as ecology, physics, communication, medicine, computer science,
mathematics, and electrical engineering. Thus, having a basic
understanding of DSP and it's concepts can be very helpful, regardless
of the field you decide to pursue.

In this chapter we will give a brief introduction to some central
concepts in DSP and how we can explore these concepts using R. We will
look at applications of DSP using some R packages designed for
bioacoustic analysis. When doing digital signal processing, R is not
typically the first computer language that comes to mind.
\texttt{Matlab}, \texttt{Octave}, and \texttt{C/C++} are often
considered to be some of the best languages for DSP. But R provides
numerous different packages (especially for working with audio data)
that make it competitive with these languages for digital signal
processing. We will use the \texttt{signal} package to do some simple
digital signal processing, and then will use the \texttt{tuneR},
\texttt{warbleR}, and \texttt{seewave} packages to work with audio data
to show you more specific examples of how R can be used in different
fields of digital signal processing.

\section{Introduction to Digital Signal
Processing}\label{introduction-to-digital-signal-processing}

First let's go over some basics of DSP before we delve into working with
signals in R. \emph{Digital Signal Processing} is the use of digital
tools to perform different signal processing operations, such as the
analysis, synthesis, and modification of signals. But what exactly
constitutes a signal? A \emph{signal} is anything that carries
information. In other words, it is a quantity that varies with time,
temperature, pressure, or any other independent variable. As described
above, signals pervade our everyday life, and thus the study of their
behavior, how they work, how we can manipulate them, and how we can
extract information from them is extremely important.

There are two main types of signals: continuous time signals and
discrete time signals. \emph{Continuous Time Signals}, as you might
suspect, are continuous. They are defined at all instances of time over
a given period. These types of signals are commonly referred to as
\emph{analog} signals. An example of an analog signal would be a simple
sine curve plotted in \ref{fig:analogsignal}. Notice that the sine curve
is defined for every value on the interval from 0 to 2\(\pi\). This is
an analog signal.

\begin{figure}
\centering
\includegraphics{bookdown_files/figure-latex/analogsignal-1.pdf}
\caption{\label{fig:analogsignal}Example of an analog signal: a simple sine
curve}
\end{figure}

\emph{Discrete Time Signals} are not continuous. They are defined only
at discrete times, and thus they are represented as a sequence of
numbers (so by your experiences in R working with sequences of numbers
you should already have an idea of how discrete signals are stored, how
they can be manipulated, etc\ldots{}). Figure @ref(fig:digital\} is an
example of the exact same sine curve as in Figure
@ref\{fig:analogsignal\}, but in a discrete form. Notice how there are
only values at specific points, and anywhere besides those points the
signal is not defined. In a real-world application, these points would
correspond to measurements of the signal.

\begin{figure}
\centering
\includegraphics{bookdown_files/figure-latex/digital-1.pdf}
\caption{\label{fig:digital}Example of a discrete signal: a sine curve with
some missing values}
\end{figure}

Notice the differences between the two graphs. The second graph is not
defined at every point and is only defined at the points where a data
point exists. This type of sampling will become important later in the
chapter and in the exercise when we begin to work with sound data (which
by the way takes the form of these simple sine curves we are working
with here). There are many other shapes and forms of signals, but since
we will later be focusing on audio data, and the sine curve is
fundamental to any sort of sound, we for now will focus on working with
a sine curve.

Signals have a wide variety of properties and characteristics that give
each signal distinct behavior. The sine curve has two important
characteristics. First, a sine curve is said to be \texttt{odd} since it
satisfies the condition sin\((-t)\) = -sin\((t)\). This is easy to
recognize by looking at the graph of a sine curve as you see that it is
symmetrical over the diagonal at the origin. In addition, a sine curve
is a \emph{periodic} signal. A periodic signal is a signal that repeats
itself after a certain interval of time (called the Period). This is
true of all real sine curves. Understanding the simple properties of
signals like we have done with the sine curve is a useful tool in
digital signal processing as it allows you to recognize simple patterns
that may occur with the signal in which you are interested.

Now that we have a general understanding of what a signal is and how we
can use it's properties to learn about it's behavior, let's now focus on
some of the most important concepts in digital signal processing, and
how we can implement them in R. Here are three of the most central
topics to DSP:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Fourier Transforms}: signal processing involves looking at the
  frequency representation of signals for both insight and computations.
\item
  \textbf{Noise}: defined as any signal that is not desired. A huge part
  of signal processing is understanding how noise is affecting your data
  and how you can efficiently remove or manage it.
\item
  \textbf{Filters}: allow you to remove out specific portions of a
  signal at once, or allow you to remove noise from certain signals.
\end{enumerate}

We will first briefly discuss working with noise and filters in R, and
then we will work with Fourier Transforms in the context of audio data.

\subsection{Sinusoidal Signals}\label{sinusoidal-signals}

As mentioned previously, sinusoidal signals are extremely important for
signal processing. We saw an example of a continuous sinusoid and a
discrete sinusoid. Here we will quickly discuss the mathematics behind
coding a sinuosoid signal.

A sine wave typically takes the following form:

\[
f(\theta) = (\alpha) \text{sin}(b(\theta - c)) + d
\]

The translations that you see above from the standard sine wave
(sin(\(\theta\))) have particular terms. Here we give a quick summary of
the terms in the above equation and their definitions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Period}: the amount of time required to complete one full
  cycle of the sine wave. A standard sine wave has period \(2\pi\). The
  sine wave described above has period \(\frac{2\pi}{|b|}\)
\item
  \textbf{Frequency}: the number of times a sine wave repeats itself
  within a single unit of time (which depends upon how the variable
  \(\theta\) is defined). This is the reciprocal of the period so in our
  case this is \(\frac{|b|}{2\pi}\).
\item
  \textbf{Amplitude}: the ``height'' of the sine wave, or more properly,
  the distance from the x-axis to the most positive point of the sine
  wave. The standard sine wave has an amplitude of 1. The amplitude is
  controlled by the \(\alpha\) parameter, and thus our sine wave has
  amplitude \(\alpha\).
\item
  \textbf{Phase Shift}: determines whether or not the sine wave passes
  through the point (0, 0). Our sine wave mentioned above is shifted to
  the right by the amount \(c\) and shifted up by \(d\).
\end{enumerate}

Next we draw a few plots to show graphically how all these parameters
influence the signal. We will graph these as digital signals.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dplyr)}
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{pi, .}\DecValTok{1}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{standard <-}\StringTok{ }\KeywordTok{sin}\NormalTok{(x)}
\OperatorTok{>}\StringTok{ }\NormalTok{altered <-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\KeywordTok{sin}\NormalTok{(}\DecValTok{3} \OperatorTok{*}\StringTok{ }\NormalTok{(x }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)) }\OperatorTok{+}\StringTok{ }\DecValTok{4}
\OperatorTok{>}\StringTok{ }\NormalTok{graphData <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(x, standard, altered)}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ graphData, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ standard, }\DataTypeTok{color =} \StringTok{"sin(x)"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ altered, }\DataTypeTok{color =} \StringTok{"2*sin(3 * (x - 1)) + 4"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{scale_color_manual}\NormalTok{(}\StringTok{""}\NormalTok{, }\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\StringTok{"sin(x)"}\NormalTok{, }\StringTok{"2*sin(3 * (x - 1)) + 4"}\NormalTok{), }
\OperatorTok{+}\StringTok{                      }\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"x"}\NormalTok{, }\DataTypeTok{y =}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-324-1.pdf}

Now that we understand the fundamentals of sinusoids, let's see how we
can work with noise and filters on sinusoids using R.

\section{Noise and Filters}\label{noise-and-filters}

Using filters to remove noise and obtain only the desired portions of
signals is a huge part of signal processing. Here we will give a couple
examples of the \emph{many} different functions available in the
\texttt{signal} package for DSP. The \texttt{signal} package is a set of
signal processing functions that was originally written for more
``standard'' signal processing languages, Matlab and Octave, but was
later translated into R. It provides an extensive set of functions
including filtering functions, resampling routines, and interpolation
functions. To follow along yourself, install the package with
\texttt{install.packages("signal")}.

For a first example, consider the sinusoid generated below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(signal)}
\OperatorTok{>}\StringTok{ }\NormalTok{t <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DataTypeTok{len =} \DecValTok{100}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{sig <-}\StringTok{ }\KeywordTok{sin}\NormalTok{(}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{pi }\OperatorTok{*}\StringTok{ }\NormalTok{t)}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(t, sig)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-325-1.pdf}

This is a simple sinusoid that has an amplitude of 1 and a frequency of
1. It is not likely that when obtaining a real-world signal you would
get a perfect sinusoid without any noise. Let's take this graph and add
some noise to it.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{noisySig <-}\StringTok{ }\KeywordTok{sin}\NormalTok{(}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{pi }\OperatorTok{*}\StringTok{ }\NormalTok{t) }\OperatorTok{+}\StringTok{ }\FloatTok{0.25} \OperatorTok{*}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\KeywordTok{length}\NormalTok{(t))}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(t, noisySig), }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-326-1.pdf}

We add noise to the function by adding a random value
(\texttt{0.25*rnorm(length(t)}) to each value in the signal. This is
more typical of a real-world signal, as you can somewhat see the general
shape (the signal you are interested in), but it is somewhat distorted
as a result of noise. The \texttt{signal} package provides a long list
of functions for filtering out noise. Here we will utilize the
\texttt{butter} function to remove the noise from this signal in an
attempt to obtain our original signal. This function generates a
variable containing the Butterworth filter polynomial coefficients. The
Butterworth filter is a good all-around filter that is often used in
radio frequency filter applications. We then use the \texttt{filter}
function from the \texttt{signal} package to apply the Butterworth
filter to the data. Finally we produce a plot using \texttt{ggplot2}
that shows the original signal without noise, the noisy signal, and the
recovered signal.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(dplyr)}
\OperatorTok{>}\StringTok{ }\NormalTok{butterFilter <-}\StringTok{ }\KeywordTok{butter}\NormalTok{(}\DecValTok{3}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{recoveredSig <-}\StringTok{ }\NormalTok{signal}\OperatorTok{::}\KeywordTok{filter}\NormalTok{(butterFilter, noisySig)}
\OperatorTok{>}\StringTok{ }\NormalTok{allSignals <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(t, sig, noisySig, recoveredSig)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: `data_frame()` is deprecated, use `tibble()`.
This warning is displayed once per session.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(allSignals, }\KeywordTok{aes}\NormalTok{(t)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ sig, }\DataTypeTok{color =} \StringTok{"Original"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ noisySig, }\DataTypeTok{color =} \StringTok{"Noisy"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ recoveredSig, }\DataTypeTok{color =} \StringTok{"Recovered"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Signal"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-327-1.pdf}

You can see that the recovered signal is not perfect, as there is still
some noise in the signal, and the timing of the peaks in the signal is
not exactly matched up with the original. But it is clear that we have
nonetheless removed a large portion of the noise from the noisy signal.
Mess around with the argument values in the \texttt{butter()} function
in the above code. See what changing the parameters does to the
recovered graph. You can also explore the wide variety of filter
functions available in the \texttt{signal} package by exploring the
package documentation
\href{https://cran.r-project.org/web/packages/signal/signal.pdf}{here}.

For a second example, suppose we are interested in not only the signal,
but also the noise. We will extract the low and high frequencies from a
sample signal. Let's start with a noisy signal

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{t <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{500}
\OperatorTok{>}\StringTok{ }\NormalTok{cleanSignal <-}\StringTok{ }\DecValTok{50} \OperatorTok{*}\StringTok{ }\KeywordTok{sin}\NormalTok{(t }\OperatorTok{*}\StringTok{ }\DecValTok{4} \OperatorTok{*}\StringTok{ }\NormalTok{pi}\OperatorTok{/}\KeywordTok{length}\NormalTok{(t))}
\OperatorTok{>}\StringTok{ }\NormalTok{noise <-}\StringTok{ }\DecValTok{50} \OperatorTok{*}\StringTok{ }\DecValTok{1}\OperatorTok{/}\DecValTok{12} \OperatorTok{*}\StringTok{ }\KeywordTok{sin}\NormalTok{(t }\OperatorTok{*}\StringTok{ }\DecValTok{4} \OperatorTok{*}\StringTok{ }\NormalTok{pi}\OperatorTok{/}\KeywordTok{length}\NormalTok{(t) }\OperatorTok{*}\StringTok{ }\DecValTok{12}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{originalSignal <-}\StringTok{ }\NormalTok{cleanSignal }\OperatorTok{+}\StringTok{ }\NormalTok{noise}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(t, originalSignal))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-328-1.pdf}

Again, you can easily recognize the pattern is sinusoidal, but there is
noise in the signal that you want to extract. Perhaps you are interested
in where the noise is coming from and want to analyze the structure of
the noise to figure this out. Thus, unlike the previous example, we want
to extract the noise from the signal and not simply eliminate it. To do
this we can again use the Butterworth filter.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{lowButter <-}\StringTok{ }\KeywordTok{butter}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\OperatorTok{/}\DecValTok{50}\NormalTok{, }\DataTypeTok{type =} \StringTok{"low"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{low <-}\StringTok{ }\NormalTok{signal}\OperatorTok{::}\KeywordTok{filter}\NormalTok{(lowButter, originalSignal)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{highButter <-}\StringTok{ }\KeywordTok{butter}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\OperatorTok{/}\DecValTok{25}\NormalTok{, }\DataTypeTok{type =} \StringTok{"high"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{high <-}\StringTok{ }\NormalTok{signal}\OperatorTok{::}\KeywordTok{filter}\NormalTok{(highButter, originalSignal)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\NormalTok{signals <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(originalSignal, low, high)}
\OperatorTok{>}\StringTok{ }
\ErrorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(signals, }\KeywordTok{aes}\NormalTok{(t)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ originalSignal, }\DataTypeTok{color =} \StringTok{"Original"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ low, }\DataTypeTok{color =} \StringTok{"Signal"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ high, }\DataTypeTok{color =} \StringTok{"Noise"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\OperatorTok{+}\StringTok{   }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Time"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Signal"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-329-1.pdf}

\section{Fourier Transforms and
Spectrograms}\label{fourier-transforms-and-spectrograms}

When working with signals you often have to consider whether or not you
need to work in the \emph{time domain} or the \emph{frequency domain}.
These two different domains can provide valuable information about a
signal. The most popular way to explore signals in the frequency domain
is to use Fourier Transforms. A \emph{Fourier Transform} is a reversible
mathematical transform developed by Joseph Fourier in the early 1800s.
The transform breaks apart a time series into a sum of finite series of
sine or cosine functions. This was a huge break through of it's time, as
Fourier argues that any signal can be broken down into a series of sine
and cosine curves. This was a fantastic development and is still one of
the most widely used tools in digital signal processing, which tells you
how useful it truly is (and how brilliant Fourier was).

The Discrete Fourier Transform (DFT) is a specific form of the Fourier
Transform applied to a time wave. The DFT allows you to switch from
working in the time domain to the frequency domain by using the
amplitude and the frequency of the signal to build the frequency
spectrum of the original time wave.

To apply Fourier Transforms we use a window size. The length of the FT
is controlled by the \emph{window length}. Increasing the window size
will increase frequency resolution, but this will also make the
transform less accurate in terms of time as more signal will be selected
for the transform. Thus there is a constant level of uncertainty between
the time of the signal and the frequency of the signal\footnote{this is
  a result of the common \emph{Heisenberg Uncertainty Principle}}.
Different windows can be used in a DFT depending on the application.
There are numerous windows available within the \texttt{seewave} package
(see Figure \ref{fig:filters}).

\begin{figure}
\centering
\includegraphics{bookdown_files/figure-latex/filters-1.pdf}
\caption{\label{fig:filters}Different available filters within the seewave
package}
\end{figure}

Computing a fourier transform on a whole sound or a single segment of
the sound may not be enough information for what you desire. One great
idea is to compute the DFT on successive sections along the entire sound
signal. A window is ``slided'' along the signal and a DFT is computed at
each of these slides. This process is called a \emph{Short-Time Fourier
Transform}. This method allows you to represent the signals in the
frequency spectrum, while also maintaining most of the information from
the time dimension (as Hannah Montana might say, it's the
\href{https://www.youtube.com/watch?v=uVjRe8QXFHY}{best of both
worlds}).

We can plot the results of an STFT in what is called a
\emph{spectrogram}. The spectogram is so useful in bioacoustics,
acoustics, and ecoacoustics (among others) because it allows you to
represent three variables in a 2D plot, which avoids using a 3D
representation that is genereally not appealing. The successive DFT are
plotted against time with the relative amplitude of each sine function
of each DFT represented by some color scale. In other words, the
spectrogram has an x-axis of time, a y-axis of frequency, and the
amplitude represented by the color scheme used inside the plot (which is
usually included in a scale).

Let's use a sample audio file provided by the \texttt{seewave} package
and produce a spectrogram of it using the \texttt{spectro} function. R
provides multiple functions like \texttt{spectro} that make the creation
of spectrograms and Fourier Transforms extremely easy and logical, which
is one of the many reasons to perform digital signal processing within
the R environment.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(seewave)}
\OperatorTok{>}\StringTok{ }\KeywordTok{data}\NormalTok{(tico)}
\OperatorTok{>}\StringTok{ }\KeywordTok{spectro}\NormalTok{(tico)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=1\linewidth]{bookdown_files/figure-latex/unnamed-chunk-330-1}

Let's explore more of the parameters for this function to get a better
understanding of how it is working. Type in \texttt{?spectro} in the R
console. The \texttt{spectro()} function contains a lot of different
arguments that allow you to control how the spectrogram is created. The
\texttt{f} argument allows you to specify the sampling rate of your
sound object. The \texttt{wl} option allows you to control the window
length that is used when the successive DFTs are produced (aka the
STFT). You can choose which window you want to use with the \texttt{wn}
option. You can also specify the amount of \texttt{ovlp} between two
successive windows with the \texttt{ovlp} argument. Let's use some of
these arguments and compare it to the standard spectrogram we previously
produced.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{spectro}\NormalTok{(tico, }\DataTypeTok{f =} \DecValTok{22050}\NormalTok{, }\DataTypeTok{wl =} \DecValTok{1024}\NormalTok{, }\DataTypeTok{wn =} \StringTok{"bartlett"}\NormalTok{, }\DataTypeTok{ovlp =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=1\linewidth]{bookdown_files/figure-latex/unnamed-chunk-331-1}

You can immediately see that there are some slight differences between
the spectrograms. The first spectrogram appears to be more precise than
the first spectrogram. Explore these parameters yourself to get a better
understanding of how these different properties impact the short-time
fourier transform and the spectrogram.

One cool thing about the \texttt{spectro()} function is that it produces
a graph, but it also stores the values along the three scales. If you
save the call to a \texttt{spectro()} function, that variable will be a
list containing the values along the time axis, values along the
frequency axis, and the amplitude values of the FFT decompositions.
These values can be accessed in familiar ways (\texttt{\$time},
\texttt{\$frequency}, \texttt{\$amp}).

Now that you have a visualization of the sound, we will use the
\texttt{tuneR} package to play the sound so you can see exactly how it
matches up with the spectrogram. First install the \texttt{tuneR}
package, which is another package great for working with sound and
signals in R. Then use the \texttt{play} function to play back the
\texttt{tico} sound. Note that the second argument in the \texttt{play}
function is the \texttt{player} argument, which may or may not need to
be defined depending on your operating system and what audio players are
installed on your system. In my case, I am playing the sound through the
\texttt{aplay} player on a machine running Linux.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(tuneR)}
\OperatorTok{>}\StringTok{ }\KeywordTok{play}\NormalTok{(tico, }\StringTok{"aplay"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The audio matches up perfectly with the spectrogram. Pretty cool!

\section{\texorpdfstring{Analyzing Audio Data with
\texttt{warbleR}}{Analyzing Audio Data with warbleR}}\label{analyzing-audio-data-with-warbler}

Now that we've explored how we visualize audio signals with Fourier
Transforms and spectrograms, let's now explore some of the packages in R
used explicitly for bioacoustic analysis of audio signals. The
\texttt{warbleR} package was written to streamline bioacoustic research
inside of R, and it provides numerous different functions for obtaining,
manipulating, and visualizing bioacoustic data (and especially
bioacoustic data of birds). We are going to go through an example to
display some of the many useful functions in the \texttt{warbleR}
package. Our goal is to analyze the recordings of Cedar Waxwings from
the xeno-canto database to determine whether or not there is variation
in these calls across large geographical distances. Along the way we
will showcase many useful functions in the \texttt{warbleR} package, and
will compute numerous meausures that give us useful information about
the signal. Let's get started!

First off, create a new directory where you want to store the data and
change the working directory to that folder. We will produce a lot of
files in the following exercise, so it is best to use a new directory to
maintain organization. Here is the directory we use, you should change
yours accordingly:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{setwd}\NormalTok{(}\StringTok{"/home/jeffdoser/Dropbox/teaching/for875/for875-19/bookdown-crc-master/"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We will extract sounds from a large and very common database in the
field of bioacoustics, xeno-canto. \texttt{warbleR} allows you to easily
query the database and work with the sounds maintained in their library.
We are interested in the sounds of Cedar Waxwings, which just so happen
to be my favorite species of bird. They are small, beautiful, majestic
birds that are fairly common in rural and suburban areas (Figure
\ref{fig:waxwing}). They also have a very large geographical region,
spanning across all three countries in North America (no wall can stop
Cedar Waxwings from crossing the border).

The \texttt{warbleR} package allows us to first query the database for
the recordings of Cedar Waxwings (\emph{Bombycilla cedrorum}) without
downloading them.

\begin{figure}
\includegraphics[width=1\linewidth]{figures/cedarWaxwing} \caption{Two cedar waxwings, possibly pondering whether or not Ross and Rachel will ever get back together (oh wait no that's me as I write this chapter between binge watching Friends)}\label{fig:waxwing}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(warbleR)}
\OperatorTok{>}\StringTok{ }\NormalTok{cedarWax <-}\StringTok{ }\KeywordTok{quer_xc}\NormalTok{(}\DataTypeTok{qword =} \StringTok{"Bombycilla cedrorum"}\NormalTok{,}
\OperatorTok{+}\StringTok{                     }\DataTypeTok{download =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
114 recordings found!
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(cedarWax)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "Recording_ID"      "Genus"            
 [3] "Specific_epithet"  "Subspecies"       
 [5] "English_name"      "Recordist"        
 [7] "Country"           "Locality"         
 [9] "Latitude"          "Longitude"        
[11] "Vocalization_type" "Audio_file"       
[13] "License"           "Url"              
[15] "Quality"           "Time"             
[17] "Date"             
\end{verbatim}

We use the \texttt{quer\_xc} function to query the database, and use the
restriction of the scientific name for Cedar Waxwings so we only obtain
recordings of our desired species. We see that this returns a data frame
with a lot of useful information, such as the latitude and longitude of
the recording, the date, the quality of the recording, and the type of
vocalization (since birds have multiple different types of
vocalizations).

Now we produce a map showing the locations of all of the recordings. The
\texttt{xc\_maps} function allows you to either save a map as an image
to your hard drive, or you can simply load the image in the R
environment. We will load the image in the R environment by setting the
\texttt{img} argument to \texttt{FALSE}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{xc_maps}\NormalTok{(}\DataTypeTok{X =}\NormalTok{ cedarWax, }\DataTypeTok{img =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The recordings are mostly in the United States, but you can see there
are recordings in Mexico and Canada as well. Now that we have an idea of
where these recordings were taken, let's look at what types of
recordings we have. We will do this using the \texttt{table()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{table}\NormalTok{(cedarWax}\OperatorTok{$}\NormalTok{Vocalization_type)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

                                   call, song 
                                            5 
                                  flight call 
                                            7 
                                         song 
                                            4 
                            call, flight call 
                                            7 
                                         call 
                                           64 
                       begging call, juvenile 
                                            3 
                                   alarm call 
                                            2 
alarm call, call, flight call, juvenile, song 
                                            1 
                                  Flight Call 
                                            1 
                                    call, dog 
                                            1 
                      call, song, wing sounds 
                                            1 
                            call, flock calls 
                                           10 
                                         Call 
                                            2 
                               Calls of flock 
                                            1 
                               juvenile calls 
                                            1 
                           call, female, male 
                                            1 
                                Feeding calls 
                                            1 
                      call, flight call, song 
                                            1 
                                  Flight call 
                                            1 
\end{verbatim}

Look closely at the output from this function. This is a great example
of the messiness of real-world data. Users from around the world input
their data into this website, and this results in many different ways of
describing the vocalizations produced by the birds. You can see the
users used many different ways to describe the calls of cedar waxwings.
There are 64 recordings labeled as ``call'' so we will just focus on
these recordings, but keep in mind that in a more serious study, we may
want to manipulate the labels and combine vocalizations that are
actually of the same type.

Now that we have the recordings we want to work with, we download them
and convert them to wav files. Since this is only an example, we will
look specifically at six of the calls within the \texttt{cedarWax}
recordings to minimize downloading and computation time.\footnote{Sound
  files are pretty large so working with these files using the warbleR
  package can be time consuming.}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{newCedarWax <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(cedarWax, cedarWax}\OperatorTok{$}\NormalTok{Recording_ID }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{313682}\NormalTok{, }\DecValTok{313683}\NormalTok{, }\DecValTok{313684}\NormalTok{, }\DecValTok{321881}\NormalTok{, }\DecValTok{329907}\NormalTok{, }\DecValTok{361006}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{quer_xc}\NormalTok{(}\DataTypeTok{X =}\NormalTok{ newCedarWax)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Downloading files...
double-checking downloaded files
\end{verbatim}

\texttt{warbleR} and \texttt{seewave} are designed to work with wav
files while the xeno-canto database stores its recordings as mp3 files.
Luckily there is a very simple function \texttt{mp32wav} that converts
all the mp3 files in the working directory to wav files. We then remove
all the mp3 files from the current directory using the \texttt{system}
function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{mp32wav}\NormalTok{()}
\OperatorTok{>}\StringTok{ }\KeywordTok{system}\NormalTok{(}\StringTok{"rm *.mp3"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\texttt{warbleR} gives us many easy ways to produce spectrograms for all
of our desired sound files at once. To do this, we use the
\texttt{lspec} function, which produces image files with spectrograms of
whole sound files split into multiple rows.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{lspec}\NormalTok{(}\DataTypeTok{ovlp =} \DecValTok{10}\NormalTok{, }\DataTypeTok{it =} \StringTok{"tiff"}\NormalTok{, }\DataTypeTok{rows =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now look in your current directory and you should see .tiff files for
all of the sound files. These files could be used to visually inspect
sound files and eliminate undesired files as a result of noise, length,
or other variables you are not interested in. But for this example we
will use all six recordings.

Remember that our ultimate goal is to determine whether or not Cedar
Waxwing calls show some sort of variation across geographical distance.
We need to produce some acoustic measures to compare the different
recordings. First, we want to perform \emph{signal detection}. In other
words, we want to find the exact parts in the recordings where a cedar
waxwing is performing its call. We only want to determine the acoustic
parameters during these times, as this will eliminate noise from having
any impact on the parameters. We can perform signal detection using the
\texttt{autodetec} function. This function automatically detects the
start and end of vocalizations based on amplitude, duration, and
frequency range attributes. In addition, \texttt{autodetec} has two
types of output:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A data frame containing the recording name, selection, start time, and
  end time.
\item
  A spectrogram for each recording with red lines showing the beginning
  and end of the signal.
\end{enumerate}

\texttt{autodetec} has a TON of parameters that you can use to help
specify exactly what type of signal you are looking for in your data. To
help us figure out what parameters we want to use, let's first look at
an example spectrogram of one of the recordings (Figure
\ref{fig:spectrogram}).

\begin{figure}
\includegraphics[width=18.89in]{figures/sampleSpectrogram} \caption{Example spectrogram of Cedar Waxwing calls}\label{fig:spectrogram}
\end{figure}

The calls appear to be between 4-10 kHz in frequency. In this sample
they are quite short, with none lasting longer than a second and most
being less than half a second. Let's try these two parameters along with
a few others and see what we get. Let's first do this on just one of the
recordings so we don't waste computing power if we have to change our
parameters

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{wavs <-}\StringTok{ }\KeywordTok{list.files}\NormalTok{(}\DataTypeTok{pattern =} \StringTok{".wav"}\NormalTok{, }\DataTypeTok{ignore.case =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{subset <-}\StringTok{ }\NormalTok{wavs[}\DecValTok{2}\NormalTok{]}
\OperatorTok{>}\StringTok{ }\KeywordTok{autodetec}\NormalTok{(}\DataTypeTok{flist =}\NormalTok{ subset, }\DataTypeTok{bp =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{10}\NormalTok{), }\DataTypeTok{threshold =} \DecValTok{10}\NormalTok{, }\DataTypeTok{mindur =} \FloatTok{0.05}\NormalTok{, }
\OperatorTok{+}\StringTok{           }\DataTypeTok{maxdur =} \FloatTok{0.5}\NormalTok{,}\DataTypeTok{ssmooth =} \DecValTok{800}\NormalTok{, }\DataTypeTok{ls =} \OtherTok{TRUE}\NormalTok{, }
\OperatorTok{+}\StringTok{           }\DataTypeTok{res =} \DecValTok{100}\NormalTok{, }\DataTypeTok{flim =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{12}\NormalTok{), }\DataTypeTok{wl =} \DecValTok{300}\NormalTok{, }\DataTypeTok{set =}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sxrow =} \DecValTok{6}\NormalTok{, }
\OperatorTok{+}\StringTok{           }\DataTypeTok{rows =} \DecValTok{5}\NormalTok{, }\DataTypeTok{redo =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{it =} \StringTok{"jpeg"}\NormalTok{, }\DataTypeTok{img =}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{smadj =} \StringTok{"end"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Detecting signals in sound files:Producing long spectrogram:
\end{verbatim}

\begin{verbatim}
                     sound.files selec  start    end
1 Bombycilla-cedrorum-313683.wav     1 0.6379 0.8424
2 Bombycilla-cedrorum-313683.wav     2 1.8631 1.9641
3 Bombycilla-cedrorum-313683.wav     3 1.9784 2.1559
4 Bombycilla-cedrorum-313683.wav     4 3.9281 4.3652
5 Bombycilla-cedrorum-313683.wav     5 5.8650 6.2886
6 Bombycilla-cedrorum-313683.wav     6 8.7235 9.0295
7 Bombycilla-cedrorum-313683.wav     7 9.1184 9.4517
\end{verbatim}

Here is a list of the parameters and what each means:

\begin{itemize}
\tightlist
\item
  \texttt{flist}: character vector indicating the subset of files to be
  analyzed
\item
  \texttt{bp}: numeric vector of length two giving the lower and upper
  bounds of a frequency bandpass filter in kHz
\item
  \texttt{threshold}: specifies the amplitude threshold for detecting
  signals in percentage
\item
  \texttt{mindur}, \texttt{maxdur}: specify the minimum call length and
  maximum call length respectively
\item
  \texttt{ssmooth}: a numeric vector of length 1 to smooth the amplitude
  envelope with a sum smooth function
\end{itemize}

The rest of the parameters above are controlling the output image. We
have attached the output image below.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{include_graphics}\NormalTok{(}\StringTok{"figures/sampleAutodetec.jpg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=18.89in]{figures/sampleAutodetec} \caption{Example output of autodetec function}\label{fig:autodetec}
\end{figure}

Well it looks like we've done a pretty good job! There are a couple
signals we are not detecting, but we are not getting any false positives
(detecting signals that aren't actually signals) so we will continue on
with these parameters (feel free to refine them as much as you want).
Let's run the \texttt{autodetec} function for all the recordings and
save it as a variable. Notice that we switched the \texttt{img} argument
to \texttt{FALSE} since we don't need to produce an image for every
recording. In addition, we remove all null values as this would
correspond to the rare situation in which the \texttt{autodetec}
function does not detect a signal in a sound file

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{waxwingSignals <-}\StringTok{ }\KeywordTok{autodetec}\NormalTok{(}\DataTypeTok{flist =}\NormalTok{ wavs, }\DataTypeTok{bp =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{10}\NormalTok{), }\DataTypeTok{threshold =} \DecValTok{10}\NormalTok{, }\DataTypeTok{mindur =} \FloatTok{0.05}\NormalTok{, }
\OperatorTok{+}\StringTok{           }\DataTypeTok{maxdur =} \FloatTok{0.5}\NormalTok{,}\DataTypeTok{ssmooth =} \DecValTok{800}\NormalTok{, }\DataTypeTok{ls =} \OtherTok{TRUE}\NormalTok{, }
\OperatorTok{+}\StringTok{           }\DataTypeTok{res =} \DecValTok{100}\NormalTok{, }\DataTypeTok{flim =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{12}\NormalTok{), }\DataTypeTok{set =}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sxrow =} \DecValTok{6}\NormalTok{, }
\OperatorTok{+}\StringTok{           }\DataTypeTok{rows =} \DecValTok{15}\NormalTok{, }\DataTypeTok{redo =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{it =} \StringTok{"tiff"}\NormalTok{, }\DataTypeTok{img =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{smadj =} \StringTok{"end"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Detecting signals in sound files:
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{waxwingSignals[}\KeywordTok{is.na}\NormalTok{(waxwingSignals)] <-}\StringTok{ }\DecValTok{0}
\end{Highlighting}
\end{Shaded}

Now that we have the locations of all the signals in the recordings, we
can begin to compute acoustic parameters. The \texttt{warbleR} package
provides the fantastic \texttt{specan} function that allows us to
calculate 22 acoustic parameters at once through a batch process. This
is much more efficient than computing all these parameters separately.
\texttt{specan} uses the time coordinates from the \texttt{autodetec}
function that we saved in our \texttt{waxwingSignals} variable. It then
computes these acoustic parameters for the recordings, but only during
the times when a signal is being performed.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{params <-}\StringTok{ }\KeywordTok{specan}\NormalTok{(waxwingSignals, }\DataTypeTok{bp =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{15}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(params)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "sound.files" "selec"       "duration"   
 [4] "meanfreq"    "sd"          "freq.median"
 [7] "freq.Q25"    "freq.Q75"    "freq.IQR"   
[10] "time.median" "time.Q25"    "time.Q75"   
[13] "time.IQR"    "skew"        "kurt"       
[16] "sp.ent"      "time.ent"    "entropy"    
[19] "sfm"         "meandom"     "mindom"     
[22] "maxdom"      "dfrange"     "modindx"    
[25] "startdom"    "enddom"      "dfslope"    
[28] "meanpeakf"  
\end{verbatim}

You can see from the \texttt{names} function that there are a wide
variety of measures computed for each sound file. Now that we have all
these measurements, let's use them to determine whether there is any
geographic variation in these cedar waxwing calls. The first step in
doing this is joining the geographic location for each recording to the
\texttt{params} data frame. The geographic location is contained within
the \texttt{cedarWax} data frame. We will first join these tables based
on the recording ID.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{params}\OperatorTok{$}\NormalTok{Recording_ID <-}\StringTok{ }\KeywordTok{gsub}\NormalTok{(}\StringTok{'.*-([0-9]+).*'}\NormalTok{,}\StringTok{'}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{1'}\NormalTok{, params}\OperatorTok{$}\NormalTok{sound.files)}
\OperatorTok{>}\StringTok{ }\NormalTok{newCedarWax}\OperatorTok{$}\NormalTok{Recording_ID <-}\StringTok{ }\KeywordTok{as.character}\NormalTok{(newCedarWax}\OperatorTok{$}\NormalTok{Recording_ID)}
\OperatorTok{>}\StringTok{ }\NormalTok{finalData <-}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(params, newCedarWax)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Joining, by = "Recording_ID"
\end{verbatim}

We will do this using a process called Principal Components Analysis, a
statistical dimension reduction technique that can be used to find
latent variables that explain large amounts of variation in a data set.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\CommentTok{# Remove the non-numeric variables and then run the pca}
\ErrorTok{>}\StringTok{ }\NormalTok{pca <-}\StringTok{ }\KeywordTok{prcomp}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ finalData[, }\KeywordTok{sapply}\NormalTok{(finalData, is.numeric)], }\DataTypeTok{scale. =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{score <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(pca[[}\DecValTok{5}\NormalTok{]])}
\OperatorTok{>}\StringTok{ }\NormalTok{ID <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(finalData}\OperatorTok{$}\NormalTok{Recording_ID)}
\OperatorTok{>}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ score, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(PC1, PC2)) }\OperatorTok{+}
\OperatorTok{+}\StringTok{   }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ finalData}\OperatorTok{$}\NormalTok{Recording_ID, }\DataTypeTok{shape =}\NormalTok{ finalData}\OperatorTok{$}\NormalTok{Country)) }
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-344-1.pdf}

From the graph, we see that two birds from the US form a group with a
bird from Mexico, and a bird from the US forms a group with two birds
from Canada. Depending on where exactly the birds from the US are
located, this could potentially suggest some variation across
geographical distance. We leave this to you to explore further if you so
desire. But for now, we see that the \texttt{warbleR} package has some
fantastic tools for manipulating and working with audio signals within
the R environment.

\section{Exercises}\label{exercises-11}

\textbf{Exercise DSP} Learning objectives: download, manipulate, and
play sound files using R, produce spectrograms of audio files, use
filters, use acoustic indices to analyze western New York soundscape
data\}

\chapter{\texorpdfstring{Graphics in R Part 2:
\texttt{graphics}}{Graphics in R Part 2: graphics}}\label{graphics}

\section{Scatter Plots}\label{scatter-plots-1}

Begin by considering a simple and classic data set sometimes called
\emph{Fisher's Iris Data}. These data are available in R.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{data}\NormalTok{(iris)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

The data contain measurements on petal and sepal length and width for
\texttt{dim(iris){[}1{]}} iris plants. The plants are from one of three
species, and the species information is also included in the data frame.
The data are commonly used to test classification methods, where the
goal would be to correctly determine the species based on the four
length and width measurements. To get a preliminary sense of how this
might work, we can draw some scatter plots of length versus width. In
\texttt{graphics}, making scatter plots is simple:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-347-1.pdf}

We see the \texttt{plot()} function by default creates a basic
scatterplot when we supply the function with values for the \texttt{x}
and \texttt{y} arguments.

Looking at the scatter plot and thinking about the focus of finding a
method to classify the species, two thoughts come to mind. First, the
plot might be improved by shading in the points. And second, using
different colors for the points corresponding to the three species would
help.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }\DataTypeTok{col =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Species)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-348-1.pdf}

The \texttt{pch\ =} argument is used to control the type of symbol used
to represent the data points. \texttt{pch\ =\ 19} specifies a filled in
circle for each data point. You can mess around with different numbers
and you'll see a wide variety of options. The
\texttt{col\ =\ iris\$Species} argument tells the \texttt{plot()}
function to assign a different color to each unique value in the the
\texttt{iris\$Species} vector.\footnote{To see the order in which R
  assigns colors to different values, run the \texttt{palette()}
  function} Notice however that there is no legend produced by default,
so we don't know which color represents each species. We can add a
legend using the \texttt{legend()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }\DataTypeTok{col =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Species)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \FloatTok{6.4}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species), }
\OperatorTok{+}\StringTok{        }\DataTypeTok{col =} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)), }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-349-1.pdf}

Let's walk through the additional complexities one at a time:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{x\ =\ 6.4,\ y\ =\ 4.4} specifies the location where the legend
  is drawn. Here I place it in a location where the box will not cover
  up any data points.
\item
  \texttt{legend\ =\ levels(iris\$Species)} specifies the names of the
  different categories that will appear in the legend.
\item
  \texttt{col\ =\ 1:length(levels(iris\$Species))} specifies the number
  of colors that are represented in the function. In this case, we use
  \texttt{length(levels(iris\$Species))} to get the number of unique
  species in the data set, which turns out to be 3.
\item
  \texttt{pch\ =\ 19} specifies the type of symbol to include in the
  legend.
\end{enumerate}

It may seem like there are a lot of arguments to specify to produce a
legend and a simple scatter plot, but this also means we have a lot of
control over the graph, which is very useful when you are trying to
develop a publication-quality figure for your own work.

Now perhaps we want to use different shapes as well for the different
species. To do this we assign different values for the \texttt{pch}
argument to each species, and subsequently change the \texttt{pch}
argument in the legend as well.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width, }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{)[iris}\OperatorTok{$}\NormalTok{Species], }\DataTypeTok{col =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Species)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \FloatTok{6.4}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species), }
\OperatorTok{+}\StringTok{        }\DataTypeTok{col =} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)), }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-350-1.pdf}

\subsection{Adding lines to a scatter
plot}\label{adding-lines-to-a-scatter-plot-1}

Next let's add a fitted least squares line to the scatter plot. This can
be done pretty easily using the \texttt{abline()} function to add a
straight ine to the curve, and the \texttt{lm()} function to actually
compute the least squares line

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width, }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{)[iris}\OperatorTok{$}\NormalTok{Species], }\DataTypeTok{col =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Species)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \FloatTok{6.4}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species), }
\OperatorTok{+}\StringTok{        }\DataTypeTok{col =} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)), }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{abline}\NormalTok{(}\KeywordTok{lm}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Sepal.Width }\OperatorTok{~}\StringTok{ }\NormalTok{iris}\OperatorTok{$}\NormalTok{Sepal.Length))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-351-1.pdf}

For the iris data, it probably makes more sense to fit separate lines by
species. Below we compute the linear model separately for each species,
then use the \texttt{abline()} function to add each line to the graph.
Note our use of logical subsetting to obtain separate data frames for
each species.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{iris.setosa <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "setosa"}\NormalTok{, ]}
\OperatorTok{>}\StringTok{ }\NormalTok{iris.versicolor <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "versicolor"}\NormalTok{, ]}
\OperatorTok{>}\StringTok{ }\NormalTok{iris.virginica <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{, ]}
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width, }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{)[iris}\OperatorTok{$}\NormalTok{Species], }\DataTypeTok{col =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Species)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \FloatTok{6.4}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species), }
\OperatorTok{+}\StringTok{        }\DataTypeTok{col =} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)), }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{abline}\NormalTok{(}\KeywordTok{lm}\NormalTok{(iris.setosa}\OperatorTok{$}\NormalTok{Sepal.Width }\OperatorTok{~}\StringTok{ }\NormalTok{iris.setosa}\OperatorTok{$}\NormalTok{Sepal.Length), }\DataTypeTok{col =} \DecValTok{1}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{abline}\NormalTok{(}\KeywordTok{lm}\NormalTok{(iris.versicolor}\OperatorTok{$}\NormalTok{Sepal.Width }\OperatorTok{~}\StringTok{ }\NormalTok{iris.versicolor}\OperatorTok{$}\NormalTok{Sepal.Length), }\DataTypeTok{col =} \DecValTok{2}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{abline}\NormalTok{(}\KeywordTok{lm}\NormalTok{(iris.virginica}\OperatorTok{$}\NormalTok{Sepal.Width }\OperatorTok{~}\StringTok{ }\NormalTok{iris.virginica}\OperatorTok{$}\NormalTok{Sepal.Length), }\DataTypeTok{col =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-352-1.pdf}

Note that we could also do this using a \texttt{for} loop, which you
will learn about soon in Chapter \ref{functions}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{iris.setosa <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "setosa"}\NormalTok{, ]}
\OperatorTok{>}\StringTok{ }\NormalTok{iris.versicolor <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "versicolor"}\NormalTok{, ]}
\OperatorTok{>}\StringTok{ }\NormalTok{iris.virginica <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{, ]}
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width, }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{)[iris}\OperatorTok{$}\NormalTok{Species], }\DataTypeTok{col =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Species)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \FloatTok{6.4}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species), }
\OperatorTok{+}\StringTok{        }\DataTypeTok{col =} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)), }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species))) \{}
\OperatorTok{+}\StringTok{   }\NormalTok{curr.species <-}\StringTok{ }\NormalTok{iris[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ }\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)[i], ]}
\OperatorTok{+}\StringTok{   }\KeywordTok{abline}\NormalTok{(}\KeywordTok{lm}\NormalTok{(curr.species}\OperatorTok{$}\NormalTok{Sepal.Width }\OperatorTok{~}\StringTok{ }\NormalTok{curr.species}\OperatorTok{$}\NormalTok{Sepal.Length), }\DataTypeTok{col =}\NormalTok{ i)}
\OperatorTok{+}\StringTok{ }\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-353-1.pdf}

Another common use of line segments in a graphic is to connect the
points in order. Although it is not clear why this helps in
understanding the iris data, the technique is illustrated next. First we
connect all lines regardless of species. This is done easily by
specifying the argument
\texttt{type\ =\ \textquotesingle{}b\textquotesingle{}} in the
\texttt{plot()} function\footnote{The ``b'' stands for ``both''. By
  default, the \texttt{type} argument is set to ``p'' for ``points''.
  You can also specify that you only want lines using
  \texttt{type\ =\ \textquotesingle{}l\textquotesingle{}}.}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length, }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width, }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{)[iris}\OperatorTok{$}\NormalTok{Species], }\DataTypeTok{col =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Species, }\DataTypeTok{type =} \StringTok{'b'}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \FloatTok{6.4}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species), }
\OperatorTok{+}\StringTok{        }\DataTypeTok{col =} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)), }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-354-1.pdf}

Now we attempt to only connect the points within a given species. Doing
this requires the use of the \texttt{lines()} function to draw three
separate lines for each species\footnote{Note that we could again
  perhaps simplify this by using a \texttt{for} loop, but we'll restrain
  ourselves until we learn about \texttt{for} loops in Chapter
  \ref{functions}.} First we create a plot for the first species, and
then subsequently use the \texttt{lines()} function to add each of the
remaining two species to the plot. Notice that there are some additional
arguments in the original \texttt{plot()} function that we have yet to
cover. Don't worry, we'll talk about all this fun stuff in the next
section :)

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "setosa"}\NormalTok{], }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "setosa"}\NormalTok{], }\DataTypeTok{pch =} \DecValTok{17}\NormalTok{, }\DataTypeTok{col =} \DecValTok{1}\NormalTok{, }\DataTypeTok{type =} \StringTok{'b'}\NormalTok{, }\DataTypeTok{xlim =} \KeywordTok{range}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Sepal.Length), }\DataTypeTok{ylim =} \KeywordTok{range}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Sepal.Width), }\DataTypeTok{xlab =} \StringTok{"Sepal Length"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Sepal Width"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{lines}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "versicolor"}\NormalTok{], }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "versicolor"}\NormalTok{], }\DataTypeTok{pch =} \DecValTok{18}\NormalTok{, }\DataTypeTok{col =} \DecValTok{2}\NormalTok{, }\DataTypeTok{type =} \StringTok{'b'}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{lines}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Length[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{], }\DataTypeTok{y =}\NormalTok{ iris}\OperatorTok{$}\NormalTok{Sepal.Width[iris}\OperatorTok{$}\NormalTok{Species }\OperatorTok{==}\StringTok{ "virginica"}\NormalTok{], }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }\DataTypeTok{col =} \DecValTok{3}\NormalTok{, }\DataTypeTok{type =} \StringTok{'b'}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \FloatTok{6.4}\NormalTok{, }\DataTypeTok{y =} \FloatTok{4.4}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species), }
\OperatorTok{+}\StringTok{        }\DataTypeTok{col =} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{levels}\NormalTok{(iris}\OperatorTok{$}\NormalTok{Species)), }\DataTypeTok{pch =} \KeywordTok{c}\NormalTok{(}\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-355-1.pdf}

\section{Labels, Axes, Text, etc.}\label{labels-axes-text-etc.-1}

The default settings of \texttt{graphics} often produce useful graphics,
but once a graphic is chosen for dissemination, the user will likely
want to customize things like the title, axes, etc. In this section some
tools for customization are presented. Most will be illustrated in the
context of a data set on crime rates in the 50 states in the United
States. These data were made available by Nathan Yau at
\url{http://flowingdata.com/2010/11/23/how-to-make-bubble-charts/}. The
data include crime rates per 100,000 people for various crimes such as
murder and robbery, and also include each state's population. The crime
rates are from the year 2005, while the population numbers are from the
year 2008, but the difference in population between the years is not
great, and the exact population is not particularly important for what
we'll do below.

First, read in the data, examine its structure, and produce a simple
scatter plot of motor vehicle theft versus burglary.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.crime <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/crimeRatesByState2005.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{crime <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.crime, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{str}\NormalTok{(crime)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'data.frame':   50 obs. of  9 variables:
 $ state              : Factor w/ 50 levels "Alabama ","Alaska ",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ murder             : num  8.2 4.8 7.5 6.7 6.9 3.7 2.9 4.4 5 6.2 ...
 $ Forcible_rate      : num  34.3 81.1 33.8 42.9 26 43.4 20 44.7 37.1 23.6 ...
 $ Robbery            : num  141.4 80.9 144.4 91.1 176.1 ...
 $ aggravated_assult  : num  248 465 327 387 317 ...
 $ burglary           : num  954 622 948 1085 693 ...
 $ larceny_theft      : num  2650 2599 2965 2711 1916 ...
 $ motor_vehicle_theft: num  288 391 924 262 713 ...
 $ population         : int  4627851 686293 6500180 2855390 36756666 4861515 3501252 873092 18328340 9685744 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary, crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-356-1.pdf}

\subsection{Labels}\label{labels-1}

By default, axis labels are the values of the \texttt{x} and \texttt{y}
values you supply to the \texttt{plot()} function. For making a
publication-quality figure, we often want to further customize these
labels, as well as potentially add a title to the graph. We can do this
using the \texttt{xlab}, \texttt{ylab}, and \texttt{main} arguments in
the \texttt{plot()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary, crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{xlab =} \StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylab =} \StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{main =} \StringTok{"Burglaries vs motor vehicle theft for US states"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-357-1.pdf}

Perhaps it may be easier to read the values on the y-axis if they were
oritented horizontally instead of vertically. We can do this using the
\texttt{las\ =\ 1} argument.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary, crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{xlab =} \StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylab =} \StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{main =} \StringTok{"Burglaries vs motor vehicle theft for US states"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{las =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-358-1.pdf}

\section{Customizing Axes}\label{customizing-axes-1}

The basic \texttt{plot()} function provides defaults for the axis
limits, as well as for other axis features (i.e., the box around the
plot). These, and other axis features such as tick marks, labels, and
transformations, can all be customized. First, we use the \texttt{xlim}
and \texttt{ylim} arguments to make the x and y axes start at zero and
go to the maxium x and y values.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary, crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{xlab =} \StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylab =} \StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{main =} \StringTok{"Burglaries vs motor vehicle theft for US states"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary)), }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-359-1.pdf}

Now we eliminate the axes and box automatically drawn by the
\texttt{plot()} function, and subsequently add our own axes using the
\texttt{axis()} function. We use most of the defaults provided by the
\texttt{axis()} function, however, looking at the help page for
\texttt{axis()} reveals a large amount of possibilities for customizing
the axes in whatever way you desire.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary, crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{xlab =} \StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylab =} \StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{main =} \StringTok{"Burglaries vs motor vehicle theft for US states"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{axes =} \OtherTok{FALSE}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary)), }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft)))}
\OperatorTok{>}\StringTok{ }\KeywordTok{axis}\NormalTok{(}\DataTypeTok{side =} \DecValTok{1}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{axis}\NormalTok{(}\DataTypeTok{side =} \DecValTok{2}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-360-1.pdf}

\subsection{Text, Point Size, and
Color}\label{text-point-size-and-color-1}

Next we make point size proportional to population, change the color,
and add a state label. First we make point size proportional to
population size using the \texttt{symbols()} function. We can control
the color of the points using the \texttt{bg} argument in the
\texttt{symbols()} function. We then use the \texttt{text()} function to
add labels to each point.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{symbols}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary, crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{xlab =} \StringTok{"Burglaries per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylab =} \StringTok{"Motor vehicle theft per 100,000 population"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{main =} \StringTok{"Burglaries vs motor vehicle theft for US states"}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary)), }
\OperatorTok{+}\StringTok{      }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{max}\NormalTok{(crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft)), }
\OperatorTok{+}\StringTok{      }\DataTypeTok{circles =}\NormalTok{ crime}\OperatorTok{$}\NormalTok{population, }
\OperatorTok{+}\StringTok{      }\DataTypeTok{inches =} \DecValTok{1}\OperatorTok{/}\DecValTok{5}\NormalTok{, }\DataTypeTok{axes =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{bg=}\StringTok{"steelblue2"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{axis}\NormalTok{(}\DataTypeTok{side =} \DecValTok{1}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{axis}\NormalTok{(}\DataTypeTok{side =} \DecValTok{2}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{text}\NormalTok{(crime}\OperatorTok{$}\NormalTok{burglary, crime}\OperatorTok{$}\NormalTok{motor_vehicle_theft, }\DataTypeTok{labels=}\NormalTok{crime}\OperatorTok{$}\NormalTok{state, }\DataTypeTok{cex=}\FloatTok{0.9}\NormalTok{, }\DataTypeTok{font=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-361-1.pdf}

This graph is mind-numbingly busy, and is missing some notable things
(i.e.~legend). For now, we leave it up to you to add in a legend, make
the graph less cluttered, fix the cutoff labels, etc. if you so desire.

You run an experiment to see if the number of alcoholic beverages a
person has on average every day is related to weight. You collect 15
data points. Enter these data in R by creating vectors, and then
reproduce the following plot.

\begin{tabular}{rr}
\toprule
\# of Drinks & Weight\\
\midrule
1.0 & 150\\
3.0 & 350\\
2.0 & 200\\
0.5 & 140\\
2.0 & 200\\
\addlinespace
1.0 & 160\\
0.0 & 175\\
0.0 & 140\\
0.0 & 167\\
1.0 & 200\\
\addlinespace
4.0 & 300\\
5.0 & 321\\
2.0 & 250\\
0.5 & 187\\
1.0 & 190\\
\bottomrule
\end{tabular}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-363-1.pdf}

\section{Other Types of Graphics}\label{other-types-of-graphics-1}

Scatter and line plots, which have just been presented, are common but
certainly not the only graphical displays in common use. Histograms,
boxplots, and bar graphs, as well as more ``mathematical'' displays such
as the graph of a function, are commonly used to represent data.
Examples of each are presented below.

\subsection{Histograms}\label{histograms-1}

Simon Newcomb conducted several experiments to estimate the speed of
light by measuring the time it took for light to travel from his
laboratory to a mirror at the base of the Washington Monument, and then
back to his lab. This is a distance of \(7.44373\) km, and by dividing
this distance by the measured time, an estimate for the speed of light
is obtained.

The times are of course quite small, and to avoid working with very
small numbers, the data are recoded to be the deviation from \(24800\)
nanoseconds. For example an observation coded as \(28\) represents a
time of \(24828\) nanoseconds, while an observation coded as \(-44\)
represents a time of \(24756\) nanoseconds.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.newcomb <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/Newcomb.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{Newcomb <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.newcomb, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(Newcomb)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Time
1   28
2   26
3   33
4   24
5   34
6  -44
\end{verbatim}

To produce a simple histogram of these data in the \texttt{graphics}
package, we can use the simple \texttt{hist()} function.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{hist}\NormalTok{(Newcomb}\OperatorTok{$}\NormalTok{Time)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-365-1.pdf}

The function automatically specifies the binwidths for the data, however
we can easily change this ourselves to something more suitable using the
\texttt{breaks} argument. We also change the axis labels, y-axis label
orientation, title, and color of the bins.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{hist}\NormalTok{(Newcomb}\OperatorTok{$}\NormalTok{Time, }\DataTypeTok{breaks =} \DecValTok{30}\NormalTok{, }\DataTypeTok{main =} \StringTok{"Histogram"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Time"}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{col =} \StringTok{'blue'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-366-1.pdf}

\subsection{Boxplots}\label{boxplots-1}

Next we consider some data from the gap minder data set to construct
some box plots. These data are available in the \texttt{gapminder}
package, which might need to be installed via
\texttt{install.packages("gapminder")}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{library}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Attaching package: 'gapminder'
\end{verbatim}

\begin{verbatim}
The following object is masked _by_ '.GlobalEnv':

    gapminder
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{boxplot}\NormalTok{(gdpPercap }\OperatorTok{~}\StringTok{ }\NormalTok{continent, }\DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(gapminder, year }\OperatorTok{==}\StringTok{ }\DecValTok{2002}\NormalTok{), }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }\DataTypeTok{col =} \StringTok{'lightblue'}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Continent"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"GDP Per-capita"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-367-1.pdf}

Here's the same set of boxplots, but with different colors and the boxes
plotted horizontally rather than vertically

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{boxplot}\NormalTok{(gdpPercap }\OperatorTok{~}\StringTok{ }\NormalTok{continent, }\DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(gapminder, year }\OperatorTok{==}\StringTok{ }\DecValTok{2002}\NormalTok{), }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }\DataTypeTok{border =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{col =} \StringTok{'lightblue'}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"GDP Per-Capita"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Continent"}\NormalTok{, }\DataTypeTok{horizontal =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-368-1.pdf}

However, notice in the last two graphs the y-axis labels were running
off the page. Using the \texttt{graphics} package, we have the ability
to adjust all the dimensions and parameters of a plot by using the
\texttt{par} function. Below we utilize the \texttt{par} function to
extend the amount of space in the plot on the left side of the graph.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar=}\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\OperatorTok{>}\StringTok{ }\KeywordTok{boxplot}\NormalTok{(gdpPercap }\OperatorTok{~}\StringTok{ }\NormalTok{continent, }\DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(gapminder, year }\OperatorTok{==}\StringTok{ }\DecValTok{2002}\NormalTok{), }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }\DataTypeTok{border =} \StringTok{'red'}\NormalTok{, }\DataTypeTok{col =} \StringTok{'lightblue'}\NormalTok{, }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"GDP Per-Capita"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Continent"}\NormalTok{, }\DataTypeTok{horizontal =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-369-1.pdf}

\subsection{Bar Graphs}\label{bar-graphs-1}

As part of a study, elementary school students were asked which was more
important to them: good grades, popularity, or athletic ability. Here is
a brief look at the data.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{u.goals <-}\StringTok{ "http://blue.for.msu.edu/FOR875/data/StudentGoals.csv"}
\OperatorTok{>}\StringTok{ }\NormalTok{StudentGoals <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(u.goals, }\DataTypeTok{header=}\OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{head}\NormalTok{(StudentGoals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Gender Grade Age  Race  Type School   Goals Grades
1    boy     5  11 White Rural    Elm  Sports      1
2    boy     5  10 White Rural    Elm Popular      2
3   girl     5  11 White Rural    Elm Popular      4
4   girl     5  11 White Rural    Elm Popular      2
5   girl     5  10 White Rural    Elm Popular      4
6   girl     5  11 White Rural    Elm Popular      4
  Sports Looks Money
1      2     4     3
2      1     4     3
3      3     1     2
4      3     4     1
5      2     1     3
6      2     1     3
\end{verbatim}

First, a simple bar graph of the most important goal chosen is drawn,
followed by a stacked bar graph which also includes the student's
gender. We then add a side by side bar graph that includes the student's
gender.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{counts <-}\StringTok{ }\KeywordTok{table}\NormalTok{(StudentGoals}\OperatorTok{$}\NormalTok{Goals)}
\OperatorTok{>}\StringTok{ }\NormalTok{counts}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

 Grades Popular  Sports 
    247     141      90 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{barplot}\NormalTok{(counts)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-371-1.pdf}

Notice that to create a basic bar graph using the graphics package, we
first take our variable of interest \texttt{StudentGoals\$Goals} and put
it in table format using the \texttt{table()} function. Next we produce
a stacked bar graph that also includes the student's gender. Then we
subsequently add a side by side bar graph that includes the student's
gender.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender.counts <-}\StringTok{ }\KeywordTok{table}\NormalTok{(StudentGoals}\OperatorTok{$}\NormalTok{Gender, StudentGoals}\OperatorTok{$}\NormalTok{Goals)}
\OperatorTok{>}\StringTok{ }\KeywordTok{barplot}\NormalTok{(gender.counts, }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"lightblue"}\NormalTok{), }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Count"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Goals"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \StringTok{"topright"}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{row.names}\NormalTok{(gender.counts), }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"lightblue"}\NormalTok{), }\DataTypeTok{pch =} \DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-372-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{gender.counts <-}\StringTok{ }\KeywordTok{table}\NormalTok{(StudentGoals}\OperatorTok{$}\NormalTok{Gender, StudentGoals}\OperatorTok{$}\NormalTok{Goals)}
\OperatorTok{>}\StringTok{ }\KeywordTok{barplot}\NormalTok{(gender.counts, }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"lightblue"}\NormalTok{), }\DataTypeTok{las =} \DecValTok{1}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Count"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Goals"}\NormalTok{, }\DataTypeTok{beside =} \OtherTok{TRUE}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{legend}\NormalTok{(}\DataTypeTok{x =} \StringTok{"topright"}\NormalTok{, }\DataTypeTok{legend =} \KeywordTok{row.names}\NormalTok{(gender.counts), }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"lightblue"}\NormalTok{), }\DataTypeTok{pch =} \DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-373-1.pdf}

In this example R counted the number of students who had each goal and
used these counts as the height of the bars. Sometimes the data contain
the bar heights as a variable. For example, we create a bar graph of
India's per capita GDP with separate bars for each year in the
data\footnote{R offers a large color palette, run \texttt{colors()} on
  the console to see a list of color names.}.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{india <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(gapminder, country }\OperatorTok{==}\StringTok{ "India"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{gdp.india <-}\StringTok{ }\NormalTok{india}\OperatorTok{$}\NormalTok{gdpPercap}
\OperatorTok{>}\StringTok{ }\KeywordTok{names}\NormalTok{(gdp.india) <-}\StringTok{ }\NormalTok{india}\OperatorTok{$}\NormalTok{year}
\OperatorTok{>}\StringTok{ }\KeywordTok{barplot}\NormalTok{(gdp.india, }\DataTypeTok{xlab =} \StringTok{"Year"}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"GDP Per Capita"}\NormalTok{, }\DataTypeTok{main =} \StringTok{"India's per-capita GDP"}\NormalTok{, }\DataTypeTok{col =} \StringTok{"steelblue2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-374-1.pdf}

\subsection{Graphs of Functions}\label{graphs-of-functions-1}

One way to create a plot of a mathematical function \(f\) is to create a
data frame with \(x\) values in one column and \(f(x)\) values in
another column, and then draw a line plot.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\NormalTok{x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\NormalTok{pi, pi, }\DataTypeTok{len =} \DecValTok{1000}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\NormalTok{sin.x <-}\StringTok{ }\KeywordTok{sin}\NormalTok{(x)}
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(x, sin.x, }\DataTypeTok{type =} \StringTok{'l'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_files/figure-latex/unnamed-chunk-375-1.pdf}

\section{Saving Graphics}\label{saving-graphics-1}

We often want to export our graphics to use in an external document or
share with colleagues. There are numerous functions available to export
graphic files in different formats. Below we demonstrate the use of the
\texttt{png()} function to export the image of the sin curve we created
above.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{>}\StringTok{ }\KeywordTok{png}\NormalTok{(}\StringTok{"sinCurve.png"}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{plot}\NormalTok{(x, sin.x, }\DataTypeTok{type =} \StringTok{'l'}\NormalTok{)}
\OperatorTok{>}\StringTok{ }\KeywordTok{dev.off}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Inside the \texttt{png()} function, we specify the name the image is
given when it is saved. There are also arguments to specify the width
and height of the saved image. This function opens a png file where the
image will be saved. There are analagous functions for other types of
files (i.e. \texttt{pdf()}, \texttt{jpeg()}). The second line
\texttt{plot(x,\ sin.x,\ type\ =\ \textquotesingle{}l\textquotesingle{})}
simply creates the plot we desire to save. The \texttt{dev.off()}
function closes the png file.

\section{\texorpdfstring{A Summary of Useful \texttt{graphics} Functions
and
Arguments}{A Summary of Useful graphics Functions and Arguments}}\label{a-summary-of-useful-graphics-functions-and-arguments}

Upon initial learning, making plots with the \texttt{graphics} package
may seem overwhelming due to the variety of different functions and
arguments that control different features of the image that is produced.
However, after some practice, you will find that the \texttt{graphics}
method of graphing gives you great flexibility in making your images
just the way you like them. This flexibility and control is one of the
main reasons we produce most of our visualizations using
\texttt{graphics}.

Below we provide a summary of the major functions and arguments you may
find helpful when working with the \texttt{graphics} package. This is
certainly not an exhaustive list, but it does include functions and
arguments we often use on a daily basis, so we think you'll find it
useful. One of the nice things about the \texttt{graphics} package is
that many of these functions utilize the same arguments.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{plot(x,\ y)}: the basic plotting function. Many of the graphs
  you produce will start with the \texttt{plot()} function. Here are
  some useful arguments (aside from x and y arguments to specify the
  data):

  \begin{itemize}
  \tightlist
  \item
    \texttt{pch}: specify the type of point in a scatter plot. We often
    use \texttt{pch\ =\ 19}.
  \item
    \texttt{xlab} and \texttt{ylab}: specify the x and y axis labels
  \item
    \texttt{xlim} and \texttt{ylim}: specify the range of the x and y
    axes
  \item
    \texttt{type}: specify the type of the plot. By default it is
    \texttt{p}, can create a line plot with
    \texttt{type\ =\ \textquotesingle{}l\textquotesingle{}} or a scatter
    plot with lines with
    \texttt{type\ =\ \textquotesingle{}b\textquotesingle{}}.
  \item
    \texttt{main}: add a title to the plot
  \item
    \texttt{cex}, \texttt{cex.lab}, \texttt{cex.main}: change the sizes
    of the points, the size of the axis label text, and the size of the
    title text, respectively
  \item
    \texttt{col}: specify the color of the points/lines
  \item
    \texttt{axes}: if \texttt{TRUE} axes will be automatically drawn, if
    \texttt{FALSE} no axes will be drawn.
  \end{itemize}
\item
  \texttt{legend(x,\ y,\ legend)}: add a legend to the graph specified
  by the location \texttt{(x,\ y)} with the text specified by the
  \texttt{legend} argument.
\item
  \texttt{points(x,\ y)}: add points to an already existing plot.
  Arguments same as those of \texttt{plot()}.
\item
  \texttt{lines(x,\ y)}: add lines to an already existing plot.
  Arguments same as those of \texttt{plot()}.
\item
  \texttt{axis()}: specify the axes
\item
  \texttt{text(x,\ y)}: add text to a plot at the location
  \texttt{(x,\ y)}.
\item
  \texttt{par()}: function to change a wide variety of graphical
  parameters for finer control over the plot's appearance.
\end{enumerate}

The functions listed above certainly do not cover the realm of plots you
can produce using the \texttt{graphics} package, but having a good
understanding of how to use these functions will give you a firm grip on
making publication-quality plots in R.

For additional help, we find that the help pages for most
\texttt{graphics} functions are quite helpful. The online documentation
for the package available
\href{https://rdrr.io/r/graphics/graphics-package.html\#heading-0}{here}
perhaps provides a more user friendly version of the help pages within
R. There are also numerous books and online tutorials available for
working with these functions, so a simple google search is often the
best way to find additional help :)

\subsection{Practice Problem}\label{practice-problem-16}

Go to the help page for the \texttt{par()} function (use
\texttt{help(par)} or \texttt{?par()}). Look at the plethora of
different arguments that you can use to specialize your plot just the
way you like it. List 5 arguments that we didn't use in this chapter,
describe what they do, then use them in a graph using the \texttt{iris}
data set (you can use any of the variables in the data set and produce
any type of graph you like).

\bibliography{book.bib,packages.bib}

\backmatter
\printindex

\end{document}
