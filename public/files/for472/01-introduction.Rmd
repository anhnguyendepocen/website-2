# Data

## FEF Tree Biomass Data Set {#fef}

When thinking about data, we might initially have in mind a modest-sized and uncomplicated data set that serves a fairly specific purpose. For example, in forestry it is convenient to have a mathematical formula that relates a tree's diameter (or some other easily measured attribute) to stem or total biomass (i.e. we cannot directly measure tree biomass without destructive sampling). When coupled with forest inventory data, such formulas provide a means to estimate forest biomass across management units or entire forest landscapes. A data set used to create such formulas includes felled tree biomass by tree component for four hardwood species of the central Appalachians sampled on the [Fernow Experimental Forest](http://www.nrs.fs.fed.us/ef/locations/wv/fernow) (FEF), West Virginia @Wood2016. A total of 88 trees were sampled from plots within two different watersheds on the FEF. Hardwood species sampled include *Acer rubrum*, *Betula lenta*, *Liriodendron tulipifera*, and *Prunus serotina*, all of which were measured in the summer of 1991 and 1992. Data include tree height, diameter, as well as green and dry weight of tree stem, top, small branches, large branches, and leaves. Table \@ref(tab:sppbio) shows a subset of these data

```{r sppbio, echo = FALSE, results = 'asis'}
library(knitr)
dat <- read.csv("../datasets/RDS-2016-0016/Data/felled_tree_biomass.csv")
dat <- dat[1:10,c("species", "dbh_in", "height_ft", "stem_green_kg", "leaves_green_kg")]
kable(
  dat, booktabs = TRUE, 
  caption = "A subset of the tree biomass data from the FEF."
)
```

The size of this dataset is relatively small, there are no missing observations, the variables are easily understood, etc. 

## FACE Experiment Data Set

We often encounter data gleaned from highly structured and complex experiments. Such data typically present challenges in organization/storage, exploratory data analysis (EDA), statistical analysis, and interpretation of analysis results. An example data set comes from the Aspen [Free-Air Carbon Dioxide Enrichment](http://www.nrs.fs.fed.us/disturbance/climate_change/face) (FACE) Experiment conducted from 1997-2009 on the [Harshaw Experimental Forest](http://www.nrs.fs.fed.us/ef/locations/wi/rhinelander/) near Rhinelander, Wisconsin. The Aspen FACE Experiment was a multidisciplinary study that assessed the effects of increasing tropospheric ozone and carbon dioxide concentrations on the structure and functioning of northern forest ecosystems. The design provided the ability to assess the effects of these gasses alone (and in combination) on many ecosystem attributes, including growth, leaf development, root characteristics, and soil carbon. The data set considered here comprises annual tree height and diameter measurements from 1997 to 2008 for *Populus tremuloides*, *Acer saccharum*, and *Betula papyrifera* grown within twelve 30 meter diameter rings in which the concentrations of tropospheric ozone and carbon dioxide were controlled @Kubiske2013. Because there was no confinement, there was no significant change in the natural, ambient environment other than elevating these trace gas concentrations. Although the basic individual tree measurements are similar to those in the FEF data set we saw in Section \@ref(fef), (i.e., height and diameter), the study design specifies various tree species clones, varying gas treatments, and treatment replicates. Further, because these are longitudinal data, (measurements were recorded over time) the data set presents many missing values as a result of tree mortality. Table \@ref(tab:face) contains the first five records as well as 5 more randomly selected records in the data set. Here, a row identifies each tree's experimental assignment, genetic description, and growth over time.

```{r face, echo = F, results = 'asis'}
set.seed(5)
dat <- read.csv("../datasets/RDS-2013-0015/Data/FACE_aspen-birch_core_growth.csv")
rows <- sample(1:dim(dat)[1], size=5)
kable(
  dat[c(1:5, rows), c(1:4, 7, 8, 34)], booktabs = TRUE,
  caption = "A small portion of the FACE experiment data set"
)
```

Notice that several height measurements in 2008 contain missing data. If all year measurements were shown, we would see much more missing data. Also, notice that this data set is substantially larger than the FEF data set with `r dim(dat)[1]` rows and `r dim(dat)[2]` columns of data in the full data set.

## PEF Inventory and LiDAR Data Set {#pef}

Coupling forest inventory with remotely sensed Light Detection and Ranging (LiDAR) data sets using regression models offers an attractive approach to mapping forest variables at stand, regional, continental, and global scales. LiDAR data have shown great potential for use in estimating spatially explicit forest variables over a range of geographic scales [@asner2009], [@babcock2013], [@finley2011], [@naesset2011], [@neigh2013]. Encouraging results from these and many other studies have spurred massive investment in new LiDAR sensors, sensor platforms, as well as extensive campaigns to collect field-based calibration data. 

Much of the interest in LiDAR based forest variable mapping is to support carbon monitoring, reporting, and verification (MRV) systems, such as defined by the United Nations Programme on [Reducing Emissions from Deforestation and Forest Degradation](http://www.un-redd.org) (UN-REDD) and NASA's [Carbon Monitoring System](http://carbon.nasa.gov) (CMS) [@le2011], [@ometto2014]. In these, and similar initiatives, AGB is the forest variable of interest because it provides a nearly direct measure of forest carbon (i.e., carbon comprises $\sim 50$\% of wood biomass, @west2004). Most efforts to quantify and/or manage forest ecosystem services (e.g., carbon, biodiversity, water) seek high spatial resolution wall-to-wall data products such as gridded maps with associated measures of uncertainty, e.g., point and associated credible intervals (CIs) at the pixel level. In fact several high profile international initiatives include language concerning the level of spatially explicit acceptable error in total forest carbon estimates, see, e.g., @REDD2009 and @UNFCCC2015.

Here, we consider a data set collected on the [Penobscot Experimental Forest](www.fs.fed.us/ne/durham/4155/penobsco.htm) (PEF) in Bradley and Eddington, Maine. The dataset comprises LiDAR waveforms collected with the [Laser Vegetation Imaging Sensor](http://lvis.gsfc.nasa.gov) (LVIS) and several forest variables measured on a set of 589 georeferenced forest inventory plots. The LVIS data were acquired during the summer of 2003. The LVIS instrument, an airborne scanning LiDAR with a 1064 nm laser, provided 12,414 LiDAR pseudo-waveform signals within the PEF. For each waveform, elevations were converted to height above the ground surface and interpolated at 0.3 m intervals. Figure \@ref(fig:img1) shows PEF LiDAR energy returns at 12 m above the ground, forest inventory plot locations, and management unit boundaries. The forest inventory data associated with each plot were drawn from the PEF's database of several on-going, long-term silvicultural experiments (see @Kenefic2015). Below we provide a plot containng the geographic coordinates, biomass (mg/ha), basal area (m$^2$/ha), stocking (trees/ha), diameter class (cm), and management unit. Table \@ref(tab:pef) shows a subset of data for 10 randomly selected plots (where each row records plot measurements) in the forest inventory data set.  

```{r pef, echo=F, results='asis'}
dat <- read.csv("../datasets/PEF/PEF-plots.csv")
set.seed(5)
rows <- sample(1:dim(dat)[1], size=10)
kable(
  dat[rows, 1:6], booktabs = TRUE, 
  caption = "A small portion of the PEF inventory data set"
)
```

```{r img1, echo = FALSE, cache = TRUE, message = FALSE, warning = FALSE, fig.cap= "Surface of LiDAR energy returns at 12 m above the ground, forest inventory plot locations, and management unit boundaries on the PEF."}
library(fields)
library(MBA)
library(rgdal)

lvis <- read.csv("../datasets/PEF/PEF-LVIS.csv.gz")

PEF.shp <- readOGR("../datasets/PEF/","MU-bounds", verbose=FALSE)
b.box <- as.vector(t(bbox(PEF.shp)))
 
surf <- mba.surf(lvis[,c(1,2,42)], no.X=100, no.Y=100, b.box=b.box, sp=TRUE, extend=TRUE)$xyz.est
proj4string(surf) <- proj4string(PEF.shp)
surf <- as.image.SpatialGridDataFrame(surf[PEF.shp,])
image.plot(surf, xaxs = "r", yaxs = "r", xlab="Easting (m)", ylab="Northing (m)")
plot(PEF.shp, add=TRUE)
points(dat[,c("easting","northing")], pch=19, cex=0.5)
```

##Zurichberg Forest inventory data set {#zf}
Measuring tree diameter and height is a time consuming process. This fact makes the Zurichberg Forest inventory data set a rare and impressive investment. These data comprise a complete enumeration of the `r dim(dat)[1]` trees in the Zurichberg Forest, including species, diameter at breast height, basal area, and volume. The stem map colored by species is shown in Figure \@ref(fig:zf).

```{r, echo = FALSE, results = 'asis'}
dat <- read.csv("../datasets/ZF/ZF-trees.csv")
```

```{r zf, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, fig.cap = "Location and species of all trees in the Zurichberg Forest."}
coords <- dat[,c("X_TREE", "Y_TREE")]

spp.name <- c("beech","maple","ash","other broadleaves",
              "spruce","silver fir", "larch", "other coniferous")

spp.col <- c("steelblue1","red","orange","pink",
             "green","dark green","black","gray")
                 
plot(coords, col=spp.col[dat$SPP+1],
     pch=19, cex=0.25, ylab="Northing", xlab="Easting")

legend.coords <- c(23,240)

legend(legend.coords, pch=19, legend=spp.name,
       col=spp.col, bty="n")
```

## Looking Forward

The four examples above illustrate a variety of data sets that might be encountered in practice, and each provides its own challenges. For the FACE data, the challenges are more statistical in nature. Complications could arise related to the complex study design and how that design might affect methods of analysis and conclusions drawn from the study. The other data sets present different challenges, such as how to:

1. Develop biomass equations suitable for population inference from the FEF's small sample of 88 trees
2. Work with spatially indexed data in the case of the PEF and Zurichberg inventory data
3. Effectively and efficiently process the PEF's high-dimentional LiDAR signal data for use in predictive models of forest variables.

This book and associated material introduce tools to tackle some of the challenges in working with real data sets within the context of the R statistical system. We will focus on important topics such as

+ Obtaining and manipulating data
+ Summarizing and visualizing data
+ Communicating findings about data that support reproducible research 
+ Programming and writing functions
+ Working with specialized data structures, e.g., spatial data and databases


## How to Learn (The Most Important Section in This Book!)

There are several ways to engage with the content of this book and associated materials. 

One way is not to engage at all. Leave the book closed on a shelf and do something else with your time. That may or may not be a good life strategy, depending on what else you do with your time, but you won't learn much from the book!

Another way to engage is to read through the book "passively", reading all that's written but not reading the book with R open on your computer, where you could enter the R commands from the book. With this strategy you'll probably learn more than if you leave the book closed on a shelf, but there are better options.

A third way to engage is to read the book while you're at a computer with R, and to enter the R commands from the book as you read about them. You'll likely learn more this way.

A fourth strategy is even better. In addition to reading and entering the commands given in the book, you think about what you're doing, and ask yourself questions (which you then go on to answer). For example, after working through some R code computing the logarithm of positive numbers you might ask yourself, "What would R do if I asked it to calculate the logarithm of a negative number? What would R do if I asked it to calculate the logarithm of a really large number such as one trillion?" You could explore these questions easily by just trying things out in the R Console window. 

If your goal is to maximize the time you have to binge-watch \emph{Stranger Things} Season 2 on Netflix, the first strategy may be optimal. But if your goal is to learn a lot about computational tools for data science, the fourth strategy is probably going to be best.


